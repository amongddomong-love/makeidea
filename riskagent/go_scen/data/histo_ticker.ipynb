{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69488b30-4e2a-41d5-b851-fdbd39a8ecaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\raw_data\\risk_thresholds_20251122.xlsx\n",
      "â–¶ alerts ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 20í–‰):\n",
      "                                  metric                              ticker  \\\n",
      "0                        KR 3Y KTB Yield                      SKTB3YAY Index   \n",
      "1                       KR 10Y KTB Yield                      SKTB10YY Index   \n",
      "2                       US 10Y vs 3M Avg                      USGG10YR Index   \n",
      "3                      TSFR 6M vs 3M Avg                        TSFR6M Index   \n",
      "4                            USDKRW Spot                       USDKRW Curncy   \n",
      "5                            KOSPI Index                         KOSPI Index   \n",
      "6                     VKOSPI (Vol Index)                        VKOSPI Index   \n",
      "7                  USDKRW 1Y Implied Vol                USDKRWV1Y BGN Curncy   \n",
      "8         USD OIS 1Y - TSFR 1M (MTD avg)  USOSFR1 BGN Curncy vs TSFR1M Index   \n",
      "9                  TSFR 3M (MTD - PrevM)                        TSFR3M Index   \n",
      "10            JPY TIBOR 3M (MTD - PrevM)                       TI0003M Index   \n",
      "11        KR 5Y CDS vs PrevM (3D consec)      KOREA CDS USD SR 5Y D14 Curncy   \n",
      "12          KR 5Y CDS vs M-3 (3D consec)      KOREA CDS USD SR 5Y D14 Curncy   \n",
      "13  KR Term Spread 10Y-3Y (5D inversion)     SKTB10YY Index - SKTB3YAY Index   \n",
      "14  CDS 5Y: United States (MTD vs PrevM)         US CDS EUR SR 5Y D14 Curncy   \n",
      "15          CDS 5Y: Japan (MTD vs PrevM)        JGB CDS USD SR 5Y D14 Curncy   \n",
      "16          CDS 5Y: China (MTD vs PrevM)   CHINAGOV CDS USD SR 5Y D14 Curncy   \n",
      "17        CDS 5Y: Vietnam (MTD vs PrevM)     VIETNM CDS USD SR 5Y D14 Curncy   \n",
      "18     CDS 5Y: Kazakhstan (MTD vs PrevM)     KAZAKS CDS USD SR 5Y D14 Curncy   \n",
      "19        CDS 5Y: Germany (MTD vs PrevM)     GERMAN CDS USD SR 5Y D14 Curncy   \n",
      "\n",
      "       latest                chg_1d     threshold_1d breach_1d  chg_10d  \\\n",
      "0      2.8650                 0.0bp            Â±15bp     False   30.0bp   \n",
      "1      3.2830                 0.0bp            Â±15bp     False   39.8bp   \n",
      "2      4.0633                   NaN              NaN       NaN      NaN   \n",
      "3      3.7784                   NaN              NaN       NaN      NaN   \n",
      "4   1471.5500                -0.04%            Â±2.0%     False    0.69%   \n",
      "5   3853.2600                -3.79%          â‰¤ -3.5%      True   -2.54%   \n",
      "6     41.3800                5.10pp         â‰¥ +5.0pp      True  -0.50pp   \n",
      "7      8.4000               -0.20pp           Â±5.0pp     False   0.08pp   \n",
      "8         NaN  -37.9bp (MTD spread)         â‰¥ +150bp     False      NaN   \n",
      "9         NaN         -2.1bp (Î”avg)    abs(Î”) > 75bp     False      NaN   \n",
      "10        NaN         -1.1bp (Î”avg)    abs(Î”) > 25bp     False      NaN   \n",
      "11    23.9330                   NaN  > +100bp for 3D     False      NaN   \n",
      "12    23.9330                   NaN  > +200bp for 3D     False      NaN   \n",
      "13    41.8000                   NaN     < 0bp for 5D     False      NaN   \n",
      "14    34.7200                -11.3%           > +30%     False      NaN   \n",
      "15    21.7570                  3.6%           > +30%     False      NaN   \n",
      "16    48.1100                  3.8%           > +30%     False      NaN   \n",
      "17    34.7640                  1.8%           > +30%     False      NaN   \n",
      "18    34.7640                  1.8%           > +30%     False      NaN   \n",
      "19     8.6070                 -2.7%           > +30%     False      NaN   \n",
      "\n",
      "   threshold_10d breach_10d breach_3m                                   note  \n",
      "0          Â±50bp      False       NaN                       ì›í™” 3Y: ìˆ˜ìµë¥  bp ê¸°ì¤€  \n",
      "1          Â±45bp      False       NaN                      ì›í™” 10Y: ìˆ˜ìµë¥  bp ê¸°ì¤€  \n",
      "2            NaN        NaN     False  3M avg=4.0946, dev=-3.1bp; ì„ê³„Â±100.0bp  \n",
      "3            NaN        NaN     False  3M avg=3.8136, dev=-3.5bp; ì„ê³„Â±100.0bp  \n",
      "4          Â±5.0%      False       NaN                          ì›/ë‹¬ëŸ¬ í™˜ìœ¨: % ê¸°ì¤€  \n",
      "5       â‰¤ -10.0%      False       NaN                             í•˜ë½ ë°©í–¥ë§Œ íŠ¸ë¦¬ê±°  \n",
      "6      â‰¥ +10.0pp      False       NaN                            ìƒìŠ¹ë§Œ íŠ¸ë¦¬ê±°(pp)  \n",
      "7        Â±10.0pp      False       NaN                               ì ˆëŒ€ pp ê¸°ì¤€  \n",
      "8            NaN        NaN       NaN        MTD OIS1Y=3.5861, TSFR1M=3.9655  \n",
      "9            NaN        NaN       NaN               MTD=3.8678, PrevM=3.8887  \n",
      "10           NaN        NaN       NaN               MTD=0.8056, PrevM=0.8164  \n",
      "11           NaN        NaN       NaN                       PrevM avg=23.8bp  \n",
      "12           NaN        NaN       NaN                         M-3 avg=21.0bp  \n",
      "13           NaN        NaN       NaN                  10Y-3Y â‰¤ 0bp ìƒíƒœ 5D ì—°ì†  \n",
      "14           NaN        NaN       NaN                   MTD=36.8, PrevM=41.5  \n",
      "15           NaN        NaN       NaN                   MTD=20.5, PrevM=19.8  \n",
      "16           NaN        NaN       NaN                   MTD=43.5, PrevM=41.9  \n",
      "17           NaN        NaN       NaN                   MTD=34.2, PrevM=33.6  \n",
      "18           NaN        NaN       NaN                   MTD=34.2, PrevM=33.6  \n",
      "19           NaN        NaN       NaN                     MTD=8.6, PrevM=8.8  \n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "ëª©ì :\n",
    "- ë¸”ë£¸ë²„ê·¸ xbbgë¡œ ì£¼ìš” ì§€í‘œë¥¼ ì¡°íšŒí•˜ê³ , 1ì¼/10ì¼ ë³€í™”ìœ¨(ë˜ëŠ” bp/pp) ê¸°ë°˜ ì„ê³„ìˆ˜ì¤€ ì´ˆê³¼ ì—¬ë¶€ë¥¼ ì ê²€\n",
    "- íŠ¹ì • í•­ëª©ì€ ì›”í‰ê· (MTD/PrevM/3M-ago) ê¸°ì¤€ìœ¼ë¡œ ìŠ¤í”„ë ˆë“œ/ë³€ë™ë¥  ì„ê³„ì¹˜ ì ê²€\n",
    "- âš ï¸ \"í˜„ì¬ ê°’ì´ ë‚˜ì˜¤ëŠ” ì§€í‘œë§Œ\" alertsì— ë°˜ì˜ (ë°ì´í„° ë¯¸ìˆ˜ê¸‰ ì‹œ í•´ë‹¹ ë¸”ë¡ì€ ì½”ë“œì—ì„œ ì£¼ì„ ì²˜ë¦¬ ì˜ˆì‹œë¥¼ ë‚¨ê¹€)\n",
    "- ê²°ê³¼ë¥¼ ì—‘ì…€ íŒŒì¼(ìš”ì•½ alerts + ì›ì‹œ raw_data)ë¡œ ì €ì¥\n",
    "\n",
    "í™˜ê²½ ìœ ì˜:\n",
    "- Bloomberg Desktop + xbbg (í„°ë¯¸ë„ ë¡œê·¸ì¸ ìƒíƒœ) í•„ìš”\n",
    "- pip: xbbg, pandas, numpy, openpyxl ë“±\n",
    "- Windows ê²½ë¡œëŠ” ë°˜ë“œì‹œ pathlib.Path ì‚¬ìš© ë˜ëŠ” / ìŠ¬ë˜ì‹œ\n",
    "\n",
    "ì„ê³„ìˆ˜ì¤€ ìš”ì•½:\n",
    "- ì›í™”ê¸ˆë¦¬(êµ­ê³ 3Y): 1ì¼ Â±15bp, 10ì¼ Â±50bp\n",
    "- ì›í™”ê¸ˆë¦¬(êµ­ê³ 10Y): 1ì¼ Â±15bp, 10ì¼ Â±45bp\n",
    "- ì™¸í™”ê¸ˆë¦¬(ë¯¸10Y/Term SOFR 6M): ìµœê·¼ 3ê°œì›” í‰ê·  ëŒ€ë¹„ Â±100bp\n",
    "- KRWUSD í™˜ìœ¨: 1ì¼ Â±2%, 10ì¼ Â±5%\n",
    "- KOSPI: 1ì¼ -3.5%, 10ì¼ -10% (í•˜ë½ ë°©í–¥ë§Œ)\n",
    "- VKOSPI: 1ì¼ +5%p, 10ì¼ +10%p (ìƒìŠ¹ ë°©í–¥ë§Œ)\n",
    "- USDKRW 1Y IV: 1ì¼ Â±5%p, 10ì¼ Â±10%p\n",
    "- ì™¸í™” ì›”í‰ê·  ì¥ë‹¨ê¸° ê¸ˆë¦¬ì°¨: (SOFR OIS 1Y - TSFR 1M) MTD í‰ê·  â‰¥ +150bp\n",
    "- KR 1Y - ê¸°ì¤€ê¸ˆë¦¬: 5ì˜ì—…ì¼ ì—°ì† < -24bp\n",
    "- ê¸°ì¤€ê¸ˆë¦¬ - ì½œê¸ˆë¦¬: > +40bp (ë ˆë²¨)\n",
    "- Term SOFR 3M: MTD-PrevM ì ˆëŒ€ë³€í™” > 75bp\n",
    "- JPY 3M TIBOR: MTD-PrevM ì ˆëŒ€ë³€í™” > 25bp\n",
    "- í•œêµ­ 5Y CDS: PrevM ëŒ€ë¹„ +100bp 3ì˜ì—…ì¼ ì—°ì† / M-3 ëŒ€ë¹„ +200bp 3ì˜ì—…ì¼ ì—°ì†\n",
    "- KR Term Spread (10Y-3Y): ì—­ì „(â‰¤0bp) 5ì˜ì—…ì¼ ì—°ì†\n",
    "- êµ­ê°€ë³„ CDS 17ê°œêµ­: ì „ì›” í‰ê·  ëŒ€ë¹„ +30% ìƒìŠ¹\n",
    "- (íšŒì‚¬ì±„/êµ­ê³ ) 3Y ë¹„ìœ¨: ì „ì›”í‰ê·  ëŒ€ë¹„ +16% ìƒìŠ¹\n",
    "- ì›”í‰ê·  ì¥ë‹¨ê¸° (ê¸ˆìœµì±„1Y - CD3M): MTD ìŠ¤í”„ë ˆë“œ â‰¥ +70bp\n",
    "- (ê¸ˆìœµì±„1Y AAA - KTB1Y): 5ì˜ì—…ì¼ ì—°ì† â‰¥ +50bp\n",
    "- S&P500: 1ì¼ â‰¤ -3%, 10ì¼ â‰¤ -12%\n",
    "- EuroStoxx50: 1ì¼ |Î”| â‰¥ 3%, 10ì¼ â‰¤ -12%\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path  # âœ… ìœˆë„ìš°ì—ì„œë„ ì•ˆì „í•œ ê²½ë¡œ ì²˜ë¦¬\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Bloomberg\n",
    "try:\n",
    "    from xbbg import blp\n",
    "except ImportError as e:\n",
    "    raise SystemExit(\n",
    "        \"xbbgê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ë‹¤ìŒì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”:\\n\"\n",
    "        \"    pip install xbbg pandas numpy openpyxl\\n\"\n",
    "        f\"ì›ë³¸ ì—ëŸ¬: {e}\"\n",
    "    )\n",
    "\n",
    "# -----------------------------\n",
    "# 0) ê³µí†µ ì„¤ì •\n",
    "# -----------------------------\n",
    "TODAY = pd.Timestamp.today(tz=\"Asia/Seoul\").date()\n",
    "# ì›”í‰ê· /ì—°ì†ì¼ íŒì • ë“±ì„ ìœ„í•´ ì¶©ë¶„í•œ ê³¼ê±°ì¹˜ í™•ë³´ (ì•½ 14ê°œì›”)\n",
    "START_DATE = (pd.Timestamp(TODAY) - timedelta(days=420)).strftime(\"%Y-%m-%d\")\n",
    "END_DATE = pd.Timestamp(TODAY).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# ğŸ’¾ ì €ì¥ ê²½ë¡œ (ì‹¤í–‰ í´ë”)\n",
    "output_path = Path(r\"C:/Users/amongpapa/chartup/raw_data\") / f\"risk_thresholds_{pd.Timestamp(TODAY).strftime('%Y%m%d')}.xlsx\"\n",
    "\n",
    "# -----------------------------\n",
    "# 1) í‹°ì»¤ ë§µ\n",
    "# -----------------------------\n",
    "TICKERS = {\n",
    "    # KTB / KR rates\n",
    "    \"KR1Y\":         \"SKTB1YAY Index\",\n",
    "    \"KR3Y\":         \"SKTB3YAY Index\",\n",
    "    \"KR10Y\":        \"SKTB10YY Index\",\n",
    "\n",
    "    # UST & SOFR\n",
    "    \"US10Y\":        \"USGG10YR Index\",\n",
    "    \"TSFR6M\":       \"TSFR6M Index\",\n",
    "    \"TSFR3M\":       \"TSFR3M Index\",\n",
    "    \"TSFR1M\":       \"TSFR1M Index\",\n",
    "    \"SOFR_OIS_1Y\":  \"USOSFR1 BGN Curncy\",   # âœ… íŒ€ì¥ë‹˜ ì§€ì •\n",
    "\n",
    "    # FX / Equities / Vol\n",
    "    \"USDKRW\":       \"USDKRW Curncy\",\n",
    "    \"KOSPI\":        \"KOSPI Index\",\n",
    "    \"VKOSPI\":       \"VKOSPI Index\",\n",
    "    \"KRW_IV1Y\":     \"USDKRWV1Y BGN Curncy\",\n",
    "\n",
    "    # KR policy & money\n",
    "    \"KRBASERATE\":   \"KORP7D Index\",         # âœ… í•œêµ­ ê¸°ì¤€ê¸ˆë¦¬\n",
    "    \"KRCALL\":       \"KOCR Index\",           # âœ… ì‹œì¥ ì½œê¸ˆë¦¬\n",
    "    \"KR_CD3M\":      \"KWCDC CMPN Curncy\",    # âœ… CD 3ê°œì›”ë¬¼\n",
    "    \"KR_FIN1Y_AAA\": \"KRFN1YAA Index\",       # ê¸ˆìœµì±„ 1ë…„ AAA\n",
    "    \"KR_CORP3Y_AA-\":\"KRCORP3YAA- Index\",    # íšŒì‚¬ì±„ 3ë…„ AA-\n",
    "\n",
    "    # Other markets\n",
    "    \"SPX\":          \"SPX Index\",\n",
    "    \"SX5E\":         \"SX5E Index\",\n",
    "\n",
    "    # JPY money market\n",
    "    \"JPY_TIBOR3M\":  \"TI0003M Index\",        # âœ… JPY 3M TIBOR\n",
    "\n",
    "    # FRA-OIS (í™˜ê²½ì— ë”°ë¼ í‹±ì»¤ ìƒì´í•  ìˆ˜ ìˆìŒ)\n",
    "    \"US_FRAOIS_3M\": \"USSFRAOIS Index\",      # âš ï¸ í•„ìš”ì‹œ êµì²´/ë¹„í™œì„±\n",
    "}\n",
    "\n",
    "# êµ­ê°€ë³„ 5Y CDS (D14)\n",
    "CDS_TICKERS = {\n",
    "    \"Korea\":          \"KOREA CDS USD SR 5Y D14 Curncy\",   # í•œêµ­\n",
    "    \"United States\":  \"US CDS EUR SR 5Y D14 Curncy\",\n",
    "    \"Japan\":          \"JGB CDS USD SR 5Y D14 Curncy\",\n",
    "    \"China\":          \"CHINAGOV CDS USD SR 5Y D14 Curncy\",\n",
    "    \"Vietnam\":        \"VIETNM CDS USD SR 5Y D14 Curncy\",\n",
    "    \"Kazakhstan\":     \"KAZAKS CDS USD SR 5Y D14 Curncy\",\n",
    "    \"Germany\":        \"GERMAN CDS USD SR 5Y D14 Curncy\",\n",
    "    \"United Kingdom\": \"UK CDS USD SR 5Y D14 Curncy\",\n",
    "    \"India\":          \"INDIA CDS USD SR 5Y D14 Curncy\",\n",
    "    \"Mexico\":         \"MEX CDS USD SR 5Y D14 Curncy\",\n",
    "    \"Indonesia\":      \"INDON CDS USD SR 5Y D14 Curncy\",\n",
    "    \"TÃ¼rkiye\":        \"TURKEY CDS USD SR 5Y D14 Curncy\",\n",
    "    \"Canada\":         \"CANPAC CDS USD SR 5Y D14 Curncy\",\n",
    "    \"Hong Kong\":      \"HONGK CDS USD SR 5Y D14 Curncy\",\n",
    "    \"Australia\":      \"AUSTLA CDS USD SR 5Y D14 Curncy\",\n",
    "    \"Philippines\":    \"PHILIP CDS USD SR 5Y D14 Curncy\",\n",
    "    \"Singapore\":      \"SINGP CDS USD SR 5Y D14 Curncy\",    # âœ… ì¶”ê°€ ê°€ëŠ¥\n",
    "    \"UAE\":            \"DPWDU CDS USD SR 5Y D14 Curncy\",    # âœ… ìš”ì²­ì‚¬í•­ ë°˜ì˜(ê¸°ì—…ê³„ì—´)\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# 2) í•„ë“œ ìš°ì„ ìˆœìœ„\n",
    "# -----------------------------\n",
    "# - ê¸ˆë¦¬: YLD_YTM_MID > YLD_YTM_LAST > PX_LAST\n",
    "# - ì§€ìˆ˜/í™˜ìœ¨/ë³€ë™ì„±: PX_LAST\n",
    "# - â˜… CDS: LAST_PRICE > MID > PX_LAST  (â€» í•µì‹¬ ìˆ˜ì •)\n",
    "FIELD_PREFS = {}\n",
    "for k in TICKERS:\n",
    "    if k in [\"KR1Y\",\"KR3Y\",\"KR10Y\"]:\n",
    "        FIELD_PREFS[k] = [\"YLD_YTM_MID\", \"YLD_YTM_LAST\", \"PX_LAST\"]\n",
    "    elif k in [\"US10Y\"]:\n",
    "        FIELD_PREFS[k] = [\"PX_LAST\", \"YLD_YTM_MID\"]\n",
    "    elif k in [\"TSFR6M\",\"TSFR3M\",\"TSFR1M\",\"USDKRW\",\"KOSPI\",\"VKOSPI\",\"KRW_IV1Y\",\"SPX\",\"SX5E\"]:\n",
    "        FIELD_PREFS[k] = [\"PX_LAST\"]\n",
    "    elif k in [\"SOFR_OIS_1Y\"]:\n",
    "        FIELD_PREFS[k] = [\"PX_LAST\", \"YLD_YTM_MID\", \"LAST_PRICE\"]\n",
    "    elif k in [\"KRBASERATE\",\"KRCALL\",\"KR_CD3M\",\"JPY_TIBOR3M\",\"US_FRAOIS_3M\"]:\n",
    "        FIELD_PREFS[k] = [\"PX_LAST\", \"LAST_PRICE\"]\n",
    "    elif k in [\"KR_FIN1Y_AAA\",\"KR_CORP3Y_AA-\"]:\n",
    "        FIELD_PREFS[k] = [\"PX_LAST\", \"YLD_YTM_MID\", \"LAST_PRICE\"]\n",
    "    else:\n",
    "        FIELD_PREFS[k] = [\"PX_LAST\"]\n",
    "\n",
    "# â˜… CDS ì „ìš©: (ì´ì „: PX_MIDâ†’PX_LAST) â†’ (ë³€ê²½: LAST_PRICEâ†’MIDâ†’PX_LAST)\n",
    "for name in CDS_TICKERS:\n",
    "    FIELD_PREFS[name] = [\"LAST_PRICE\", \"MID\", \"PX_LAST\"]  # â˜… ìˆ˜ì •\n",
    "\n",
    "# â˜… BDH í˜¸ì¶œ ì‹œ ëˆ„ë½ ë°©ì§€ë¥¼ ìœ„í•´ í•­ìƒ í¬í•¨í•  Fallback í•„ë“œ\n",
    "FALLBACK_FIELDS = {\"LAST_PRICE\", \"MID\", \"PX_LAST\", \"PX_MID\", \"YLD_YTM_MID\", \"YLD_YTM_LAST\"}  # â˜… ìˆ˜ì •\n",
    "\n",
    "# -----------------------------\n",
    "# 3) ì„ê³„ê°’\n",
    "# -----------------------------\n",
    "THRESHOLDS = {\n",
    "    \"KR3Y_1d_bp\": 15,   \"KR3Y_10d_bp\": 50,\n",
    "    \"KR10Y_1d_bp\": 15,  \"KR10Y_10d_bp\": 45,\n",
    "    \"USFX_1d_pct\": 2.0, \"USFX_10d_pct\": 5.0,\n",
    "    \"KOSPI_1d_down_pct\": -3.5, \"KOSPI_10d_down_pct\": -10.0,\n",
    "    \"VKOSPI_1d_up_pp\": 5.0,    \"VKOSPI_10d_up_pp\": 10.0,\n",
    "    \"KRWIV_1d_pp\": 5.0, \"KRWIV_10d_pp\": 10.0,\n",
    "    \"G3M_dev_bp\": 100.0,\n",
    "\n",
    "    # ì¶”ê°€ ì„ê³„\n",
    "    \"SPREAD_SOFR1M_vs_OIS1Y_MTD_bp\": 150.0,\n",
    "    \"KR_1Y_minus_BASE_5d_level_bp\": -24.0,\n",
    "    \"BASE_minus_CALL_bp\": 40.0,\n",
    "    \"TSFR3M_prevM_abs_bp\": 75.0,\n",
    "    \"JPY_TIBOR3M_prevM_abs_bp\": 25.0,\n",
    "    \"KR5YCDS_prevM_bp_3d\": 100.0,\n",
    "    \"KR5YCDS_M3ago_bp_3d\": 200.0,\n",
    "    \"KR_10Y_3Y_inversion_5d\": 5,\n",
    "    \"CDS_prevM_pct_up\": 30.0,\n",
    "    \"CorpAAminus_KTB3Y_ratio_prevM_pct\": 16.0,\n",
    "    \"Fin1Y_minus_CD3M_MTD_bp\": 70.0,\n",
    "    \"Fin1YAAA_minus_KTB1Y_5d_bp\": 50.0,\n",
    "    \"SPX_1d_down_pct\": -3.0, \"SPX_10d_down_pct\": -12.0,\n",
    "    \"SX5E_1d_abs_pct\": 3.0,  \"SX5E_10d_down_pct\": -12.0,\n",
    "    \"FRAOIS_prevM_bp\": 30.0,\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# 4) ìœ í‹¸ í•¨ìˆ˜\n",
    "# -----------------------------\n",
    "def fetch_hist_with_field_prefs(ticker_map, cds_map, field_prefs, start_date, end_date):\n",
    "    \"\"\"\n",
    "    ë©€í‹° í•„ë“œë¡œ BDH ì¡°íšŒ í›„, ê°€ìš©ì„±ì´ ê°€ì¥ ì¢‹ì€ í•„ë“œë¥¼ ì±„íƒí•˜ì—¬ ë‹¨ì¼ ì‹œê³„ì—´ë¡œ ë³‘í•©\n",
    "    ë°˜í™˜: DataFrame(index=Date, columns=keys)\n",
    "    \"\"\"\n",
    "    all_pairs = list(ticker_map.items()) + list(cds_map.items())\n",
    "    # â˜… ìš”ì²­ í•„ë“œ = ìš°ì„ ìˆœìœ„ í•„ë“œ í•©ì§‘í•© + Fallback (ëˆ„ë½ ë°©ì§€)\n",
    "    prefs_fields = {fld for prefs in field_prefs.values() for fld in prefs}\n",
    "    all_fields = sorted(prefs_fields | FALLBACK_FIELDS)  # â˜… ìˆ˜ì •\n",
    "\n",
    "    raw = blp.bdh(\n",
    "        tickers=[t for _, t in all_pairs],\n",
    "        flds=all_fields,\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        Per=\"D\",\n",
    "        Fill=\"P\",\n",
    "    )\n",
    "\n",
    "    # ì¼ë¶€ í™˜ê²½ì—ì„œ ë‹¨ì¼ ì¢…ëª©/í•„ë“œ ì¡°í•©ì¼ ë•Œ MultiIndexê°€ ì•„ë‹ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë°©ì–´\n",
    "    if not isinstance(raw.columns, pd.MultiIndex):\n",
    "        raw.columns = pd.MultiIndex.from_product([[all_pairs[0][1]], all_fields])\n",
    "\n",
    "    raw.index = pd.to_datetime(raw.index, errors=\"coerce\")\n",
    "    raw = raw.sort_index()\n",
    "\n",
    "    out = {}\n",
    "\n",
    "    # ê³µí†µ fallback (ì¼ë°˜ìì‚°): PX_LAST â†’ LAST_PRICE â†’ PX_MID â†’ MID\n",
    "    default_general = [\"PX_LAST\", \"LAST_PRICE\", \"PX_MID\", \"MID\"]\n",
    "    # ê³µí†µ fallback (CDS): LAST_PRICE â†’ MID â†’ PX_LAST\n",
    "    default_cds = [\"LAST_PRICE\", \"MID\", \"PX_LAST\"]\n",
    "\n",
    "    # ì¼ë°˜ í‹±ì»¤\n",
    "    for key, bb_ticker in ticker_map.items():\n",
    "        prefs = field_prefs.get(key, default_general)  # â˜… ìˆ˜ì •: ì¼ë°˜ë„ ë³´ê°•\n",
    "        ser = None\n",
    "        for fld in prefs:\n",
    "            if (bb_ticker, fld) in raw.columns:\n",
    "                tmp = pd.to_numeric(raw[(bb_ticker, fld)], errors=\"coerce\").ffill().bfill()\n",
    "                if tmp.notna().sum() > 0:\n",
    "                    ser = tmp\n",
    "                    # print(f\"[{key}] ì‚¬ìš© í•„ë“œ: {fld}\")  # ë””ë²„ê·¸ìš©\n",
    "                    break\n",
    "        out[key] = ser if ser is not None else pd.Series(index=raw.index, dtype=float)\n",
    "\n",
    "    # CDS(êµ­ê°€ëª… í‚¤)\n",
    "    for name, bb_ticker in cds_map.items():\n",
    "        prefs = field_prefs.get(name, default_cds)     # â˜… ìˆ˜ì •: CDS ê¸°ë³¸ê°’ ê³ ì •\n",
    "        ser = None\n",
    "        for fld in prefs:\n",
    "            if (bb_ticker, fld) in raw.columns:\n",
    "                tmp = pd.to_numeric(raw[(bb_ticker, fld)], errors=\"coerce\").ffill().bfill()\n",
    "                if tmp.notna().sum() > 0:\n",
    "                    ser = tmp\n",
    "                    # print(f\"[CDS:{name}] ì‚¬ìš© í•„ë“œ: {fld}\")  # ë””ë²„ê·¸ìš©\n",
    "                    break\n",
    "        out[name] = ser if ser is not None else pd.Series(index=raw.index, dtype=float)\n",
    "\n",
    "    df = pd.DataFrame(out)\n",
    "    df.index = pd.to_datetime(df.index, errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "def last_value(series):\n",
    "    s = series.dropna()\n",
    "    return float(s.iloc[-1]) if len(s) else np.nan\n",
    "\n",
    "def bp_change(series, days=1):\n",
    "    s = series.dropna()\n",
    "    if len(s) <= days:\n",
    "        return np.nan\n",
    "    return float((s.iloc[-1] - s.iloc[-1 - days]) * 100.0)\n",
    "\n",
    "def pct_change(series, days=1):\n",
    "    s = series.dropna()\n",
    "    if len(s) <= days:\n",
    "        return np.nan\n",
    "    prev = s.iloc[-1 - days]\n",
    "    if prev == 0 or np.isnan(prev):\n",
    "        return np.nan\n",
    "    return float((s.iloc[-1] / prev - 1.0) * 100.0)\n",
    "\n",
    "def pp_change(series, days=1):\n",
    "    s = series.dropna()\n",
    "    if len(s) <= days:\n",
    "        return np.nan\n",
    "    return float(s.iloc[-1] - s.iloc[-1 - days])\n",
    "\n",
    "def trailing_3m_avg(series):\n",
    "    \"\"\"ìµœê·¼ 3ê°œì›”(ì˜ì—…ì¼ ì•½ 63ê°œ) í‰ê· \"\"\"\n",
    "    s = series.dropna()\n",
    "    if len(s) < 10:\n",
    "        return np.nan\n",
    "    window = min(63, len(s))\n",
    "    return float(s.iloc[-window:].mean())\n",
    "\n",
    "def month_avg(series, months_ago=0):\n",
    "    \"\"\"\n",
    "    ë‹¬ë ¥ì›” í‰ê·  (months_ago=0: ë‹¹ì›”, 1: ì „ì›”, 3: 3ê°œì›”ì „)\n",
    "    - ì¸ë±ìŠ¤ê°€ datetime ë³€í™˜ ê°€ëŠ¥í•œì§€ ì•ˆì „í•˜ê²Œ ì²´í¬\n",
    "    \"\"\"\n",
    "    s = series.dropna()\n",
    "    if s.empty:\n",
    "        return np.nan\n",
    "    dt = pd.to_datetime(s.index, errors=\"coerce\")\n",
    "    valid = ~pd.isna(dt)\n",
    "    s, dt = s[valid], dt[valid]\n",
    "    if len(s) == 0:\n",
    "        return np.nan\n",
    "    last_dt = dt.max()\n",
    "    target = last_dt - pd.DateOffset(months=months_ago)\n",
    "    mask = (dt.year == target.year) & (dt.month == target.month)\n",
    "    if not mask.any():\n",
    "        return np.nan\n",
    "    # â˜… boolean mask ì¸ë±ì‹± ì•ˆì •í™”\n",
    "    return float(s[mask].mean())  # â˜… ìˆ˜ì •\n",
    "\n",
    "def consec_last_n(bool_series, n):\n",
    "    \"\"\"ë§ˆì§€ë§‰ Nì˜ì—…ì¼ ëª¨ë‘ True ì¸ì§€\"\"\"\n",
    "    s = bool_series.dropna().astype(bool)\n",
    "    if len(s) < n:\n",
    "        return False\n",
    "    return bool(s.iloc[-n:].all())\n",
    "\n",
    "def has_data(series, min_points=5):\n",
    "    \"\"\"ë°ì´í„° ìœ íš¨ì„± ì²´í¬: ê²°ì¸¡ ì œê±° í›„ ìµœì†Œ ê°œìˆ˜ í™•ë³´\"\"\"\n",
    "    return series.dropna().shape[0] >= min_points\n",
    "\n",
    "# -----------------------------\n",
    "# 5) ë°ì´í„° ìˆ˜ì§‘\n",
    "# -----------------------------\n",
    "hist = fetch_hist_with_field_prefs(\n",
    "    ticker_map=TICKERS,\n",
    "    cds_map=CDS_TICKERS,\n",
    "    field_prefs=FIELD_PREFS,\n",
    "    start_date=START_DATE,\n",
    "    end_date=END_DATE,\n",
    ")\n",
    "\n",
    "# series ì ‘ê·¼ìš© ë§µ êµ¬ì„± (í‚¤: TICKERS/êµ­ê°€ëª…)\n",
    "series_map = {}\n",
    "for k in TICKERS.keys():\n",
    "    if k in hist.columns:\n",
    "        series_map[k] = hist[k]\n",
    "for name in CDS_TICKERS.keys():\n",
    "    if name in hist.columns:\n",
    "        series_map[name] = hist[name]\n",
    "\n",
    "# -----------------------------\n",
    "# 6) ì„ê³„ ë¡œì§\n",
    "# -----------------------------\n",
    "rows = []\n",
    "\n",
    "# ---- (A) ì›í™”ê¸ˆë¦¬ - êµ­ê³  3ë…„ ----\n",
    "if has_data(series_map.get(\"KR3Y\", pd.Series(dtype=float))):\n",
    "    kr3y_1d = bp_change(series_map[\"KR3Y\"], 1)\n",
    "    kr3y_10d = bp_change(series_map[\"KR3Y\"], 10)\n",
    "    rows.append({\n",
    "        \"metric\": \"KR 3Y KTB Yield\",\n",
    "        \"ticker\": TICKERS[\"KR3Y\"],\n",
    "        \"latest\": last_value(series_map[\"KR3Y\"]),\n",
    "        \"chg_1d\": f\"{kr3y_1d:.1f}bp\" if pd.notna(kr3y_1d) else np.nan,\n",
    "        \"threshold_1d\": \"Â±15bp\",\n",
    "        \"breach_1d\": (abs(kr3y_1d) >= THRESHOLDS[\"KR3Y_1d_bp\"]) if pd.notna(kr3y_1d) else np.nan,\n",
    "        \"chg_10d\": f\"{kr3y_10d:.1f}bp\" if pd.notna(kr3y_10d) else np.nan,\n",
    "        \"threshold_10d\": \"Â±50bp\",\n",
    "        \"breach_10d\": (abs(kr3y_10d) >= THRESHOLDS[\"KR3Y_10d_bp\"]) if pd.notna(kr3y_10d) else np.nan,\n",
    "        \"note\": \"ì›í™” 3Y: ìˆ˜ìµë¥  bp ê¸°ì¤€\",\n",
    "    })\n",
    "\n",
    "# ---- (B) ì›í™”ê¸ˆë¦¬ - êµ­ê³  10ë…„ ----\n",
    "if has_data(series_map.get(\"KR10Y\", pd.Series(dtype=float))):\n",
    "    kr10y_1d = bp_change(series_map[\"KR10Y\"], 1)\n",
    "    kr10y_10d = bp_change(series_map[\"KR10Y\"], 10)\n",
    "    rows.append({\n",
    "        \"metric\": \"KR 10Y KTB Yield\",\n",
    "        \"ticker\": TICKERS[\"KR10Y\"],\n",
    "        \"latest\": last_value(series_map[\"KR10Y\"]),\n",
    "        \"chg_1d\": f\"{kr10y_1d:.1f}bp\" if pd.notna(kr10y_1d) else np.nan,\n",
    "        \"threshold_1d\": \"Â±15bp\",\n",
    "        \"breach_1d\": (abs(kr10y_1d) >= THRESHOLDS[\"KR10Y_1d_bp\"]) if pd.notna(kr10y_1d) else np.nan,\n",
    "        \"chg_10d\": f\"{kr10y_10d:.1f}bp\" if pd.notna(kr10y_10d) else np.nan,\n",
    "        \"threshold_10d\": \"Â±45bp\",\n",
    "        \"breach_10d\": (abs(kr10y_10d) >= THRESHOLDS[\"KR10Y_10d_bp\"]) if pd.notna(kr10y_10d) else np.nan,\n",
    "        \"note\": \"ì›í™” 10Y: ìˆ˜ìµë¥  bp ê¸°ì¤€\",\n",
    "    })\n",
    "\n",
    "# ---- (C) ë¯¸10Y: 3M í‰ê·  ëŒ€ë¹„ Â±100bp ----\n",
    "if has_data(series_map.get(\"US10Y\", pd.Series(dtype=float))):\n",
    "    us10y_last = last_value(series_map[\"US10Y\"])\n",
    "    us10y_3m = trailing_3m_avg(series_map[\"US10Y\"])\n",
    "    dev_bp = (us10y_last - us10y_3m) * 100.0 if pd.notna(us10y_last) and pd.notna(us10y_3m) else np.nan\n",
    "    rows.append({\n",
    "        \"metric\": \"US 10Y vs 3M Avg\",\n",
    "        \"ticker\": TICKERS[\"US10Y\"],\n",
    "        \"latest\": us10y_last,\n",
    "        \"breach_3m\": (abs(dev_bp) >= THRESHOLDS[\"G3M_dev_bp\"]) if pd.notna(dev_bp) else np.nan,\n",
    "        \"note\": f\"3M avg={us10y_3m:.4f}, dev={dev_bp:.1f}bp; ì„ê³„Â±{THRESHOLDS['G3M_dev_bp']}bp\" if pd.notna(dev_bp) else \"ë°ì´í„° ë¶€ì¡±\",\n",
    "    })\n",
    "\n",
    "# ---- (D) TSFR 6M: 3M í‰ê·  ëŒ€ë¹„ Â±100bp ----\n",
    "if has_data(series_map.get(\"TSFR6M\", pd.Series(dtype=float))):\n",
    "    ts6_last = last_value(series_map[\"TSFR6M\"])\n",
    "    ts6_3m = trailing_3m_avg(series_map[\"TSFR6M\"])\n",
    "    dev_bp = (ts6_last - ts6_3m) * 100.0 if pd.notna(ts6_last) and pd.notna(ts6_3m) else np.nan\n",
    "    rows.append({\n",
    "        \"metric\": \"TSFR 6M vs 3M Avg\",\n",
    "        \"ticker\": TICKERS[\"TSFR6M\"],\n",
    "        \"latest\": ts6_last,\n",
    "        \"breach_3m\": (abs(dev_bp) >= THRESHOLDS[\"G3M_dev_bp\"]) if pd.notna(dev_bp) else np.nan,\n",
    "        \"note\": f\"3M avg={ts6_3m:.4f}, dev={dev_bp:.1f}bp; ì„ê³„Â±{THRESHOLDS['G3M_dev_bp']}bp\" if pd.notna(dev_bp) else \"ë°ì´í„° ë¶€ì¡±\",\n",
    "    })\n",
    "\n",
    "# ---- (E) USDKRW: 1ì¼ Â±2%, 10ì¼ Â±5% ----\n",
    "if has_data(series_map.get(\"USDKRW\", pd.Series(dtype=float))):\n",
    "    krw_1d = pct_change(series_map[\"USDKRW\"], 1)\n",
    "    krw_10d = pct_change(series_map[\"USDKRW\"], 10)\n",
    "    rows.append({\n",
    "        \"metric\": \"USDKRW Spot\",\n",
    "        \"ticker\": TICKERS[\"USDKRW\"],\n",
    "        \"latest\": last_value(series_map[\"USDKRW\"]),\n",
    "        \"chg_1d\": f\"{krw_1d:.2f}%\" if pd.notna(krw_1d) else np.nan,\n",
    "        \"threshold_1d\": \"Â±2.0%\",\n",
    "        \"breach_1d\": (abs(krw_1d) >= THRESHOLDS[\"USFX_1d_pct\"]) if pd.notna(krw_1d) else np.nan,\n",
    "        \"chg_10d\": f\"{krw_10d:.2f}%\" if pd.notna(krw_10d) else np.nan,\n",
    "        \"threshold_10d\": \"Â±5.0%\",\n",
    "        \"breach_10d\": (abs(krw_10d) >= THRESHOLDS[\"USFX_10d_pct\"]) if pd.notna(krw_10d) else np.nan,\n",
    "        \"note\": \"ì›/ë‹¬ëŸ¬ í™˜ìœ¨: % ê¸°ì¤€\",\n",
    "    })\n",
    "\n",
    "# ---- (F) KOSPI: 1ì¼ -3.5%, 10ì¼ -10% (í•˜ë½ë§Œ) ----\n",
    "if has_data(series_map.get(\"KOSPI\", pd.Series(dtype=float))):\n",
    "    k1 = pct_change(series_map[\"KOSPI\"], 1)\n",
    "    k10 = pct_change(series_map[\"KOSPI\"], 10)\n",
    "    rows.append({\n",
    "        \"metric\": \"KOSPI Index\",\n",
    "        \"ticker\": TICKERS[\"KOSPI\"],\n",
    "        \"latest\": last_value(series_map[\"KOSPI\"]),\n",
    "        \"chg_1d\": f\"{k1:.2f}%\" if pd.notna(k1) else np.nan,\n",
    "        \"threshold_1d\": \"â‰¤ -3.5%\",\n",
    "        \"breach_1d\": (k1 <= THRESHOLDS[\"KOSPI_1d_down_pct\"]) if pd.notna(k1) else np.nan,\n",
    "        \"chg_10d\": f\"{k10:.2f}%\" if pd.notna(k10) else np.nan,\n",
    "        \"threshold_10d\": \"â‰¤ -10.0%\",\n",
    "        \"breach_10d\": (k10 <= THRESHOLDS[\"KOSPI_10d_down_pct\"]) if pd.notna(k10) else np.nan,\n",
    "        \"note\": \"í•˜ë½ ë°©í–¥ë§Œ íŠ¸ë¦¬ê±°\",\n",
    "    })\n",
    "\n",
    "# ---- (G) VKOSPI: 1ì¼ +5pp, 10ì¼ +10pp (ìƒìŠ¹ë§Œ) ----\n",
    "if has_data(series_map.get(\"VKOSPI\", pd.Series(dtype=float))):\n",
    "    v1 = pp_change(series_map[\"VKOSPI\"], 1)\n",
    "    v10 = pp_change(series_map[\"VKOSPI\"], 10)\n",
    "    rows.append({\n",
    "        \"metric\": \"VKOSPI (Vol Index)\",\n",
    "        \"ticker\": TICKERS[\"VKOSPI\"],\n",
    "        \"latest\": last_value(series_map[\"VKOSPI\"]),\n",
    "        \"chg_1d\": f\"{v1:.2f}pp\" if pd.notna(v1) else np.nan,\n",
    "        \"threshold_1d\": \"â‰¥ +5.0pp\",\n",
    "        \"breach_1d\": (v1 >= THRESHOLDS[\"VKOSPI_1d_up_pp\"]) if pd.notna(v1) else np.nan,\n",
    "        \"chg_10d\": f\"{v10:.2f}pp\" if pd.notna(v10) else np.nan,\n",
    "        \"threshold_10d\": \"â‰¥ +10.0pp\",\n",
    "        \"breach_10d\": (v10 >= THRESHOLDS[\"VKOSPI_10d_up_pp\"]) if pd.notna(v10) else np.nan,\n",
    "        \"note\": \"ìƒìŠ¹ë§Œ íŠ¸ë¦¬ê±°(pp)\",\n",
    "    })\n",
    "\n",
    "# ---- (H) USDKRW 1Y IV: 1ì¼ Â±5pp, 10ì¼ Â±10pp ----\n",
    "if has_data(series_map.get(\"KRW_IV1Y\", pd.Series(dtype=float))):\n",
    "    iv1 = pp_change(series_map[\"KRW_IV1Y\"], 1)\n",
    "    iv10 = pp_change(series_map[\"KRW_IV1Y\"], 10)\n",
    "    rows.append({\n",
    "        \"metric\": \"USDKRW 1Y Implied Vol\",\n",
    "        \"ticker\": TICKERS[\"KRW_IV1Y\"],\n",
    "        \"latest\": last_value(series_map[\"KRW_IV1Y\"]),\n",
    "        \"chg_1d\": f\"{iv1:.2f}pp\" if pd.notna(iv1) else np.nan,\n",
    "        \"threshold_1d\": \"Â±5.0pp\",\n",
    "        \"breach_1d\": (abs(iv1) >= THRESHOLDS[\"KRWIV_1d_pp\"]) if pd.notna(iv1) else np.nan,\n",
    "        \"chg_10d\": f\"{iv10:.2f}pp\" if pd.notna(iv10) else np.nan,\n",
    "        \"threshold_10d\": \"Â±10.0pp\",\n",
    "        \"breach_10d\": (abs(iv10) >= THRESHOLDS[\"KRWIV_10d_pp\"]) if pd.notna(iv10) else np.nan,\n",
    "        \"note\": \"ì ˆëŒ€ pp ê¸°ì¤€\",\n",
    "    })\n",
    "\n",
    "# ---- (I) ì™¸í™” ì›”í‰ê·  ì¥ë‹¨ê¸°: (SOFR OIS 1Y - TSFR 1M) MTD â‰¥ +150bp ----\n",
    "if has_data(series_map.get(\"SOFR_OIS_1Y\", pd.Series(dtype=float))) and has_data(series_map.get(\"TSFR1M\", pd.Series(dtype=float))):\n",
    "    ois1y_mtd = month_avg(series_map[\"SOFR_OIS_1Y\"], 0)\n",
    "    tsfr1m_mtd = month_avg(series_map[\"TSFR1M\"], 0)\n",
    "    mtd_spread = (ois1y_mtd - tsfr1m_mtd) * 100.0 if pd.notna(ois1y_mtd) and pd.notna(tsfr1m_mtd) else np.nan\n",
    "    rows.append({\n",
    "        \"metric\": \"USD OIS 1Y - TSFR 1M (MTD avg)\",\n",
    "        \"ticker\": f\"{TICKERS['SOFR_OIS_1Y']} vs {TICKERS['TSFR1M']}\",\n",
    "        \"chg_1d\": f\"{mtd_spread:.1f}bp (MTD spread)\" if pd.notna(mtd_spread) else np.nan,\n",
    "        \"threshold_1d\": f\"â‰¥ +{THRESHOLDS['SPREAD_SOFR1M_vs_OIS1Y_MTD_bp']:.0f}bp\",\n",
    "        \"breach_1d\": (mtd_spread >= THRESHOLDS[\"SPREAD_SOFR1M_vs_OIS1Y_MTD_bp\"]) if pd.notna(mtd_spread) else np.nan,\n",
    "        \"note\": f\"MTD OIS1Y={ois1y_mtd:.4f}, TSFR1M={tsfr1m_mtd:.4f}\" if pd.notna(mtd_spread) else \"ë°ì´í„°/í‹±ì»¤ í™•ì¸ í•„ìš”\",\n",
    "    })\n",
    "\n",
    "# ---- (J) KR 1Y - ê¸°ì¤€ê¸ˆë¦¬: 5ì˜ì—…ì¼ ì—°ì† < -24bp ----\n",
    "if has_data(series_map.get(\"KR1Y\", pd.Series(dtype=float))) and has_data(series_map.get(\"KRBASERATE\", pd.Series(dtype=float))):\n",
    "    spr_bp = (series_map[\"KR1Y\"] - series_map[\"KRBASERATE\"]) * 100.0\n",
    "    rows.append({\n",
    "        \"metric\": \"KR 1Y - BaseRate (level)\",\n",
    "        \"ticker\": f\"{TICKERS['KR1Y']} - {TICKERS['KRBASERATE']}\",\n",
    "        \"latest\": float(spr_bp.dropna().iloc[-1]) if spr_bp.dropna().size else np.nan,\n",
    "        \"threshold_1d\": \"5ì˜ì—…ì¼ ì—°ì† < -24bp\",\n",
    "        \"breach_1d\": consec_last_n(spr_bp < THRESHOLDS[\"KR_1Y_minus_BASE_5d_level_bp\"], 5) if spr_bp.dropna().size else np.nan,\n",
    "        \"note\": \"ë ˆë²¨ ê¸°ì¤€(ì¼ë³„ ìŠ¤í”„ë ˆë“œ)\",\n",
    "    })\n",
    "\n",
    "# ---- (K) ê¸°ì¤€ê¸ˆë¦¬ - ì½œê¸ˆë¦¬: > +40bp ----\n",
    "if has_data(series_map.get(\"KRBASERATE\", pd.Series(dtype=float))) and has_data(series_map.get(\"KRCALL\", pd.Series(dtype=float))):\n",
    "    base_call = (series_map[\"KRBASERATE\"] - series_map[\"KRCALL\"]) * 100.0\n",
    "    rows.append({\n",
    "        \"metric\": \"KR Base - Call (level)\",\n",
    "        \"ticker\": f\"{TICKERS['KRBASERATE']} - {TICKERS['KRCALL']}\",\n",
    "        \"latest\": float(base_call.dropna().iloc[-1]) if base_call.dropna().size else np.nan,\n",
    "        \"threshold_1d\": f\"> +{THRESHOLDS['BASE_minus_CALL_bp']:.0f}bp\",\n",
    "        \"breach_1d\": (base_call.dropna().iloc[-1] > THRESHOLDS[\"BASE_minus_CALL_bp\"]) if base_call.dropna().size else np.nan,\n",
    "        \"note\": \"ë ˆë²¨ ê¸°ì¤€\",\n",
    "    })\n",
    "\n",
    "# ---- (L) TSFR 3M: MTD-PrevM ì ˆëŒ€ë³€í™” > 75bp ----\n",
    "if has_data(series_map.get(\"TSFR3M\", pd.Series(dtype=float))):\n",
    "    ts3_cur = month_avg(series_map[\"TSFR3M\"], 0)\n",
    "    ts3_prev = month_avg(series_map[\"TSFR3M\"], 1)\n",
    "    ts3_diff = (ts3_cur - ts3_prev) * 100.0 if pd.notna(ts3_cur) and pd.notna(ts3_prev) else np.nan\n",
    "    rows.append({\n",
    "        \"metric\": \"TSFR 3M (MTD - PrevM)\",\n",
    "        \"ticker\": TICKERS[\"TSFR3M\"],\n",
    "        \"chg_1d\": f\"{ts3_diff:.1f}bp (Î”avg)\" if pd.notna(ts3_diff) else np.nan,\n",
    "        \"threshold_1d\": f\"abs(Î”) > {THRESHOLDS['TSFR3M_prevM_abs_bp']:.0f}bp\",\n",
    "        \"breach_1d\": (abs(ts3_diff) > THRESHOLDS[\"TSFR3M_prevM_abs_bp\"]) if pd.notna(ts3_diff) else np.nan,\n",
    "        \"note\": f\"MTD={ts3_cur:.4f}, PrevM={ts3_prev:.4f}\" if pd.notna(ts3_diff) else \"ë°ì´í„°/í‹±ì»¤ í™•ì¸ í•„ìš”\",\n",
    "    })\n",
    "\n",
    "# ---- (M) JPY 3M TIBOR: MTD-PrevM ì ˆëŒ€ë³€í™” > 25bp ----\n",
    "if has_data(series_map.get(\"JPY_TIBOR3M\", pd.Series(dtype=float))):\n",
    "    tib_cur = month_avg(series_map[\"JPY_TIBOR3M\"], 0)\n",
    "    tib_prev = month_avg(series_map[\"JPY_TIBOR3M\"], 1)\n",
    "    tib_diff = (tib_cur - tib_prev) * 100.0 if pd.notna(tib_cur) and pd.notna(tib_prev) else np.nan\n",
    "    rows.append({\n",
    "        \"metric\": \"JPY TIBOR 3M (MTD - PrevM)\",\n",
    "        \"ticker\": TICKERS[\"JPY_TIBOR3M\"],\n",
    "        \"chg_1d\": f\"{tib_diff:.1f}bp (Î”avg)\" if pd.notna(tib_diff) else np.nan,\n",
    "        \"threshold_1d\": f\"abs(Î”) > {THRESHOLDS['JPY_TIBOR3M_prevM_abs_bp']:.0f}bp\",\n",
    "        \"breach_1d\": (abs(tib_diff) > THRESHOLDS[\"JPY_TIBOR3M_prevM_abs_bp\"]) if pd.notna(tib_diff) else np.nan,\n",
    "        \"note\": f\"MTD={tib_cur:.4f}, PrevM={tib_prev:.4f}\" if pd.notna(tib_diff) else \"ë°ì´í„°/í‹±ì»¤ í™•ì¸ í•„ìš”\",\n",
    "    })\n",
    "\n",
    "# ---- (N) í•œêµ­ 5Y CDS: PrevM +100bp 3D / M-3 +200bp 3D ----\n",
    "if has_data(series_map.get(\"Korea\", pd.Series(dtype=float))):\n",
    "    cds_kr = series_map[\"Korea\"]\n",
    "    prevM_avg = month_avg(cds_kr, 1)\n",
    "    m3_avg = month_avg(cds_kr, 3)\n",
    "\n",
    "    if pd.notna(prevM_avg):\n",
    "        dev_prev = cds_kr - prevM_avg\n",
    "        rows.append({\n",
    "            \"metric\": \"KR 5Y CDS vs PrevM (3D consec)\",\n",
    "            \"ticker\": CDS_TICKERS[\"Korea\"],\n",
    "            \"latest\": last_value(cds_kr),\n",
    "            \"threshold_1d\": f\"> +{THRESHOLDS['KR5YCDS_prevM_bp_3d']:.0f}bp for 3D\",\n",
    "            \"breach_1d\": consec_last_n(dev_prev > THRESHOLDS[\"KR5YCDS_prevM_bp_3d\"], 3),\n",
    "            \"note\": f\"PrevM avg={prevM_avg:.1f}bp\",\n",
    "        })\n",
    "\n",
    "    if pd.notna(m3_avg):\n",
    "        dev_m3 = cds_kr - m3_avg\n",
    "        rows.append({\n",
    "            \"metric\": \"KR 5Y CDS vs M-3 (3D consec)\",\n",
    "            \"ticker\": CDS_TICKERS[\"Korea\"],\n",
    "            \"latest\": last_value(cds_kr),\n",
    "            \"threshold_1d\": f\"> +{THRESHOLDS['KR5YCDS_M3ago_bp_3d']:.0f}bp for 3D\",\n",
    "            \"breach_1d\": consec_last_n(dev_m3 > THRESHOLDS[\"KR5YCDS_M3ago_bp_3d\"], 3),\n",
    "            \"note\": f\"M-3 avg={m3_avg:.1f}bp\",\n",
    "        })\n",
    "\n",
    "# ---- (O) KR Term Spread (10Y-3Y): 5D ì—­ì „ ì§€ì† ----\n",
    "if has_data(series_map.get(\"KR10Y\", pd.Series(dtype=float))) and has_data(series_map.get(\"KR3Y\", pd.Series(dtype=float))):\n",
    "    term_spread = (series_map[\"KR10Y\"] - series_map[\"KR3Y\"]) * 100.0\n",
    "    rows.append({\n",
    "        \"metric\": \"KR Term Spread 10Y-3Y (5D inversion)\",\n",
    "        \"ticker\": f\"{TICKERS['KR10Y']} - {TICKERS['KR3Y']}\",\n",
    "        \"latest\": float(term_spread.dropna().iloc[-1]) if term_spread.dropna().size else np.nan,\n",
    "        \"threshold_1d\": \"< 0bp for 5D\",\n",
    "        \"breach_1d\": consec_last_n(term_spread <= 0.0, THRESHOLDS[\"KR_10Y_3Y_inversion_5d\"]) if term_spread.dropna().size else np.nan,\n",
    "        \"note\": \"10Y-3Y â‰¤ 0bp ìƒíƒœ 5D ì—°ì†\",\n",
    "    })\n",
    "\n",
    "# ---- (P) êµ­ê°€ë³„ CDS 17ê°œêµ­: ì „ì›” í‰ê·  ëŒ€ë¹„ +30% ìƒìŠ¹ ----\n",
    "for country, bb in CDS_TICKERS.items():\n",
    "    if country == \"Korea\":\n",
    "        continue  # í•œêµ­ì€ ìœ„ì—ì„œ bp ê¸°ì¤€ 3D ì—°ì† ë¡œì§ ì ìš©\n",
    "    s = series_map.get(country, pd.Series(dtype=float))\n",
    "    if has_data(s):\n",
    "        mtd, prev = month_avg(s, 0), month_avg(s, 1)\n",
    "        pct_up = ((mtd / prev - 1.0) * 100.0) if (pd.notna(mtd) and pd.notna(prev) and prev != 0) else np.nan\n",
    "        rows.append({\n",
    "            \"metric\": f\"CDS 5Y: {country} (MTD vs PrevM)\",\n",
    "            \"ticker\": bb,\n",
    "            \"latest\": last_value(s),\n",
    "            \"chg_1d\": f\"{pct_up:.1f}%\" if pd.notna(pct_up) else np.nan,\n",
    "            \"threshold_1d\": f\"> +{THRESHOLDS['CDS_prevM_pct_up']:.0f}%\",\n",
    "            \"breach_1d\": (pct_up > THRESHOLDS[\"CDS_prevM_pct_up\"]) if pd.notna(pct_up) else np.nan,\n",
    "            \"note\": f\"MTD={mtd:.1f}, PrevM={prev:.1f}\" if pd.notna(pct_up) else \"ë°ì´í„°/í‹±ì»¤ í™•ì¸ í•„ìš”\",\n",
    "        })\n",
    "\n",
    "# ---- (Q) (íšŒì‚¬ì±„/êµ­ê³ ) 3Y ë¹„ìœ¨: ì „ì›”í‰ê·  ëŒ€ë¹„ +16% ìƒìŠ¹ ----\n",
    "if has_data(series_map.get(\"KR3Y\", pd.Series(dtype=float))) and has_data(series_map.get(\"KR_CORP3Y_AA-\", pd.Series(dtype=float))):\n",
    "    ktb3y_mtd  = month_avg(series_map[\"KR3Y\"], 0)\n",
    "    corp3y_mtd = month_avg(series_map[\"KR_CORP3Y_AA-\"], 0)\n",
    "    ktb3y_prev  = month_avg(series_map[\"KR3Y\"], 1)\n",
    "    corp3y_prev = month_avg(series_map[\"KR_CORP3Y_AA-\"], 1)\n",
    "\n",
    "    ratio_cur  = (ktb3y_mtd / corp3y_mtd) if (pd.notna(ktb3y_mtd) and pd.notna(corp3y_mtd) and corp3y_mtd != 0) else np.nan\n",
    "    ratio_prev = (ktb3y_prev / corp3y_prev) if (pd.notna(ktb3y_prev) and pd.notna(corp3y_prev) and corp3y_prev != 0) else np.nan\n",
    "    ratio_pct  = ((ratio_cur / ratio_prev - 1.0) * 100.0) if (pd.notna(ratio_cur) and pd.notna(ratio_prev) and ratio_prev != 0) else np.nan\n",
    "\n",
    "    rows.append({\n",
    "        \"metric\": \"KTB3Y / Corp(AA-) 3Y (MTD vs PrevM)\",\n",
    "        \"ticker\": \"KR3Y / KR_CORP3Y_AA-\",\n",
    "        \"chg_1d\": f\"{ratio_pct:.1f}%\" if pd.notna(ratio_pct) else np.nan,\n",
    "        \"threshold_1d\": f\"> +{THRESHOLDS['CorpAAminus_KTB3Y_ratio_prevM_pct']:.0f}%\",\n",
    "        \"breach_1d\": (ratio_pct > THRESHOLDS[\"CorpAAminus_KTB3Y_ratio_prevM_pct\"]) if pd.notna(ratio_pct) else np.nan,\n",
    "        \"note\": f\"MTD={ratio_cur:.4f}, PrevM={ratio_prev:.4f}\" if pd.notna(ratio_pct) else \"ë°ì´í„°/í‹±ì»¤ í™•ì¸ í•„ìš”\",\n",
    "    })\n",
    "\n",
    "# ---- (R) ì›”í‰ê·  ì¥ë‹¨ê¸° (ê¸ˆìœµì±„1Y - CD3M): MTD ìŠ¤í”„ë ˆë“œ â‰¥ +70bp ----\n",
    "if has_data(series_map.get(\"KR_FIN1Y_AAA\", pd.Series(dtype=float))) and has_data(series_map.get(\"KR_CD3M\", pd.Series(dtype=float))):\n",
    "    fin1y_mtd = month_avg(series_map[\"KR_FIN1Y_AAA\"], 0)\n",
    "    cd3m_mtd  = month_avg(series_map[\"KR_CD3M\"], 0)\n",
    "    fin_cd_bp = (fin1y_mtd - cd3m_mtd) * 100.0 if pd.notna(fin1y_mtd) and pd.notna(cd3m_mtd) else np.nan\n",
    "    rows.append({\n",
    "        \"metric\": \"(MTD) Fin 1Y - CD 3M\",\n",
    "        \"ticker\": f\"{TICKERS['KR_FIN1Y_AAA']} - {TICKERS['KR_CD3M']}\",\n",
    "        \"chg_1d\": f\"{fin_cd_bp:.1f}bp\" if pd.notna(fin_cd_bp) else np.nan,\n",
    "        \"threshold_1d\": f\"â‰¥ +{THRESHOLDS['Fin1Y_minus_CD3M_MTD_bp']:.0f}bp\",\n",
    "        \"breach_1d\": (fin_cd_bp >= THRESHOLDS[\"Fin1Y_minus_CD3M_MTD_bp\"]) if pd.notna(fin_cd_bp) else np.nan,\n",
    "        \"note\": f\"MTD Fin1Y={fin1y_mtd:.4f}, CD3M={cd3m_mtd:.4f}\" if pd.notna(fin_cd_bp) else \"ë°ì´í„°/í‹±ì»¤ í™•ì¸ í•„ìš”\",\n",
    "    })\n",
    "\n",
    "# ---- (S) Fin1Y AAA - KTB1Y: 5ì˜ì—…ì¼ ì—°ì† â‰¥ +50bp ----\n",
    "if has_data(series_map.get(\"KR_FIN1Y_AAA\", pd.Series(dtype=float))) and has_data(series_map.get(\"KR1Y\", pd.Series(dtype=float))):\n",
    "    fin_minus_ktb1y = (series_map[\"KR_FIN1Y_AAA\"] - series_map[\"KR1Y\"]) * 100.0\n",
    "    rows.append({\n",
    "        \"metric\": \"Fin 1Y(AAA) - KTB 1Y (5D consec â‰¥50bp)\",\n",
    "        \"ticker\": f\"{TICKERS['KR_FIN1Y_AAA']} - {TICKERS['KR1Y']}\",\n",
    "        \"latest\": float(fin_minus_ktb1y.dropna().iloc[-1]) if fin_minus_ktb1y.dropna().size else np.nan,\n",
    "        \"threshold_1d\": f\"â‰¥ +{THRESHOLDS['Fin1YAAA_minus_KTB1Y_5d_bp']:.0f}bp for 5D\",\n",
    "        \"breach_1d\": consec_last_n(fin_minus_ktb1y >= THRESHOLDS[\"Fin1YAAA_minus_KTB1Y_5d_bp\"], 5) if fin_minus_ktb1y.dropna().size else np.nan,\n",
    "        \"note\": \"ë ˆë²¨ ê¸°ì¤€(ì¼ë³„ ìŠ¤í”„ë ˆë“œ)\",\n",
    "    })\n",
    "\n",
    "# ---- (T) S&P 500: 1ì¼ â‰¤ -3%, 10ì¼ â‰¤ -12% ----\n",
    "if has_data(series_map.get(\"SPX\", pd.Series(dtype=float))):\n",
    "    spx_1d = pct_change(series_map[\"SPX\"], 1)\n",
    "    spx_10d = pct_change(series_map[\"SPX\"], 10)\n",
    "    rows.append({\n",
    "        \"metric\": \"S&P 500\",\n",
    "        \"ticker\": TICKERS[\"SPX\"],\n",
    "        \"latest\": last_value(series_map[\"SPX\"]),\n",
    "        \"chg_1d\": f\"{spx_1d:.2f}%\" if pd.notna(spx_1d) else np.nan,\n",
    "        \"threshold_1d\": \"â‰¤ -3.0%\",\n",
    "        \"breach_1d\": (spx_1d <= THRESHOLDS[\"SPX_1d_down_pct\"]) if pd.notna(spx_1d) else np.nan,\n",
    "        \"chg_10d\": f\"{spx_10d:.2f}%\" if pd.notna(spx_10d) else np.nan,\n",
    "        \"threshold_10d\": \"â‰¤ -12.0%\",\n",
    "        \"breach_10d\": (spx_10d <= THRESHOLDS[\"SPX_10d_down_pct\"]) if pd.notna(spx_10d) else np.nan,\n",
    "        \"note\": \"í•˜ë½ë§Œ íŠ¸ë¦¬ê±°\",\n",
    "    })\n",
    "\n",
    "# ---- (U) EuroStoxx50: 1ì¼ |Î”| â‰¥ 3%, 10ì¼ â‰¤ -12% ----\n",
    "if has_data(series_map.get(\"SX5E\", pd.Series(dtype=float))):\n",
    "    sx_1d = pct_change(series_map[\"SX5E\"], 1)\n",
    "    sx_10d = pct_change(series_map[\"SX5E\"], 10)\n",
    "    rows.append({\n",
    "        \"metric\": \"EuroStoxx50\",\n",
    "        \"ticker\": TICKERS[\"SX5E\"],\n",
    "        \"latest\": last_value(series_map[\"SX5E\"]),\n",
    "        \"chg_1d\": f\"{sx_1d:.2f}%\" if pd.notna(sx_1d) else np.nan,\n",
    "        \"threshold_1d\": f\"abs â‰¥ {THRESHOLDS['SX5E_1d_abs_pct']:.1f}%\",\n",
    "        \"breach_1d\": (abs(sx_1d) >= THRESHOLDS[\"SX5E_1d_abs_pct\"]) if pd.notna(sx_1d) else np.nan,\n",
    "        \"chg_10d\": f\"{sx_10d:.2f}%\" if pd.notna(sx_10d) else np.nan,\n",
    "        \"threshold_10d\": \"â‰¤ -12.0%\",\n",
    "        \"breach_10d\": (sx_10d <= THRESHOLDS[\"SX5E_10d_down_pct\"]) if pd.notna(sx_10d) else np.nan,\n",
    "        \"note\": \"1DëŠ” ì ˆëŒ€ê°’, 10DëŠ” í•˜ë½ë§Œ\",\n",
    "    })\n",
    "\n",
    "# ---- (V) 3M FRA-OIS: PrevM ëŒ€ë¹„ +30bp ----\n",
    "if has_data(series_map.get(\"US_FRAOIS_3M\", pd.Series(dtype=float))):\n",
    "    fraois_mtd  = month_avg(series_map[\"US_FRAOIS_3M\"], 0)\n",
    "    fraois_prev = month_avg(series_map[\"US_FRAOIS_3M\"], 1)\n",
    "    diff_bp = (fraois_mtd - fraois_prev) * 100.0 if pd.notna(fraois_mtd) and pd.notna(fraois_prev) else np.nan\n",
    "    rows.append({\n",
    "        \"metric\": \"USD 3M FRA-OIS (MTD - PrevM)\",\n",
    "        \"ticker\": TICKERS[\"US_FRAOIS_3M\"],\n",
    "        \"chg_1d\": f\"{diff_bp:.1f}bp (Î”avg)\" if pd.notna(diff_bp) else np.nan,\n",
    "        \"threshold_1d\": f\"> +{THRESHOLDS['FRAOIS_prevM_bp']:.0f}bp\",\n",
    "        \"breach_1d\": (diff_bp > THRESHOLDS[\"FRAOIS_prevM_bp\"]) if pd.notna(diff_bp) else np.nan,\n",
    "        \"note\": f\"MTD={fraois_mtd:.2f}, PrevM={fraois_prev:.2f}\" if pd.notna(diff_bp) else \"ë°ì´í„°/í‹±ì»¤ í™•ì¸ í•„ìš”\",\n",
    "    })\n",
    "\n",
    "# -----------------------------\n",
    "# 7) ì—‘ì…€ ì €ì¥ (alerts + raw_data)\n",
    "# -----------------------------\n",
    "alerts_df = pd.DataFrame(rows)\n",
    "\n",
    "order_cols = [\n",
    "    \"metric\",\"ticker\",\"latest\",\n",
    "    \"chg_1d\",\"threshold_1d\",\"breach_1d\",\n",
    "    \"chg_10d\",\"threshold_10d\",\"breach_10d\",\n",
    "    \"breach_3m\",\"note\",\n",
    "]\n",
    "for c in order_cols:\n",
    "    if c not in alerts_df.columns:\n",
    "        alerts_df[c] = np.nan\n",
    "\n",
    "alerts_df = alerts_df[order_cols]\n",
    "\n",
    "with pd.ExcelWriter(output_path, engine=\"openpyxl\") as writer:\n",
    "    alerts_df.to_excel(writer, sheet_name=\"alerts\", index=False)\n",
    "    raw_df = hist.copy()\n",
    "    raw_df.index.name = \"Date\"\n",
    "    raw_df.reset_index().to_excel(writer, sheet_name=\"raw_data\", index=False)\n",
    "\n",
    "print(f\"âœ… ì €ì¥ ì™„ë£Œ: {output_path}\")\n",
    "print(\"â–¶ alerts ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 20í–‰):\")\n",
    "print(alerts_df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "843b815c-0933-47cc-84e0-41d67c16afc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–¶ ì„ê³„ì¹˜ íŒŒì¼: C:\\Users\\amongpapa\\chartup\\raw_data\\risk_thresholds_20251122.xlsx\n",
      "â–¶ ì„ê³„ì¹˜ ì´ˆê³¼ ì§€í‘œ ìˆ˜: 2\n",
      "â–¶ ì „ì†¡ ë©”ì‹œì§€ ë¯¸ë¦¬ë³´ê¸°:\n",
      "============================================================\n",
      "[ë¦¬ìŠ¤í¬ ì„ê³„ì¹˜ ì´ˆê³¼ ì•Œë¦¼]\n",
      "2025-11-22 ê¸°ì¤€\n",
      "\n",
      "â€¢ KOSPI Index (KOSPI Index)\n",
      "   - 1ì¼ ë³€í™”: -3.79% (ê¸°ì¤€ â‰¤ -3.5%)\n",
      "   - 3ê°œì›”/í‰ê·  ê¸°ì¤€ ì´ˆê³¼: í•˜ë½ ë°©í–¥ë§Œ íŠ¸ë¦¬ê±°\n",
      "   - í˜„ì¬ ìˆ˜ì¤€: 3853.26\n",
      "\n",
      "â€¢ VKOSPI (Vol Index) (VKOSPI Index)\n",
      "   - 1ì¼ ë³€í™”: 5.10pp (ê¸°ì¤€ â‰¥ +5.0pp)\n",
      "   - 3ê°œì›”/í‰ê·  ê¸°ì¤€ ì´ˆê³¼: ìƒìŠ¹ë§Œ íŠ¸ë¦¬ê±°(pp)\n",
      "   - í˜„ì¬ ìˆ˜ì¤€: 41.38\n",
      "\n",
      "\n",
      "ìì„¸í•œ ì§€í‘œëŠ” ë‚´ë¶€ ëŒ€ì‹œë³´ë“œì—ì„œ í™•ì¸í•´ì£¼ì„¸ìš”.\n",
      "https://chartupndown.com/risk_monitor\n",
      "============================================================\n",
      "âœ… í…”ë ˆê·¸ë¨ ì „ì†¡ ì„±ê³µ\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "ë¦¬ìŠ¤í¬ ì„ê³„ì¹˜ ì´ˆê³¼ ë‚´ì—­ í…”ë ˆê·¸ë¨ ì „ì†¡ ìŠ¤í¬ë¦½íŠ¸\n",
    "\n",
    "ëª©ì :\n",
    "- ê¸°ì¡´ 'risk_thresholds_YYYYMMDD.xlsx' (alerts ì‹œíŠ¸)ë¥¼ ì½ì–´ì„œ\n",
    "- breach_1d / breach_10d / breach_3m ì¤‘ í•˜ë‚˜ë¼ë„ Trueì¸ í•­ëª©ë§Œ ê³¨ë¼\n",
    "- í…”ë ˆê·¸ë¨ìœ¼ë¡œ ìš”ì•½ ë©”ì‹œì§€ë¥¼ ì „ì†¡í•˜ê³ , ë§ˆì§€ë§‰ ì¤„ì— ëŒ€ì‹œë³´ë“œ ë§í¬ë¥¼ ì¶”ê°€í•œë‹¤.\n",
    "\n",
    "ì „ì œ:\n",
    "- ì•ì„œ íŒ€ì¥ë‹˜ì´ ì‹¤í–‰í•˜ì‹  Bloomberg/xbbg ìŠ¤í¬ë¦½íŠ¸ì™€ ë™ì¼í•œ ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ\n",
    "  risk_thresholds_YYYYMMDD.xlsx íŒŒì¼ì´ ìƒì„±ë˜ì–´ ìˆì–´ì•¼ í•œë‹¤.\n",
    "- í…”ë ˆê·¸ë¨ ë´‡ í† í°ê³¼ ì±„ë„/ì±„íŒ… ID ê°€ ì¤€ë¹„ë˜ì–´ ìˆì–´ì•¼ í•œë‹¤.\n",
    "\n",
    "í•„ìš” íŒ¨í‚¤ì§€:\n",
    "    pip install pandas requests openpyxl\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "# ==========================\n",
    "# 1. í…”ë ˆê·¸ë¨ ì„¤ì •ê°’\n",
    "# ==========================\n",
    "BOT_TOKEN = \"8432426313:AAEdvkoFEozZE-1F0ARc82i_JXCWA4fPfgE\"  # íŒ€ì¥ë‹˜ ë´‡ í† í°\n",
    "CHAT_ID   = \"-4956067497\"                                     # íŒ€ì¥ë‹˜ ì±„ë„/ì±„íŒ… ID\n",
    "\n",
    "TELEGRAM_API_URL = f\"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage\"\n",
    "\n",
    "# ==========================\n",
    "# 2. íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
    "# ==========================\n",
    "# - risk_thresholds_YYYYMMDD.xlsx ê°€ ì €ì¥ëœ í´ë”\n",
    "OUTPUT_DIR = Path(r\"C:/Users/amongpapa/chartup/raw_data\")\n",
    "\n",
    "# - ê¸°ë³¸ì€ \"ì˜¤ëŠ˜ ë‚ ì§œ\" íŒŒì¼ì„ ì°¾ë„ë¡ êµ¬ì„±\n",
    "#   (í•„ìš”í•˜ë©´ mainì—ì„œ execution_dateë¥¼ ì¸ìë¡œ ë°›ë„ë¡ í™•ì¥í•´ë„ ë¨)\n",
    "def get_risk_excel_path(target_date: date | None = None) -> Path:\n",
    "    \"\"\"\n",
    "    ëŒ€ìƒ ë‚ ì§œì˜ risk_thresholds_YYYYMMDD.xlsx ê²½ë¡œë¥¼ ë°˜í™˜í•˜ëŠ” í—¬í¼ í•¨ìˆ˜.\n",
    "    target_dateë¥¼ ë„˜ê¸°ì§€ ì•Šìœ¼ë©´ ì˜¤ëŠ˜ ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ íŒŒì¼ëª…ì„ ë§Œë“ ë‹¤.\n",
    "    \"\"\"\n",
    "    if target_date is None:\n",
    "        target_date = date.today()\n",
    "    fname = f\"risk_thresholds_{target_date:%Y%m%d}.xlsx\"\n",
    "    return OUTPUT_DIR / fname\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# 3. ì—‘ì…€ì—ì„œ breach í•­ëª© ì¶”ì¶œ\n",
    "# ==========================\n",
    "def load_breach_rows(excel_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    risk_thresholds ì—‘ì…€ íŒŒì¼ì—ì„œ alerts ì‹œíŠ¸ë¥¼ ì½ê³ ,\n",
    "    breach_1d / breach_10d / breach_3m ì¤‘ í•˜ë‚˜ë¼ë„ Trueì¸ í–‰ë§Œ í•„í„°ë§í•´ì„œ ë°˜í™˜.\n",
    "\n",
    "    ë°˜í™˜:\n",
    "        breach_df (DataFrame): breach í–‰ë§Œ ëª¨ì€ ìš”ì•½ í…Œì´ë¸”\n",
    "    \"\"\"\n",
    "    if not excel_path.exists():\n",
    "        raise FileNotFoundError(f\"ì„ê³„ì¹˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {excel_path}\")\n",
    "\n",
    "    # alerts ì‹œíŠ¸ ì½ê¸°\n",
    "    df = pd.read_excel(excel_path, sheet_name=\"alerts\")\n",
    "\n",
    "    # breach ì»¬ëŸ¼ë“¤ë§Œ ìë™ íƒìƒ‰ (breachë¡œ ì‹œì‘í•˜ëŠ” ëª¨ë“  ì»¬ëŸ¼)\n",
    "    breach_cols = [c for c in df.columns if c.startswith(\"breach\")]\n",
    "    if not breach_cols:\n",
    "        # breach ì»¬ëŸ¼ì´ ì•„ì˜ˆ ì—†ìœ¼ë©´ ë¹ˆ DF ë°˜í™˜\n",
    "        return df.iloc[0:0].copy()\n",
    "\n",
    "    # NaN â†’ False ë¡œ ì±„ìš°ê³  í–‰ ë‹¨ìœ„ë¡œ OR ì¡°ê±´\n",
    "    mask = df[breach_cols].fillna(False).any(axis=1)\n",
    "    breach_df = df.loc[mask].copy()\n",
    "\n",
    "    return breach_df\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# 4. í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ í…ìŠ¤íŠ¸ êµ¬ì„±\n",
    "# ==========================\n",
    "def format_value(x) -> str:\n",
    "    \"\"\"\n",
    "    NaN, None ì€ ë¹ˆ ë¬¸ìì—´ë¡œ ì²˜ë¦¬í•˜ê³ , ë‚˜ë¨¸ì§€ëŠ” ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ëŠ” ë‹¨ìˆœ í—¬í¼.\n",
    "    \"\"\"\n",
    "    if pd.isna(x):\n",
    "        return \"\"\n",
    "    return str(x)\n",
    "\n",
    "\n",
    "def build_message_from_breach_df(breach_df: pd.DataFrame, target_date: date) -> str:\n",
    "    \"\"\"\n",
    "    breach_dfë¥¼ ê¸°ë°˜ìœ¼ë¡œ í…”ë ˆê·¸ë¨ì— ë³´ë‚¼ ë©”ì‹œì§€ ë³¸ë¬¸ì„ êµ¬ì„±í•œë‹¤.\n",
    "\n",
    "    ê·œì¹™:\n",
    "    - í—¤ë”: ë‚ ì§œ + ì œëª©\n",
    "    - ê° í•­ëª©:\n",
    "        * metric (ì§€í‘œ ì´ë¦„)\n",
    "        * (í•„ìš” ì‹œ) latest ê°’\n",
    "        * breach_1d / breach_10d / breach_3m ì¤‘ Trueì¸ ê²ƒë§Œ ê³¨ë¼ì„œ\n",
    "          ë³€í™”ëŸ‰ + ê¸°ì¤€ì„ í•œ ì¤„ì”© bullet ë¡œ í‘œì‹œ\n",
    "        * noteê°€ ìˆìœ¼ë©´ ë§ˆì§€ë§‰ì— ê´„í˜¸ë¡œ ì¶”ê°€\n",
    "    - ë§ˆì§€ë§‰ ì¤„ì— risk_monitor ë§í¬ ì¶”ê°€\n",
    "    \"\"\"\n",
    "    header_lines = [\n",
    "        f\"[ë¦¬ìŠ¤í¬ ì„ê³„ì¹˜ ì´ˆê³¼ ì•Œë¦¼]\",\n",
    "        f\"{target_date:%Y-%m-%d} ê¸°ì¤€\",\n",
    "        \"\",\n",
    "    ]\n",
    "\n",
    "    body_lines: list[str] = []\n",
    "\n",
    "    if breach_df.empty:\n",
    "        # ì„ê³„ì¹˜ ì´ˆê³¼ í•­ëª©ì´ ì—†ì„ ë•Œ\n",
    "        body_lines.append(\"ì˜¤ëŠ˜ì€ ì„¤ì •ëœ ì„ê³„ìˆ˜ì¤€ì„ ì´ˆê³¼í•œ ì§€í‘œê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    else:\n",
    "        # ê° í–‰ë³„ë¡œ í…ìŠ¤íŠ¸ ì •ë¦¬\n",
    "        for idx, row in breach_df.iterrows():\n",
    "            metric = format_value(row.get(\"metric\", \"\"))\n",
    "            ticker = format_value(row.get(\"ticker\", \"\"))\n",
    "            latest = row.get(\"latest\", np.nan)\n",
    "            latest_str = format_value(latest)\n",
    "\n",
    "            line_header = f\"â€¢ {metric}\"\n",
    "            if ticker:\n",
    "                line_header += f\" ({ticker})\"\n",
    "            body_lines.append(line_header)\n",
    "\n",
    "            # ì–´ë–¤ breachê°€ ë°œìƒí–ˆëŠ”ì§€ ì •ë¦¬\n",
    "            # 1ì¼\n",
    "            if bool(row.get(\"breach_1d\", False)):\n",
    "                chg_1d = format_value(row.get(\"chg_1d\", \"\"))\n",
    "                th_1d  = format_value(row.get(\"threshold_1d\", \"\"))\n",
    "                body_lines.append(f\"   - 1ì¼ ë³€í™”: {chg_1d} (ê¸°ì¤€ {th_1d})\")\n",
    "\n",
    "            # 10ì¼\n",
    "            if bool(row.get(\"breach_10d\", False)):\n",
    "                chg_10d = format_value(row.get(\"chg_10d\", \"\"))\n",
    "                th_10d  = format_value(row.get(\"threshold_10d\", \"\"))\n",
    "                body_lines.append(f\"   - 10ì¼ ë³€í™”: {chg_10d} (ê¸°ì¤€ {th_10d})\")\n",
    "\n",
    "            # 3ê°œì›”/ê¸°íƒ€ ê¸°ì¤€ (breach_3m ì»¬ëŸ¼)\n",
    "            if bool(row.get(\"breach_3m\", False)):\n",
    "                note = format_value(row.get(\"note\", \"\"))\n",
    "                if note:\n",
    "                    body_lines.append(f\"   - 3ê°œì›”/í‰ê·  ê¸°ì¤€ ì´ˆê³¼: {note}\")\n",
    "                else:\n",
    "                    body_lines.append(f\"   - 3ê°œì›”/í‰ê·  ê¸°ì¤€ ì´ˆê³¼\")\n",
    "\n",
    "            # latest ê°’ì´ ì˜ë¯¸ ìˆì„ ê²½ìš° í•œ ì¤„ ì¶”ê°€ (ì›ì¹˜ ì•Šìœ¼ë©´ ì£¼ì„ ì²˜ë¦¬ ê°€ëŠ¥)\n",
    "            if latest_str:\n",
    "                body_lines.append(f\"   - í˜„ì¬ ìˆ˜ì¤€: {latest_str}\")\n",
    "\n",
    "            # í•­ëª© ê°„ êµ¬ë¶„ìš© ë¹ˆ ì¤„\n",
    "            body_lines.append(\"\")\n",
    "\n",
    "    # footer: ë§í¬ ì¶”ê°€\n",
    "    footer_lines = [\n",
    "        \"\",\n",
    "        \"ìì„¸í•œ ì§€í‘œëŠ” ë‚´ë¶€ ëŒ€ì‹œë³´ë“œì—ì„œ í™•ì¸í•´ì£¼ì„¸ìš”.\",\n",
    "        \"https://chartupndown.com/risk_monitor\",\n",
    "    ]\n",
    "\n",
    "    # ì „ì²´ ë©”ì‹œì§€ í•©ì¹˜ê¸°\n",
    "    full_message = \"\\n\".join(header_lines + body_lines + footer_lines)\n",
    "    return full_message\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# 5. í…”ë ˆê·¸ë¨ ì „ì†¡ í•¨ìˆ˜\n",
    "# ==========================\n",
    "def send_telegram_message(text: str) -> None:\n",
    "    \"\"\"\n",
    "    í…”ë ˆê·¸ë¨ sendMessage APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì§€ì •ëœ CHAT_IDë¡œ ë©”ì‹œì§€ë¥¼ ì „ì†¡í•œë‹¤.\n",
    "    \"\"\"\n",
    "    payload = {\n",
    "        \"chat_id\": CHAT_ID,\n",
    "        \"text\": text,\n",
    "        \"parse_mode\": \"HTML\",  # í•„ìš”ì‹œ Markdown ìœ¼ë¡œ ë³€ê²½ ê°€ëŠ¥\n",
    "    }\n",
    "    try:\n",
    "        resp = requests.post(TELEGRAM_API_URL, data=payload, timeout=10)\n",
    "        resp.raise_for_status()\n",
    "        print(\"âœ… í…”ë ˆê·¸ë¨ ì „ì†¡ ì„±ê³µ\")\n",
    "    except requests.RequestException as e:\n",
    "        print(\"âš ï¸ í…”ë ˆê·¸ë¨ ì „ì†¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:\", e)\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# 6. ë©”ì¸ ì‹¤í–‰ íë¦„\n",
    "# ==========================\n",
    "def send_risk_alert_via_telegram(target_date: date | None = None) -> None:\n",
    "    \"\"\"\n",
    "    í†µí•© ì‹¤í–‰ í•¨ìˆ˜:\n",
    "    1) ëŒ€ìƒ ë‚ ì§œì˜ risk_thresholds ì—‘ì…€ ê²½ë¡œ ê³„ì‚°\n",
    "    2) breach í–‰ë§Œ í•„í„°ë§\n",
    "    3) í…ìŠ¤íŠ¸ ë©”ì‹œì§€ êµ¬ì„±\n",
    "    4) í…”ë ˆê·¸ë¨ ì „ì†¡\n",
    "    \"\"\"\n",
    "    if target_date is None:\n",
    "        target_date = date.today()\n",
    "\n",
    "    excel_path = get_risk_excel_path(target_date)\n",
    "    print(f\"â–¶ ì„ê³„ì¹˜ íŒŒì¼: {excel_path}\")\n",
    "\n",
    "    breach_df = load_breach_rows(excel_path)\n",
    "    print(f\"â–¶ ì„ê³„ì¹˜ ì´ˆê³¼ ì§€í‘œ ìˆ˜: {len(breach_df)}\")\n",
    "\n",
    "    msg = build_message_from_breach_df(breach_df, target_date)\n",
    "    print(\"â–¶ ì „ì†¡ ë©”ì‹œì§€ ë¯¸ë¦¬ë³´ê¸°:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(msg)\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # ì‹¤ì œ í…”ë ˆê·¸ë¨ ì „ì†¡\n",
    "    send_telegram_message(msg)\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# 7. ì§ì ‘ ì‹¤í–‰ ì‹œ ì§„ì…ì \n",
    "# ==========================\n",
    "if __name__ == \"__main__\":\n",
    "    # ê¸°ë³¸ì€ ì˜¤ëŠ˜ ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ë™ì‘\n",
    "    send_risk_alert_via_telegram()\n",
    "\n",
    "    # íŠ¹ì • ë‚ ì§œ íŒŒì¼ì„ ë³´ë‚´ê³  ì‹¶ìœ¼ë©´ ì˜ˆì‹œì²˜ëŸ¼ í˜¸ì¶œ\n",
    "    # from datetime import datetime\n",
    "    # send_risk_alert_via_telegram(datetime(2025, 11, 17).date())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e2bbb1b-c2fa-4b0d-a0a0-fbc427a56c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/114] ì¡°íšŒ ì‹œì‘ â–¶ IND001 (BDIY Index)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND001.xlsx\n",
      "[2/114] ì¡°íšŒ ì‹œì‘ â–¶ IND002 (BIZD US Equity)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND002.xlsx\n",
      "[3/114] ì¡°íšŒ ì‹œì‘ â–¶ IND003 (BKX Index)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND003.xlsx\n",
      "[4/114] ì¡°íšŒ ì‹œì‘ â–¶ IND004 (BOFA CDS USD SR 5Y D14 Curncy)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND004.xlsx\n",
      "[5/114] ì¡°íšŒ ì‹œì‘ â–¶ IND005 (CBRZ1U5 CBIN Curncy)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND005.xlsx\n",
      "[6/114] ì¡°íšŒ ì‹œì‘ â–¶ IND006 (CDX HY CDSI GEN 5Y Corp)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND006.xlsx\n",
      "[7/114] ì¡°íšŒ ì‹œì‘ â–¶ IND007 (CDX HY CDSI GEN 5Y SPRD Corp)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND007.xlsx\n",
      "[8/114] ì¡°íšŒ ì‹œì‘ â–¶ IND009 (CFIN1U5 CBIN Curncy)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND009.xlsx\n",
      "[9/114] ì¡°íšŒ ì‹œì‘ â–¶ IND010 (CFRTR1U5 CBIN Curncy)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND010.xlsx\n",
      "[10/114] ì¡°íšŒ ì‹œì‘ â–¶ IND011 (CHEFTYOY Index)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND011.xlsx\n",
      "[11/114] ì¡°íšŒ ì‹œì‘ â–¶ IND012 (CHRXCINY Index)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND012.xlsx\n",
      "[12/114] ì¡°íšŒ ì‹œì‘ â–¶ IND013 (CHVAIOY Index)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND013.xlsx\n",
      "[13/114] ì¡°íšŒ ì‹œì‘ â–¶ IND014 (CINC CDS USD SR 5Y D14 Curncy)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND014.xlsx\n",
      "[14/114] ì¡°íšŒ ì‹œì‘ â–¶ IND015 (CITLY1U5 CBIN Curncy)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND015.xlsx\n",
      "[15/114] ì¡°íšŒ ì‹œì‘ â–¶ IND016 (CL1 Comdty)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND016.xlsx\n",
      "[16/114] ì¡°íšŒ ì‹œì‘ â–¶ IND017 (CNGDPYOY Index)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND017.xlsx\n",
      "[17/114] ì¡°íšŒ ì‹œì‘ â–¶ IND018 (CNH BGN Curncy)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND018.xlsx\n",
      "[18/114] ì¡°íšŒ ì‹œì‘ â–¶ IND019 (CNH Curncy)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND019.xlsx\n",
      "[19/114] ì¡°íšŒ ì‹œì‘ â–¶ IND020 (CO1 Comdty)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND020.xlsx\n",
      "[20/114] ì¡°íšŒ ì‹œì‘ â–¶ IND021 (CONCCONF Index)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND021.xlsx\n",
      "[21/114] ì¡°íšŒ ì‹œì‘ â–¶ IND022 (CTURK1U5 CBIN Curncy)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND022.xlsx\n",
      "[22/114] ì¡°íšŒ ì‹œì‘ â–¶ IND023 (DXY Curncy)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND023.xlsx\n",
      "[23/114] ì¡°íšŒ ì‹œì‘ â–¶ IND024 (EMB US Equity)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND024.xlsx\n",
      "[24/114] ì¡°íšŒ ì‹œì‘ â–¶ IND025 (EPUCNUSD Index)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND025.xlsx\n",
      "[25/114] ì¡°íšŒ ì‹œì‘ â–¶ IND026 (EUA Comdty)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND026.xlsx\n",
      "[26/114] ì¡°íšŒ ì‹œì‘ â–¶ IND028 (EURUSD BGN Curncy)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND028.xlsx\n",
      "[27/114] ì¡°íšŒ ì‹œì‘ â–¶ IND029 (EURUSD Curncy)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND029.xlsx\n",
      "[28/114] ì¡°íšŒ ì‹œì‘ â–¶ IND030 (EWT US Equity)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND030.xlsx\n",
      "[29/114] ì¡°íšŒ ì‹œì‘ â–¶ IND031 (FDTR Index)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND031.xlsx\n",
      "[30/114] ì¡°íšŒ ì‹œì‘ â–¶ IND034 (GBTP10YR Index)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND034.xlsx\n",
      "[31/114] ì¡°íšŒ ì‹œì‘ â–¶ IND035 (GDBR2 Index)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND035.xlsx\n",
      "[32/114] ì¡°íšŒ ì‹œì‘ â–¶ IND036 (SKTB10YY Index)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND036.xlsx\n",
      "[33/114] ì¡°íšŒ ì‹œì‘ â–¶ IND037 (GPRXGPRD Index)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND037.xlsx\n",
      "[34/114] ì¡°íšŒ ì‹œì‘ â–¶ IND038 (GS CDS USD SR 5Y D14 Curncy)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND038.xlsx\n",
      "[35/114] ì¡°íšŒ ì‹œì‘ â–¶ IND039 (GSCPI Index)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND039.xlsx\n",
      "[36/114] ì¡°íšŒ ì‹œì‘ â–¶ IND040 (ICLN US Equity)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND040.xlsx\n",
      "[37/114] ì¡°íšŒ ì‹œì‘ â–¶ IND041 (INJCJC Index)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND041.xlsx\n",
      "[38/114] ì¡°íšŒ ì‹œì‘ â–¶ IND042 (ITRX XOVER CDSI GEN 5Y Corp)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND042.xlsx\n",
      "[39/114] ì¡°íšŒ ì‹œì‘ â–¶ IND043 (JNK US Equity)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND043.xlsx\n",
      "[40/114] ì¡°íšŒ ì‹œì‘ â–¶ IND044 (JPEIGLSP Index)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND044.xlsx\n",
      "[41/114] ì¡°íšŒ ì‹œì‘ â–¶ IND045 (JPMCC CDS USD SR 5Y D14 Curncy)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND045.xlsx\n",
      "[42/114] ì¡°íšŒ ì‹œì‘ â–¶ IND046 (JPMVXYEM Index)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND046.xlsx\n",
      "[43/114] ì¡°íšŒ ì‹œì‘ â–¶ IND047 (JPMVXYGL Index)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND047.xlsx\n",
      "[44/114] ì¡°íšŒ ì‹œì‘ â–¶ IND048 (KOREA CDS USD SR 5Y D14 Curncy)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND048.xlsx\n",
      "[45/114] ì¡°íšŒ ì‹œì‘ â–¶ IND049 (KOSPI2 Index)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND049.xlsx\n",
      "[46/114] ì¡°íšŒ ì‹œì‘ â–¶ IND050 (KRE US Equity)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND050.xlsx\n",
      "[47/114] ì¡°íšŒ ì‹œì‘ â–¶ IND051 (KRW Curncy)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND051.xlsx\n",
      "[48/114] ì¡°íšŒ ì‹œì‘ â–¶ IND052 (LF98TRUU Index)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND052.xlsx\n",
      "[49/114] ì¡°íšŒ ì‹œì‘ â–¶ IND053 (LIT US Equity)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND053.xlsx\n",
      "[50/114] ì¡°íšŒ ì‹œì‘ â–¶ IND054 (MOVE Index)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND054.xlsx\n",
      "[51/114] ì¡°íšŒ ì‹œì‘ â–¶ IND055 (MPMICNMA Index)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND055.xlsx\n",
      "[52/114] ì¡°íšŒ ì‹œì‘ â–¶ IND056 (MPMIGLMA Index)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND056.xlsx\n",
      "[53/114] ì¡°íšŒ ì‹œì‘ â–¶ IND057 (MS CDS USD SR 5Y D14 Curncy)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND057.xlsx\n",
      "[54/114] ì¡°íšŒ ì‹œì‘ â–¶ IND058 (MXEF0CX0 Index)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND058.xlsx\n",
      "[55/114] ì¡°íšŒ ì‹œì‘ â–¶ IND059 (NDX Index)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND059.xlsx\n",
      "[56/114] ì¡°íšŒ ì‹œì‘ â–¶ IND060 (OVX Index)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND060.xlsx\n",
      "[57/114] ì¡°íšŒ ì‹œì‘ â–¶ IND061 (PCE CYOY Index)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND061.xlsx\n",
      "[58/114] ì¡°íšŒ ì‹œì‘ â–¶ IND062 (PLTR US Equity)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND062.xlsx\n",
      "[59/114] ì¡°íšŒ ì‹œì‘ â–¶ IND063 (PRODNFR% Index)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND063.xlsx\n",
      "[60/114] ì¡°íšŒ ì‹œì‘ â–¶ IND064 (SHSPSCFI Index)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND064.xlsx\n",
      "[61/114] ì¡°íšŒ ì‹œì‘ â–¶ IND065 (SOFRRATE Index)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND065.xlsx\n",
      "[62/114] ì¡°íšŒ ì‹œì‘ â–¶ IND066 (SOX Index)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND066.xlsx\n",
      "[63/114] ì¡°íšŒ ì‹œì‘ â–¶ IND068 (SPX Index)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND068.xlsx\n",
      "[64/114] ì¡°íšŒ ì‹œì‘ â–¶ IND070 (USDCNH Curncy)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND070.xlsx\n",
      "[65/114] ì¡°íšŒ ì‹œì‘ â–¶ IND071 (USDKRW Curncy)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND071.xlsx\n",
      "[66/114] ì¡°íšŒ ì‹œì‘ â–¶ IND072 (USGG10YR Index)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND072.xlsx\n",
      "[67/114] ì¡°íšŒ ì‹œì‘ â–¶ IND073 (USGG2YR Index)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND073.xlsx\n",
      "[68/114] ì¡°íšŒ ì‹œì‘ â–¶ IND074 (USGG5YR Index)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND074.xlsx\n",
      "[69/114] ì¡°íšŒ ì‹œì‘ â–¶ IND075 (USGGBE10 Index)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND075.xlsx\n",
      "[70/114] ì¡°íšŒ ì‹œì‘ â–¶ IND076 (USOSFR10 BGN Curncy)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND076.xlsx\n",
      "[71/114] ì¡°íšŒ ì‹œì‘ â–¶ IND077 (VIX Index)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND077.xlsx\n",
      "[72/114] ì¡°íšŒ ì‹œì‘ â–¶ IND078 (VNQ US Equity)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND078.xlsx\n",
      "[73/114] ì¡°íšŒ ì‹œì‘ â–¶ IND079 (VXN Index)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND079.xlsx\n",
      "[74/114] ì¡°íšŒ ì‹œì‘ â–¶ IND080 (WCBR US Equity)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND080.xlsx\n",
      "[75/114] ì¡°íšŒ ì‹œì‘ â–¶ IND081 (XBTUSD Curncy)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND081.xlsx\n",
      "[76/114] ì¡°íšŒ ì‹œì‘ â–¶ IND048 (KOREA CDS USD SR 5Y D14 Curncy)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND048.xlsx\n",
      "[77/114] ì¡°íšŒ ì‹œì‘ â–¶ IND036 (SKTB10YY Index)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND036.xlsx\n",
      "[78/114] ì¡°íšŒ ì‹œì‘ â–¶ IND049 (KOSPI2 Index)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND049.xlsx\n",
      "[79/114] ì¡°íšŒ ì‹œì‘ â–¶ IND077 (VIX Index)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND077.xlsx\n",
      "[80/114] ì¡°íšŒ ì‹œì‘ â–¶ IND072 (USGG10YR Index)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND072.xlsx\n",
      "[81/114] ì¡°íšŒ ì‹œì‘ â–¶ IND081 (XBTUSD Curncy)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\IND081.xlsx\n",
      "[82/114] ì¡°íšŒ ì‹œì‘ â–¶ IND500 (KR 3Y KTB Yield)\n",
      "âš ï¸ ë°ì´í„° ì—†ìŒ: IND500 (KR 3Y KTB Yield) ëŠ” ìŠ¤í‚µí•©ë‹ˆë‹¤.\n",
      "[83/114] ì¡°íšŒ ì‹œì‘ â–¶ IND501 (KR 10Y KTB Yield)\n",
      "âš ï¸ ë°ì´í„° ì—†ìŒ: IND501 (KR 10Y KTB Yield) ëŠ” ìŠ¤í‚µí•©ë‹ˆë‹¤.\n",
      "[84/114] ì¡°íšŒ ì‹œì‘ â–¶ IND502 (US 10Y vs 3M Avg)\n",
      "âš ï¸ ë°ì´í„° ì—†ìŒ: IND502 (US 10Y vs 3M Avg) ëŠ” ìŠ¤í‚µí•©ë‹ˆë‹¤.\n",
      "[85/114] ì¡°íšŒ ì‹œì‘ â–¶ IND503 (TSFR 6M vs 3M Avg)\n",
      "âš ï¸ ë°ì´í„° ì—†ìŒ: IND503 (TSFR 6M vs 3M Avg) ëŠ” ìŠ¤í‚µí•©ë‹ˆë‹¤.\n",
      "[86/114] ì¡°íšŒ ì‹œì‘ â–¶ IND504 (USDKRW Spot)\n",
      "âš ï¸ ë°ì´í„° ì—†ìŒ: IND504 (USDKRW Spot) ëŠ” ìŠ¤í‚µí•©ë‹ˆë‹¤.\n",
      "[87/114] ì¡°íšŒ ì‹œì‘ â–¶ IND505 (ì½”ìŠ¤í”¼ Index)\n",
      "âš ï¸ ë°ì´í„° ì—†ìŒ: IND505 (ì½”ìŠ¤í”¼ Index) ëŠ” ìŠ¤í‚µí•©ë‹ˆë‹¤.\n",
      "[88/114] ì¡°íšŒ ì‹œì‘ â–¶ IND506 (ì½”ìŠ¤í”¼ë³€ë™ì„±)\n",
      "âš ï¸ ë°ì´í„° ì—†ìŒ: IND506 (ì½”ìŠ¤í”¼ë³€ë™ì„±) ëŠ” ìŠ¤í‚µí•©ë‹ˆë‹¤.\n",
      "[89/114] ì¡°íšŒ ì‹œì‘ â–¶ IND507 (USDKRW 1Y Implied Vol)\n",
      "âš ï¸ ë°ì´í„° ì—†ìŒ: IND507 (USDKRW 1Y Implied Vol) ëŠ” ìŠ¤í‚µí•©ë‹ˆë‹¤.\n",
      "[90/114] ì¡°íšŒ ì‹œì‘ â–¶ IND508 (USD OIS 1Y - TSFR 1M)\n",
      "âš ï¸ ë°ì´í„° ì—†ìŒ: IND508 (USD OIS 1Y - TSFR 1M) ëŠ” ìŠ¤í‚µí•©ë‹ˆë‹¤.\n",
      "[91/114] ì¡°íšŒ ì‹œì‘ â–¶ IND509 (TSFR 3M)\n",
      "âš ï¸ ë°ì´í„° ì—†ìŒ: IND509 (TSFR 3M) ëŠ” ìŠ¤í‚µí•©ë‹ˆë‹¤.\n",
      "[92/114] ì¡°íšŒ ì‹œì‘ â–¶ IND510 (JPY TIBOR 3M)\n",
      "âš ï¸ ë°ì´í„° ì—†ìŒ: IND510 (JPY TIBOR 3M) ëŠ” ìŠ¤í‚µí•©ë‹ˆë‹¤.\n",
      "[93/114] ì¡°íšŒ ì‹œì‘ â–¶ IND511 (KR 5Y CDS vs PrevM)\n",
      "âš ï¸ ë°ì´í„° ì—†ìŒ: IND511 (KR 5Y CDS vs PrevM) ëŠ” ìŠ¤í‚µí•©ë‹ˆë‹¤.\n",
      "[94/114] ì¡°íšŒ ì‹œì‘ â–¶ IND512 (KR 5Y CDS vs M-3)\n",
      "âš ï¸ ë°ì´í„° ì—†ìŒ: IND512 (KR 5Y CDS vs M-3) ëŠ” ìŠ¤í‚µí•©ë‹ˆë‹¤.\n",
      "[95/114] ì¡°íšŒ ì‹œì‘ â–¶ IND513 (KR Term Spread 10Y-3Y)\n",
      "âš ï¸ ë°ì´í„° ì—†ìŒ: IND513 (KR Term Spread 10Y-3Y) ëŠ” ìŠ¤í‚µí•©ë‹ˆë‹¤.\n",
      "[96/114] ì¡°íšŒ ì‹œì‘ â–¶ IND514 (CDS 5Y: United States)\n",
      "âš ï¸ ë°ì´í„° ì—†ìŒ: IND514 (CDS 5Y: United States) ëŠ” ìŠ¤í‚µí•©ë‹ˆë‹¤.\n",
      "[97/114] ì¡°íšŒ ì‹œì‘ â–¶ IND515 (CDS 5Y: Japan)\n",
      "âš ï¸ ë°ì´í„° ì—†ìŒ: IND515 (CDS 5Y: Japan) ëŠ” ìŠ¤í‚µí•©ë‹ˆë‹¤.\n",
      "[98/114] ì¡°íšŒ ì‹œì‘ â–¶ IND516 (CDS 5Y: China)\n",
      "âš ï¸ ë°ì´í„° ì—†ìŒ: IND516 (CDS 5Y: China) ëŠ” ìŠ¤í‚µí•©ë‹ˆë‹¤.\n",
      "[99/114] ì¡°íšŒ ì‹œì‘ â–¶ IND517 (CDS 5Y: Vietnam)\n",
      "âš ï¸ ë°ì´í„° ì—†ìŒ: IND517 (CDS 5Y: Vietnam) ëŠ” ìŠ¤í‚µí•©ë‹ˆë‹¤.\n",
      "[100/114] ì¡°íšŒ ì‹œì‘ â–¶ IND518 (CDS 5Y: Kazakhstan)\n",
      "âš ï¸ ë°ì´í„° ì—†ìŒ: IND518 (CDS 5Y: Kazakhstan) ëŠ” ìŠ¤í‚µí•©ë‹ˆë‹¤.\n",
      "[101/114] ì¡°íšŒ ì‹œì‘ â–¶ IND519 (CDS 5Y: Germany)\n",
      "âš ï¸ ë°ì´í„° ì—†ìŒ: IND519 (CDS 5Y: Germany) ëŠ” ìŠ¤í‚µí•©ë‹ˆë‹¤.\n",
      "[102/114] ì¡°íšŒ ì‹œì‘ â–¶ IND520 (CDS 5Y: United Kingdom)\n",
      "âš ï¸ ë°ì´í„° ì—†ìŒ: IND520 (CDS 5Y: United Kingdom) ëŠ” ìŠ¤í‚µí•©ë‹ˆë‹¤.\n",
      "[103/114] ì¡°íšŒ ì‹œì‘ â–¶ IND521 (CDS 5Y: India)\n",
      "âš ï¸ ë°ì´í„° ì—†ìŒ: IND521 (CDS 5Y: India) ëŠ” ìŠ¤í‚µí•©ë‹ˆë‹¤.\n",
      "[104/114] ì¡°íšŒ ì‹œì‘ â–¶ IND522 (CDS 5Y: Mexico)\n",
      "âš ï¸ ë°ì´í„° ì—†ìŒ: IND522 (CDS 5Y: Mexico) ëŠ” ìŠ¤í‚µí•©ë‹ˆë‹¤.\n",
      "[105/114] ì¡°íšŒ ì‹œì‘ â–¶ IND523 (CDS 5Y: Indonesia)\n",
      "âš ï¸ ë°ì´í„° ì—†ìŒ: IND523 (CDS 5Y: Indonesia) ëŠ” ìŠ¤í‚µí•©ë‹ˆë‹¤.\n",
      "[106/114] ì¡°íšŒ ì‹œì‘ â–¶ IND524 (CDS 5Y: TÃ¼rkiye)\n",
      "âš ï¸ ë°ì´í„° ì—†ìŒ: IND524 (CDS 5Y: TÃ¼rkiye) ëŠ” ìŠ¤í‚µí•©ë‹ˆë‹¤.\n",
      "[107/114] ì¡°íšŒ ì‹œì‘ â–¶ IND525 (CDS 5Y: Canada)\n",
      "âš ï¸ ë°ì´í„° ì—†ìŒ: IND525 (CDS 5Y: Canada) ëŠ” ìŠ¤í‚µí•©ë‹ˆë‹¤.\n",
      "[108/114] ì¡°íšŒ ì‹œì‘ â–¶ IND526 (CDS 5Y: Hong Kong)\n",
      "âš ï¸ ë°ì´í„° ì—†ìŒ: IND526 (CDS 5Y: Hong Kong) ëŠ” ìŠ¤í‚µí•©ë‹ˆë‹¤.\n",
      "[109/114] ì¡°íšŒ ì‹œì‘ â–¶ IND527 (CDS 5Y: Australia)\n",
      "âš ï¸ ë°ì´í„° ì—†ìŒ: IND527 (CDS 5Y: Australia) ëŠ” ìŠ¤í‚µí•©ë‹ˆë‹¤.\n",
      "[110/114] ì¡°íšŒ ì‹œì‘ â–¶ IND528 (CDS 5Y: Philippines)\n",
      "âš ï¸ ë°ì´í„° ì—†ìŒ: IND528 (CDS 5Y: Philippines) ëŠ” ìŠ¤í‚µí•©ë‹ˆë‹¤.\n",
      "[111/114] ì¡°íšŒ ì‹œì‘ â–¶ IND529 (CDS 5Y: Singapore)\n",
      "âš ï¸ ë°ì´í„° ì—†ìŒ: IND529 (CDS 5Y: Singapore) ëŠ” ìŠ¤í‚µí•©ë‹ˆë‹¤.\n",
      "[112/114] ì¡°íšŒ ì‹œì‘ â–¶ IND530 (CDS 5Y: UAE)\n",
      "âš ï¸ ë°ì´í„° ì—†ìŒ: IND530 (CDS 5Y: UAE) ëŠ” ìŠ¤í‚µí•©ë‹ˆë‹¤.\n",
      "[113/114] ì¡°íšŒ ì‹œì‘ â–¶ IND531 (S&P 500)\n",
      "âš ï¸ ë°ì´í„° ì—†ìŒ: IND531 (S&P 500) ëŠ” ìŠ¤í‚µí•©ë‹ˆë‹¤.\n",
      "[114/114] ì¡°íšŒ ì‹œì‘ â–¶ IND532 (EuroStoxx50)\n",
      "âš ï¸ ë°ì´í„° ì—†ìŒ: IND532 (EuroStoxx50) ëŠ” ìŠ¤í‚µí•©ë‹ˆë‹¤.\n",
      "ğŸ‰ ëª¨ë“  ì§€í‘œ ì¡°íšŒ ë° ì €ì¥ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# â–¶ í•„ìš” íŒ¨í‚¤ì§€ ì„¤ì¹˜ (í•œ ë²ˆë§Œ ì‹¤í–‰)\n",
    "# pip install xbbg blpapi pandas openpyxl\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import blpapi                                   # Bloomberg lowâ€‘level API\n",
    "from xbbg import blp                            # xbbg ë˜í¼\n",
    "\n",
    "# 1) í™˜ê²½ ì„¤ì •\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# ì…ë ¥ íŒŒì¼ ê²½ë¡œ: indicator.xlsx\n",
    "input_path = r\"C:\\Users\\amongpapa\\chartup\\go_scen\\data\\indicator.xlsx\"\n",
    "\n",
    "# ì¶œë ¥ì„ ì €ì¥í•  í´ë” (set)\n",
    "output_dir = r\"C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\"\n",
    "\n",
    "# ì¡°íšŒ ê¸°ê°„: ì˜¤ëŠ˜ ê¸°ì¤€ ê³¼ê±° 1ë…„\n",
    "today      = datetime.today()\n",
    "end_date   = today.strftime(\"%Y-%m-%d\")                        # ì˜ˆ: '2025-07-29'\n",
    "start_date = (today - timedelta(days=365)).strftime(\"%Y-%m-%d\")  # ì˜ˆ: '2024-07-29'\n",
    "\n",
    "# 2) ì¶œë ¥ í´ë” ì¤€ë¹„\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "os.makedirs(output_dir, exist_ok=True)  # ì—†ìœ¼ë©´ ìƒì„±\n",
    "\n",
    "# 3) indicator.xlsx ì½ê¸°\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df_ind = pd.read_excel(input_path, dtype=str)  # ëª¨ë“  ì¹¼ëŸ¼ì„ ë¬¸ìì—´ë¡œ ë¡œë“œ\n",
    "\n",
    "# í•„ìˆ˜ ì¹¼ëŸ¼ í™•ì¸\n",
    "required_cols = {'Indicator_ID', 'Bloomberg_Ticker'}\n",
    "if not required_cols.issubset(df_ind.columns):\n",
    "    raise KeyError(f\"'{', '.join(required_cols)}' ì¹¼ëŸ¼ì´ ëª¨ë‘ í•„ìš”í•©ë‹ˆë‹¤. íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "\n",
    "# 4) í‹°ì»¤ë³„ ì¡°íšŒ ë° ì €ì¥\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "total = len(df_ind)\n",
    "for idx, row in df_ind.iterrows():\n",
    "    indicator_id = row['Indicator_ID'].strip()      # ì§€í‘œ ê³ ìœ  ID\n",
    "    ticker       = row['Bloomberg_Ticker'].strip()   # ë¸”ë£¸ë²„ê·¸ í‹°ì»¤\n",
    "\n",
    "    print(f\"[{idx+1}/{total}] ì¡°íšŒ ì‹œì‘ â–¶ {indicator_id} ({ticker})\")\n",
    "\n",
    "    try:\n",
    "        # PX_LAST(ì¢…ê°€) ì¼ë³„ ì‹œê³„ì—´ ì¡°íšŒ\n",
    "        df_ts = blp.bdh(\n",
    "            tickers=[ticker],        # ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì…ë ¥\n",
    "            flds='PX_LAST',          # ì¡°íšŒ í•„ë“œ: ì¢…ê°€\n",
    "            start_date=start_date,   # ì‹œì‘ì¼\n",
    "            end_date=end_date,       # ì¢…ë£Œì¼\n",
    "            Per='D',                 # ì¼ë³„ ë°ì´í„°\n",
    "            adjust='all'             # ë°°ë‹¹Â·ë¶„í•  ë“± ì¡°ì • ë°˜ì˜\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ì¡°íšŒ ì‹¤íŒ¨: {indicator_id} ({ticker}) â†’ {e}\")\n",
    "        continue\n",
    "\n",
    "    if df_ts.empty:\n",
    "        print(f\"âš ï¸ ë°ì´í„° ì—†ìŒ: {indicator_id} ({ticker}) ëŠ” ìŠ¤í‚µí•©ë‹ˆë‹¤.\")\n",
    "        continue\n",
    "\n",
    "    # ì—‘ì…€ë¡œ ì €ì¥\n",
    "    output_path = os.path.join(output_dir, f\"{indicator_id}.xlsx\")\n",
    "    df_ts.to_excel(output_path, engine='openpyxl')\n",
    "    print(f\"âœ… ì €ì¥ ì™„ë£Œ: {output_path}\")\n",
    "\n",
    "print(\"ğŸ‰ ëª¨ë“  ì§€í‘œ ì¡°íšŒ ë° ì €ì¥ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c5bceb1-2c5f-4968-b3cc-89720a522020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] IND001.xlsx -> C1='G', level=normal, D1(mu)=2071.17, E1(sd)=106.566 (z=1.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] IND002.xlsx -> C1='G', level=normal, D1(mu)=14.5265, E1(sd)=0.577152 (z=-0.84)\n",
      "[OK] IND003.xlsx -> C1='G', level=normal, D1(mu)=149.787, E1(sd)=2.59085 (z=-0.64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] IND004.xlsx -> C1='G', level=normal, D1(mu)=68.9176, E1(sd)=3.33801 (z=0.93)\n",
      "[OK] IND005.xlsx -> C1='G', level=normal, D1(mu)=139.506, E1(sd)=6.3645 (z=1.03)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] IND006.xlsx -> C1='G', level=normal, D1(mu)=107.359, E1(sd)=0.393447 (z=-1.83)\n",
      "[OK] IND007.xlsx -> C1='G', level=normal, D1(mu)=323.4, E1(sd)=11.627 (z=1.57)\n",
      "[SKIP] IND008.xlsx (file not found)\n",
      "[OK] IND009.xlsx -> C1='G', level=normal, D1(mu)=16.1422, E1(sd)=1.75258 (z=-1.29)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] IND010.xlsx -> C1='G', level=normal, D1(mu)=36.7317, E1(sd)=2.38844 (z=-1.58)\n",
      "[OK] IND011.xlsx -> C1='G', level=None, D1(mu)=n/a, E1(sd)=n/a (z=n/a)\n",
      "[OK] IND012.xlsx -> C1='G', level=None, D1(mu)=n/a, E1(sd)=n/a (z=n/a)\n",
      "[OK] IND013.xlsx -> C1='G', level=None, D1(mu)=n/a, E1(sd)=n/a (z=n/a)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] IND014.xlsx -> C1='G', level=normal, D1(mu)=55.9492, E1(sd)=2.32394 (z=2.14)\n",
      "[OK] IND015.xlsx -> C1='G', level=normal, D1(mu)=35.9229, E1(sd)=3.32954 (z=-1.59)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] IND016.xlsx -> C1='G', level=normal, D1(mu)=61.2657, E1(sd)=2.1559 (z=-1.49)\n",
      "[OK] IND017.xlsx -> C1='G', level=None, D1(mu)=n/a, E1(sd)=n/a (z=n/a)\n",
      "[OK] IND018.xlsx -> C1='G', level=normal, D1(mu)=7.12403, E1(sd)=0.0134011 (z=-1.41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] IND019.xlsx -> C1='G', level=normal, D1(mu)=7.12403, E1(sd)=0.0134011 (z=-1.41)\n",
      "[OK] IND020.xlsx -> C1='G', level=normal, D1(mu)=65.2557, E1(sd)=2.21714 (z=-1.22)\n",
      "[OK] IND021.xlsx -> C1='G', level=None, D1(mu)=n/a, E1(sd)=n/a (z=n/a)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] IND022.xlsx -> C1='G', level=normal, D1(mu)=255.839, E1(sd)=10.3907 (z=-1.14)\n",
      "[OK] IND023.xlsx -> C1='G', level=normal, D1(mu)=98.6182, E1(sd)=0.932354 (z=1.68)\n",
      "[OK] IND024.xlsx -> C1='G', level=normal, D1(mu)=95.089, E1(sd)=0.956528 (z=1.11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] IND025.xlsx -> C1='Y', level=yellow, D1(mu)=368.414, E1(sd)=113.018 (z=0.48)\n",
      "[OK] IND026.xlsx -> C1='G', level=normal, D1(mu)=58.5725, E1(sd)=2.30545 (z=-2.42)\n",
      "[SKIP] IND027.xlsx (file not found)\n",
      "[OK] IND028.xlsx -> C1='G', level=normal, D1(mu)=1.16525, E1(sd)=0.00874146 (z=-1.60)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] IND029.xlsx -> C1='G', level=normal, D1(mu)=1.16525, E1(sd)=0.00874146 (z=-1.60)\n",
      "[OK] IND030.xlsx -> C1='G', level=normal, D1(mu)=63.9023, E1(sd)=2.10525 (z=-1.00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] IND031.xlsx -> C1='G', level=normal, D1(mu)=4.225, E1(sd)=0.175 (z=-1.29)\n",
      "[SKIP] IND032.xlsx (file not found)\n",
      "[SKIP] IND033.xlsx (file not found)\n",
      "[OK] IND034.xlsx -> C1='G', level=normal, D1(mu)=3.25607, E1(sd)=0.286787 (z=-0.87)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] IND035.xlsx -> C1='G', level=normal, D1(mu)=1.98515, E1(sd)=0.0381405 (z=0.76)\n",
      "[OK] IND036.xlsx -> C1='G', level=None, D1(mu)=n/a, E1(sd)=n/a (z=n/a)\n",
      "[OK] IND037.xlsx -> C1='G', level=normal, D1(mu)=135.464, E1(sd)=50.0001 (z=-0.89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] IND038.xlsx -> C1='G', level=normal, D1(mu)=68.9175, E1(sd)=3.33794 (z=0.93)\n",
      "[OK] IND039.xlsx -> C1='G', level=None, D1(mu)=n/a, E1(sd)=n/a (z=n/a)\n",
      "[OK] IND040.xlsx -> C1='G', level=normal, D1(mu)=16.0377, E1(sd)=1.07356 (z=0.03)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] IND041.xlsx -> C1='G', level=normal, D1(mu)=227.157, E1(sd)=10.8363 (z=-0.66)\n",
      "[OK] IND042.xlsx -> C1='G', level=normal, D1(mu)=264.143, E1(sd)=7.41639 (z=0.43)\n",
      "[OK] IND043.xlsx -> C1='G', level=normal, D1(mu)=96.7224, E1(sd)=0.342063 (z=0.11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] IND044.xlsx -> C1='G', level=normal, D1(mu)=255.762, E1(sd)=11.4802 (z=-0.77)\n",
      "[OK] IND045.xlsx -> C1='G', level=normal, D1(mu)=42.873, E1(sd)=2.88381 (z=1.17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] IND046.xlsx -> C1='G', level=normal, D1(mu)=6.62667, E1(sd)=0.262955 (z=-0.71)\n",
      "[OK] IND047.xlsx -> C1='G', level=normal, D1(mu)=7.25267, E1(sd)=0.288426 (z=-0.29)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] IND048.xlsx -> C1='G', level=normal, D1(mu)=22.2331, E1(sd)=2.19985 (z=0.77)\n",
      "[OK] IND049.xlsx -> C1='G', level=normal, D1(mu)=506.423, E1(sd)=54.9684 (z=0.62)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] IND050.xlsx -> C1='G', level=normal, D1(mu)=62.2774, E1(sd)=2.05653 (z=-0.32)\n",
      "[OK] IND051.xlsx -> C1='G', level=normal, D1(mu)=1418.82, E1(sd)=28.0373 (z=1.88)\n",
      "[OK] IND052.xlsx -> C1='G', level=normal, D1(mu)=2874.19, E1(sd)=8.94461 (z=0.10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] IND053.xlsx -> C1='G', level=normal, D1(mu)=56.9235, E1(sd)=4.78175 (z=0.70)\n",
      "[OK] IND054.xlsx -> C1='G', level=normal, D1(mu)=76.267, E1(sd)=5.39344 (z=0.47)\n",
      "[OK] IND055.xlsx -> C1='G', level=None, D1(mu)=n/a, E1(sd)=n/a (z=n/a)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] IND056.xlsx -> C1='G', level=None, D1(mu)=n/a, E1(sd)=n/a (z=n/a)\n",
      "[OK] IND057.xlsx -> C1='Y', level=yellow, D1(mu)=54.7748, E1(sd)=2.81331 (z=1.98)\n",
      "[OK] IND058.xlsx -> C1='G', level=normal, D1(mu)=1840.65, E1(sd)=5.47972 (z=-2.71)\n",
      "[OK] IND059.xlsx -> C1='G', level=normal, D1(mu)=24739.5, E1(sd)=673.296 (z=-0.74)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] IND060.xlsx -> C1='G', level=normal, D1(mu)=34.6333, E1(sd)=2.33113 (z=0.57)\n",
      "[OK] IND061.xlsx -> C1='G', level=None, D1(mu)=n/a, E1(sd)=n/a (z=n/a)\n",
      "[OK] IND062.xlsx -> C1='G', level=normal, D1(mu)=176.936, E1(sd)=11.9697 (z=-1.85)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] IND063.xlsx -> C1='G', level=None, D1(mu)=n/a, E1(sd)=n/a (z=n/a)\n",
      "[OK] IND064.xlsx -> C1='G', level=normal, D1(mu)=1665.52, E1(sd)=377.094 (z=-0.72)\n",
      "[OK] IND065.xlsx -> C1='G', level=normal, D1(mu)=4.19433, E1(sd)=0.159472 (z=-1.78)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] IND066.xlsx -> C1='G', level=normal, D1(mu)=6549.48, E1(sd)=467.371 (z=-0.31)\n",
      "[SKIP] IND067.xlsx (file not found)\n",
      "[OK] IND068.xlsx -> C1='G', level=normal, D1(mu)=6676.49, E1(sd)=113.925 (z=-0.65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] IND069.xlsx -> C1='G', level=None, D1(mu)=n/a, E1(sd)=n/a (z=n/a)\n",
      "[OK] IND070.xlsx -> C1='G', level=normal, D1(mu)=7.12403, E1(sd)=0.0134011 (z=-1.41)\n",
      "[OK] IND071.xlsx -> C1='Y', level=yellow, D1(mu)=1418.82, E1(sd)=28.0373 (z=1.88)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] IND072.xlsx -> C1='G', level=normal, D1(mu)=4.08824, E1(sd)=0.0663221 (z=-0.38)\n",
      "[OK] IND073.xlsx -> C1='G', level=normal, D1(mu)=3.55518, E1(sd)=0.0548594 (z=-0.87)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] IND074.xlsx -> C1='G', level=normal, D1(mu)=3.66436, E1(sd)=0.0589699 (z=-0.73)\n",
      "[OK] IND075.xlsx -> C1='G', level=normal, D1(mu)=2.33132, E1(sd)=0.0437362 (z=-1.84)\n",
      "[OK] IND076.xlsx -> C1='G', level=normal, D1(mu)=3.61512, E1(sd)=0.0653133 (z=0.28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] IND077.xlsx -> C1='Y', level=red, D1(mu)=17.8152, E1(sd)=2.71988 (z=2.06)\n",
      "[OK] IND078.xlsx -> C1='G', level=normal, D1(mu)=90.4734, E1(sd)=1.1655 (z=-0.78)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] IND079.xlsx -> C1='Y', level=red, D1(mu)=21.9778, E1(sd)=3.31969 (z=2.10)\n",
      "[OK] IND080.xlsx -> C1='G', level=normal, D1(mu)=31.2294, E1(sd)=0.885058 (z=-3.23)\n",
      "[OK] IND081.xlsx -> C1='G', level=normal, D1(mu)=108108, E1(sd)=9545.45 (z=-2.49)\n",
      "[SKIP] IND082.xlsx (file not found)\n",
      "[SKIP] IND083.xlsx (file not found)\n",
      "[SKIP] IND084.xlsx (file not found)\n",
      "[SKIP] IND085.xlsx (file not found)\n",
      "[SKIP] IND086.xlsx (file not found)\n",
      "[SKIP] IND087.xlsx (file not found)\n",
      "[SKIP] IND088.xlsx (file not found)\n",
      "[SKIP] IND089.xlsx (file not found)\n",
      "[SKIP] IND090.xlsx (file not found)\n",
      "[SKIP] IND091.xlsx (file not found)\n",
      "[SKIP] IND092.xlsx (file not found)\n",
      "[SKIP] IND093.xlsx (file not found)\n",
      "[SKIP] IND094.xlsx (file not found)\n",
      "[SKIP] IND095.xlsx (file not found)\n",
      "[SKIP] IND096.xlsx (file not found)\n",
      "[SKIP] IND097.xlsx (file not found)\n",
      "[SKIP] IND098.xlsx (file not found)\n",
      "[SKIP] IND099.xlsx (file not found)\n",
      "[SKIP] IND100.xlsx (file not found)\n",
      "[SKIP] IND101.xlsx (file not found)\n",
      "[SKIP] IND102.xlsx (file not found)\n",
      "[SKIP] IND103.xlsx (file not found)\n",
      "[SKIP] IND104.xlsx (file not found)\n",
      "[SKIP] IND105.xlsx (file not found)\n",
      "[SKIP] IND106.xlsx (file not found)\n",
      "[SKIP] IND107.xlsx (file not found)\n",
      "[SKIP] IND108.xlsx (file not found)\n",
      "[SKIP] IND109.xlsx (file not found)\n",
      "[SKIP] IND110.xlsx (file not found)\n",
      "[SKIP] IND111.xlsx (file not found)\n",
      "[SKIP] IND112.xlsx (file not found)\n",
      "[SKIP] IND113.xlsx (file not found)\n",
      "[SKIP] IND114.xlsx (file not found)\n",
      "[SKIP] IND115.xlsx (file not found)\n",
      "[SKIP] IND116.xlsx (file not found)\n",
      "[SKIP] IND117.xlsx (file not found)\n",
      "[SKIP] IND118.xlsx (file not found)\n",
      "[SKIP] IND119.xlsx (file not found)\n",
      "[SKIP] IND120.xlsx (file not found)\n",
      "[SKIP] IND121.xlsx (file not found)\n",
      "[SKIP] IND122.xlsx (file not found)\n",
      "[SKIP] IND123.xlsx (file not found)\n",
      "[SKIP] IND124.xlsx (file not found)\n",
      "[SKIP] IND125.xlsx (file not found)\n",
      "[SKIP] IND126.xlsx (file not found)\n",
      "[SKIP] IND127.xlsx (file not found)\n",
      "[SKIP] IND128.xlsx (file not found)\n",
      "[SKIP] IND129.xlsx (file not found)\n",
      "[SKIP] IND130.xlsx (file not found)\n",
      "[SKIP] IND131.xlsx (file not found)\n",
      "[SKIP] IND132.xlsx (file not found)\n",
      "[SKIP] IND133.xlsx (file not found)\n",
      "[SKIP] IND134.xlsx (file not found)\n",
      "[SKIP] IND135.xlsx (file not found)\n",
      "[SKIP] IND136.xlsx (file not found)\n",
      "[SKIP] IND137.xlsx (file not found)\n",
      "[SKIP] IND138.xlsx (file not found)\n",
      "[SKIP] IND139.xlsx (file not found)\n",
      "[SKIP] IND140.xlsx (file not found)\n",
      "[SKIP] IND141.xlsx (file not found)\n",
      "[SKIP] IND142.xlsx (file not found)\n",
      "[SKIP] IND143.xlsx (file not found)\n",
      "[SKIP] IND144.xlsx (file not found)\n",
      "[SKIP] IND145.xlsx (file not found)\n",
      "[SKIP] IND146.xlsx (file not found)\n",
      "[SKIP] IND147.xlsx (file not found)\n",
      "[SKIP] IND148.xlsx (file not found)\n",
      "[SKIP] IND149.xlsx (file not found)\n",
      "[SKIP] IND150.xlsx (file not found)\n",
      "[SKIP] IND151.xlsx (file not found)\n",
      "\n",
      "ìš”ì•½ ì €ì¥: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\\vol_band_summary_20251122_114136.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\2112831122.py:303: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "IND001 ~ IND151 ì—‘ì…€ íŒŒì¼ì— ëŒ€í•´:\n",
    "1) ì‹œê³„ì—´(ë‚ ì§œ, ê°’) ìë™ íƒì§€\n",
    "2) ìµœê·¼ í‰ê· /í‘œì¤€í¸ì°¨ ê¸°ë°˜ ì„ê³„ì¹˜ ê³„ì‚°\n",
    "3) ë§ˆì§€ë§‰ ê°’ì´ ì„ê³„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ\n",
    "      - ì •ìƒ       â†’ C1 = 'G'\n",
    "      - ì£¼ì˜/ê²½ê³ /ì‹¬ê° â†’ C1 = 'Y'  (ì£¼ì˜ ì´ìƒì€ ëª¨ë‘ Y)\n",
    "4) D1ì— 60ì¼ í‰ê· (mu), E1ì— 60ì¼ í‘œì¤€í¸ì°¨(sd=Ïƒ) ê¸°ë¡\n",
    "5) ì‹¤í–‰ ìš”ì•½ CSV ì €ì¥\n",
    "\n",
    "ì„¤ì¹˜:\n",
    "    pip install pandas openpyxl numpy\n",
    "\n",
    "ì‚¬ìš©:\n",
    "    python script.py\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "# ================= íŒ€ì¥ë‹˜ í™˜ê²½ ì„¤ì • =================\n",
    "BASE_DIR = r\"C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\"  # ì—‘ì…€ í´ë” ê²½ë¡œ (raw string ì‚¬ìš©)\n",
    "FILE_PREFIX = \"IND\"                                       # íŒŒì¼ ì ‘ë‘ì‚¬\n",
    "FILE_RANGE = range(1, 152)                                # 001~151\n",
    "\n",
    "SHEET_NAME = 0                  # ì²« ë²ˆì§¸ ì‹œíŠ¸(ì •ìˆ˜ ë˜ëŠ” ì‹œíŠ¸ëª…)\n",
    "WINDOW = 60                     # ë¡¤ë§ ìœˆë„ìš°(ì¼ìˆ˜, í‰ê· /í‘œì¤€í¸ì°¨ ê³„ì‚°ìš©)\n",
    "K = 2.0                         # (í˜„ì¬ëŠ” z-score ì°¸ê³ ìš©, ì„ê³„ì¹˜ì—ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)\n",
    "MIN_PERIODS = max(30, WINDOW // 2)  # ìµœì†Œ ê³„ì‚° ë°ì´í„° ê¸¸ì´(ì§§ì€ ë°ì´í„° ë³´í˜¸)\n",
    "\n",
    "# ì»¬ëŸ¼ ì´ë¦„ íŒíŠ¸(ìš°ì„  ë§¤ì¹­)\n",
    "DATE_COL_HINTS = [\"date\", \"ë‚ ì§œ\", \"ì¼ì\", \"time\", \"ì¼ì‹œ\"]\n",
    "VALUE_COL_HINTS = [\"close\", \"price\", \"value\", \"index\", \"ì§€ìˆ˜\", \"ì¢…ê°€\", \"ê°€ê²©\", \"ê°’\", \"ìˆ˜ì¹˜\", \"PX_LAST\"]\n",
    "# ====================================================\n",
    "\n",
    "# âœ… [ì¶”ê°€] ì§€í‘œë³„ ê³ ì • ì„ê³„ì¹˜ ì„¤ì • (ë°©ì‹ A: ì ˆëŒ€ê°’ ê¸°ì¤€)\n",
    "# - ì—¬ê¸° ìˆëŠ” IDëŠ” ê³ ì • ì„ê³„ì¹˜ë¥¼ ì‚¬ìš©\n",
    "# - ì—¬ê¸°ì— ì—†ëŠ” IDëŠ” ìë™ ê³„ì‚° ì„ê³„ì¹˜(í‰ê·  Ã— 1.1 / 1.2 / 1.3)ë¥¼ ì‚¬ìš©\n",
    "CUSTOM_THRESHOLDS = {\n",
    "    # USD/KRW í™˜ìœ¨ (IND071): ê°’ì´ ì»¤ì§ˆìˆ˜ë¡ ë¦¬ìŠ¤í¬â†‘\n",
    "    \"IND071\": {\n",
    "        \"direction\": \"up\",   # up: ê°’ì´ ì»¤ì§ˆìˆ˜ë¡ ìœ„í—˜, down: ê°’ì´ ì‘ì•„ì§ˆìˆ˜ë¡ ìœ„í—˜\n",
    "        \"yellow\": 1400.0,    # ì£¼ì˜\n",
    "        \"orange\": 1600.0,    # ê²½ê³ \n",
    "        \"red\": 1800.0        # ì‹¬ê°\n",
    "    },\n",
    "    # í•„ìš”í•˜ë©´ ì½”ìŠ¤í”¼/ë¯¸êµ­ ê¸ˆë¦¬ ë“± ì¶”ê°€ ê°€ëŠ¥\n",
    "    # \"IND001\": {\n",
    "    #     \"direction\": \"down\",\n",
    "    #     \"yellow\": 2400.0,\n",
    "    #     \"orange\": 2200.0,\n",
    "    #     \"red\": 2000.0\n",
    "    # },\n",
    "    # \"IND050\": {\n",
    "    #     \"direction\": \"up\",\n",
    "    #     \"yellow\": 4.5,\n",
    "    #     \"orange\": 5.0,\n",
    "    #     \"red\": 5.5\n",
    "    # },\n",
    "}\n",
    "\n",
    "\n",
    "# ---------------- ë„ìš°ë¯¸: ì¤‘ë³µ ì»¬ëŸ¼ëª… ìœ ì¼í™” ----------------\n",
    "def _make_unique(names):\n",
    "    \"\"\"\n",
    "    ë™ì¼í•œ ì»¬ëŸ¼ëª…ì´ ë°˜ë³µë  ê²½ìš° .1, .2 ì ‘ë¯¸ì‚¬ë¥¼ ë¶€ì—¬í•´ ìœ ì¼í™”\n",
    "    ì˜ˆ) ['nan','nan'] -> ['nan','nan.1']\n",
    "    \"\"\"\n",
    "    seen = {}\n",
    "    out = []\n",
    "    for n in names:\n",
    "        key = str(n)\n",
    "        if key not in seen:\n",
    "            seen[key] = 0\n",
    "            out.append(key)\n",
    "        else:\n",
    "            seen[key] += 1\n",
    "            out.append(f\"{key}.{seen[key]}\")\n",
    "    return out\n",
    "\n",
    "\n",
    "def _clean_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    ê³µë°± ì •ë¦¬ + ìœ ì¼í™”\n",
    "    \"\"\"\n",
    "    cols = [re.sub(r\"\\s+\", \" \", str(c)).strip() for c in df.columns]\n",
    "    df.columns = _make_unique(cols)\n",
    "    return df\n",
    "\n",
    "\n",
    "# ---------------- ìœ í‹¸: ìˆ«ì ë¬¸ìì—´ â†’ float (í•­ìƒ Series ë°˜í™˜) ----------------\n",
    "def _as_numeric_series(s) -> pd.Series:\n",
    "    \"\"\"\n",
    "    ì–´ë–¤ ì…ë ¥(s: Series/DataFrame/ndarray/ë¦¬ìŠ¤íŠ¸)ì´ ì™€ë„ **í•­ìƒ pandas.Series**ë¡œ ë³€í™˜ í›„\n",
    "    ì•ˆì „í•˜ê²Œ ìˆ«ìë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "    - ê³µë°±/ëŒ€ì‹œë¥˜(\"\", \"-\", \"â€”\", \"_\") â†’ NaN\n",
    "    - ê´„í˜¸ ìŒìˆ˜ \"(123)\" â†’ -123\n",
    "    - ì½¤ë§ˆ ì œê±° \"1,234.56\" â†’ 1234.56\n",
    "    - í¼ì„¼íŠ¸ \"5.2%\" â†’ 0.052\n",
    "    \"\"\"\n",
    "    if isinstance(s, pd.DataFrame):\n",
    "        # ìˆ«ì ë³€í™˜ë¥ ì´ ê°€ì¥ ë†’ì€ ì»¬ëŸ¼ í•˜ë‚˜ ìë™ ì„ íƒ\n",
    "        best_col = None\n",
    "        best_ratio = -1.0\n",
    "        for col in s.columns:\n",
    "            x = pd.to_numeric(\n",
    "                pd.Series(s[col]).astype(\"string\")\n",
    "                .str.replace(\",\", \"\", regex=False)\n",
    "                .str.replace(\"%\", \"\", regex=False),\n",
    "                errors=\"coerce\",\n",
    "            )\n",
    "            ratio = x.notna().mean()\n",
    "            if ratio > best_ratio:\n",
    "                best_ratio, best_col = ratio, col\n",
    "        s = s[best_col]\n",
    "\n",
    "    if not isinstance(s, pd.Series):\n",
    "        s = pd.Series(s)\n",
    "\n",
    "    ss = s.astype(\"string\").str.strip()\n",
    "    ss = ss.replace(\n",
    "        {\n",
    "            \"\": pd.NA,\n",
    "            \"-\": pd.NA,\n",
    "            \"â€”\": pd.NA,\n",
    "            \"_\": pd.NA,\n",
    "            \"nan\": pd.NA,\n",
    "            \"NaN\": pd.NA,\n",
    "            \"None\": pd.NA,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # ê´„í˜¸ ìŒìˆ˜ ì²˜ë¦¬\n",
    "    neg_mask = ss.str.match(r\"^\\(.*\\)$\", na=False)\n",
    "    ss2 = ss.str.replace(r\"^\\((.*)\\)$\", r\"\\1\", regex=True)  # '(123)' -> '123'\n",
    "\n",
    "    # ì½¤ë§ˆ/í¼ì„¼íŠ¸ ì œê±°\n",
    "    ss2 = ss2.str.replace(\",\", \"\", regex=False)\n",
    "    pct_mask = ss2.str.endswith(\"%\", na=False)\n",
    "    ss2 = ss2.str.replace(\"%\", \"\", regex=False)\n",
    "\n",
    "    # ìˆ«ì ë³€í™˜\n",
    "    num = pd.to_numeric(ss2, errors=\"coerce\")\n",
    "\n",
    "    # ê´„í˜¸ ìŒìˆ˜ ì ìš©\n",
    "    if neg_mask.any():\n",
    "        num.loc[neg_mask & num.notna()] = -num.loc[neg_mask & num.notna()].abs()\n",
    "\n",
    "    # í¼ì„¼íŠ¸ â†’ /100\n",
    "    if pct_mask.any():\n",
    "        num.loc[pct_mask & num.notna()] = num.loc[pct_mask & num.notna()] / 100.0\n",
    "\n",
    "    return num.astype(\"float64\")\n",
    "\n",
    "\n",
    "# ---------------- ìŠ¤ì½”ì–´ë§ í—¬í¼ ----------------\n",
    "def _numeric_score(df: pd.DataFrame, lookahead: int = 5) -> int:\n",
    "    \"\"\"\n",
    "    ìƒìœ„ lookaheadí–‰ì—ì„œ ìˆ«ìë¡œ ë³€í™˜ ê°€ëŠ¥í•œ ì—´ ê°œìˆ˜ ìŠ¤ì½”ì–´ë§.\n",
    "    \"\"\"\n",
    "    head = df.head(lookahead)\n",
    "    cnt = 0\n",
    "    for c in head.columns:\n",
    "        s = head[c]\n",
    "        s_num = _as_numeric_series(s)\n",
    "        numlike = s_num.notna().mean()\n",
    "        if numlike >= 0.5:\n",
    "            cnt += 1\n",
    "    return cnt\n",
    "\n",
    "\n",
    "def _likely_good(df: pd.DataFrame) -> bool:\n",
    "    \"\"\"í˜„ì¬ í˜•íƒœê°€ 'í—¤ë”-ë°ì´í„°'ë¡œ ì ì ˆí•œì§€ ê°„ë‹¨ ìŠ¤ì½”ì–´.\"\"\"\n",
    "    return _numeric_score(df, lookahead=5) >= 2  # ìˆ«ìí˜• ì—´ 2ê°œ ì´ìƒì´ë©´ OK\n",
    "\n",
    "\n",
    "# ---------------- í—¤ë” ìë™ ê°ì§€ ----------------\n",
    "def detect_header_and_read(path, sheet_name=0, max_scan=10) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    í—¤ë”/ë°ì´í„° ì‹œì‘í–‰ì´ ë¶ˆëª…í™•í•œ ì—‘ì…€ì„ ìœ„í•œ ë¡œë”.\n",
    "    1) ì¼ë°˜ ë¡œë“œ í›„ ê°„ì´ ì ê²€, ê´œì°®ìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ì»¬ëŸ¼ ìœ ì¼í™” ì ìš©)\n",
    "    2) ìƒë‹¨ max_scaní–‰ì„ í›„ë³´ í—¤ë”ë¡œ ê°€ì •í•´ ìŠ¤ì½”ì–´ë§ í›„ ë² ìŠ¤íŠ¸ í—¤ë” ì±„íƒ\n",
    "    \"\"\"\n",
    "    # 1) ì¼ë°˜ ë¡œë“œ ì‹œë„\n",
    "    df0 = pd.read_excel(path, sheet_name=sheet_name, engine=\"openpyxl\", header=0)\n",
    "    if df0.shape[0] == 0:\n",
    "        df0 = pd.read_excel(path, sheet_name=sheet_name, engine=\"openpyxl\", header=None)\n",
    "    if _likely_good(df0):\n",
    "        return _clean_columns(df0)\n",
    "\n",
    "    # 2) í›„ë³´ í—¤ë” ìŠ¤ìº”\n",
    "    raw = pd.read_excel(path, sheet_name=sheet_name, engine=\"openpyxl\", header=None)\n",
    "    nrows = min(max_scan, len(raw))\n",
    "    best_score, best_row = -1e9, 0\n",
    "    for hdr in range(nrows):\n",
    "        tmp = raw.copy()\n",
    "        tmp.columns = _make_unique(tmp.iloc[hdr].astype(str).str.strip())\n",
    "        tmp = tmp.iloc[hdr + 1:].reset_index(drop=True)\n",
    "\n",
    "        score_num = _numeric_score(tmp, lookahead=5)\n",
    "        penalty = sum(\n",
    "            1\n",
    "            for name in tmp.columns\n",
    "            if str(name).lower() in (\"nan\", \"nat\", \"\", \"none\")\n",
    "        )\n",
    "        score = score_num - 0.5 * penalty  # ë‚˜ìœ í—¤ë” íŒ¨ë„í‹°\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score, best_row = score, hdr\n",
    "\n",
    "    raw.columns = _make_unique(raw.iloc[best_row].astype(str).str.strip())\n",
    "    df = raw.iloc[best_row + 1:].reset_index(drop=True)\n",
    "    return _clean_columns(df)\n",
    "\n",
    "\n",
    "# ---------------- ë‚ ì§œ/ê°’ ì»¬ëŸ¼ ìë™ ì„ íƒ ----------------\n",
    "def _pick_date_col(df: pd.DataFrame) -> Optional[str]:\n",
    "    # íŒíŠ¸ ìš°ì„ \n",
    "    for hint in DATE_COL_HINTS:\n",
    "        for c in df.columns:\n",
    "            if hint.lower() in str(c).lower():\n",
    "                return c\n",
    "    # dtype/ë³€í™˜ë¥  ê¸°ë°˜\n",
    "    dt_cols = [c for c in df.columns if pd.api.types.is_datetime64_any_dtype(df[c])]\n",
    "    if dt_cols:\n",
    "        return dt_cols[0]\n",
    "    best_col, best_ratio = None, 0.0\n",
    "    for c in df.columns:\n",
    "        try:\n",
    "            converted = pd.to_datetime(df[c], errors=\"coerce\", infer_datetime_format=True)\n",
    "            ratio = converted.notna().mean()\n",
    "            if ratio > best_ratio and ratio >= 0.7:\n",
    "                best_col, best_ratio = c, ratio\n",
    "        except Exception:\n",
    "            pass\n",
    "    return best_col\n",
    "\n",
    "\n",
    "def _pick_value_col(df: pd.DataFrame, exclude_cols: list) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    ê°’ ì»¬ëŸ¼ ìë™ ì„ íƒ(íŒíŠ¸ â†’ í†µê³„ ìŠ¤ì½”ì–´).\n",
    "    \"\"\"\n",
    "    # íŒíŠ¸ ìš°ì„ \n",
    "    for hint in VALUE_COL_HINTS:\n",
    "        for c in df.columns:\n",
    "            if c in exclude_cols:\n",
    "                continue\n",
    "            if hint.lower() in str(c).lower():\n",
    "                return c\n",
    "\n",
    "    # ìˆ«ìí˜• í›„ë³´ ìŠ¤ì½”ì–´ë§(ê²°ì¸¡â†“, ë¶„ì‚°>0, ìƒ˜í”Œ ìˆ˜ ì¶©ë¶„)\n",
    "    candidates = []\n",
    "    for c in df.columns:\n",
    "        if c in exclude_cols:\n",
    "            continue\n",
    "        series = _as_numeric_series(df[c])\n",
    "        na_ratio = pd.isna(series).mean()\n",
    "        var = np.nanvar(series.astype(float))\n",
    "        if (~pd.isna(series)).sum() >= MIN_PERIODS and var > 0:\n",
    "            candidates.append((c, na_ratio, var))\n",
    "\n",
    "    if not candidates:\n",
    "        # MIN_PERIODS ë¯¸ë§Œì´ì–´ë„ ìµœì„ ì˜ ìˆ«ìí˜• ì»¬ëŸ¼ì„ fallback\n",
    "        fallback = []\n",
    "        for c in df.columns:\n",
    "            if c in exclude_cols:\n",
    "                continue\n",
    "            series = _as_numeric_series(df[c])\n",
    "            var = np.nanvar(series.astype(float))\n",
    "            if var > 0:\n",
    "                na_ratio = pd.isna(series).mean()\n",
    "                fallback.append((c, na_ratio, var))\n",
    "        if not fallback:\n",
    "            return None\n",
    "        fallback.sort(key=lambda x: (x[1], -x[2]))\n",
    "        return fallback[0][0]\n",
    "\n",
    "    candidates.sort(key=lambda x: (x[1], -x[2]))\n",
    "    return candidates[0][0]\n",
    "\n",
    "\n",
    "# ---------------- ë¡œë”©/ê³„ì‚° ----------------\n",
    "def _load_timeseries(path: str, sheet_name=0) -> Tuple[pd.Series, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    ì—‘ì…€ì—ì„œ ì‹œê³„ì—´(ë‚ ì§œ, ê°’)ì„ ì¶”ì¶œí•´ Series ë°˜í™˜.\n",
    "    - ë‚ ì§œ ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ DatetimeIndex ì •ë ¬\n",
    "    - ì—†ìœ¼ë©´ ë‹¨ìˆœ ìˆœë²ˆ ì¸ë±ìŠ¤\n",
    "    \"\"\"\n",
    "    df = detect_header_and_read(path, sheet_name=sheet_name)\n",
    "\n",
    "    date_col = _pick_date_col(df)\n",
    "    value_col = _pick_value_col(df, exclude_cols=[date_col] if date_col else [])\n",
    "\n",
    "    if value_col is None:\n",
    "        raise ValueError(\"ìˆ«ìí˜• ì‹œê³„ì—´ ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (í—¤ë”/í˜•ì‹ í™•ì¸ í•„ìš”)\")\n",
    "\n",
    "    if date_col is not None:\n",
    "        dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
    "        df = df.loc[dt.notna()].copy()\n",
    "        df.index = pd.to_datetime(df[date_col], errors=\"coerce\")\n",
    "        df = df.sort_index()\n",
    "    else:\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "    s = _as_numeric_series(df[value_col]).astype(float).dropna()\n",
    "\n",
    "    # ê°™ì€ ë‚ ì§œ ì¤‘ë³µ â†’ í‰ê· \n",
    "    if isinstance(df.index, pd.DatetimeIndex) and s.index.has_duplicates:\n",
    "        s = s.groupby(level=0).mean()\n",
    "\n",
    "    return s.sort_index(), df\n",
    "\n",
    "\n",
    "# ---------------- ì„ê³„ì¹˜ ê¸°ë°˜ í”Œë˜ê·¸ ê³„ì‚° ----------------\n",
    "def compute_threshold_flag(\n",
    "    s: pd.Series,\n",
    "    indicator_id: Optional[str] = None,\n",
    "    window: int = 60,\n",
    "    k: float = 2.0,\n",
    ") -> Tuple[str, dict]:\n",
    "    \"\"\"\n",
    "    1) 60ì¼ ë¡¤ë§ í‰ê· (mu), í‘œì¤€í¸ì°¨(sd) ê³„ì‚°\n",
    "    2) ì„ê³„ì¹˜ ê²°ì •\n",
    "       - CUSTOM_THRESHOLDSì— ë“±ë¡ëœ ID: ê³ ì • ì„ê³„ì¹˜ ì‚¬ìš©\n",
    "       - ê·¸ ì™¸: muÃ—1.1, 1.2, 1.3 ìë™ ì„ê³„ì¹˜ ì‚¬ìš©\n",
    "    3) ë§ˆì§€ë§‰ ê°’ì˜ ë ˆë²¨ íŒë‹¨\n",
    "       - level âˆˆ {normal, yellow, orange, red}\n",
    "       - íŒ€ì¥ë‹˜ ìš”ì²­: ì£¼ì˜ ì´ìƒ(yellow, orange, red)ì€ ëª¨ë‘ 'Y', ê·¸ ì™¸ëŠ” 'G'\n",
    "    ë°˜í™˜:\n",
    "      flag: 'G' ë˜ëŠ” 'Y'\n",
    "      info: ê°ì¢… ì°¸ê³  ì •ë³´(dict)\n",
    "    \"\"\"\n",
    "    if len(s) < MIN_PERIODS:\n",
    "        # ë°ì´í„°ê°€ ë„ˆë¬´ ì§§ìœ¼ë©´ ë³´ìˆ˜ì ìœ¼ë¡œ G ì²˜ë¦¬\n",
    "        return \"G\", {\"reason\": \"too_short\", \"len\": len(s)}\n",
    "\n",
    "    roll_mean = s.rolling(window=window, min_periods=MIN_PERIODS).mean()\n",
    "    roll_std = s.rolling(window=window, min_periods=MIN_PERIODS).std(ddof=0)\n",
    "\n",
    "    last_val = s.iloc[-1]\n",
    "    mu = roll_mean.iloc[-1]\n",
    "    sd = roll_std.iloc[-1]\n",
    "\n",
    "    if pd.isna(mu) or pd.isna(sd) or sd == 0:\n",
    "        return \"G\", {\n",
    "            \"reason\": \"nan_or_zero_std\",\n",
    "            \"mu\": mu,\n",
    "            \"sd\": sd,\n",
    "            \"last\": last_val,\n",
    "        }\n",
    "\n",
    "    # z-scoreëŠ” ì°¸ê³ ìš©ìœ¼ë¡œë§Œ ê³„ì‚°\n",
    "    z = (last_val - mu) / sd\n",
    "\n",
    "    # 1) ì„ê³„ì¹˜ ê²°ì • (ê³ ì •/ìë™)\n",
    "    ind_id = (indicator_id or \"\").upper()\n",
    "    cfg = CUSTOM_THRESHOLDS.get(ind_id)\n",
    "\n",
    "    if cfg is not None:\n",
    "        # âœ… ê³ ì • ì„ê³„ì¹˜ ì‚¬ìš©\n",
    "        direction = cfg.get(\"direction\", \"up\")\n",
    "        thr_yellow = cfg[\"yellow\"]\n",
    "        thr_orange = cfg[\"orange\"]\n",
    "        thr_red = cfg[\"red\"]\n",
    "        reason = \"custom_threshold\"\n",
    "    else:\n",
    "        # âœ… ìë™ ì„ê³„ì¹˜ (í‰ê·  Ã— ë¹„ìœ¨)\n",
    "        direction = \"up\"  # ê¸°ë³¸: ê°’ì´ ì˜¬ë¼ê°ˆìˆ˜ë¡ ìœ„í—˜í•œ ì§€í‘œë¡œ ê°€ì •\n",
    "        thr_yellow = mu * 1.1\n",
    "        thr_orange = mu * 1.2\n",
    "        thr_red = mu * 1.3\n",
    "        reason = \"auto_threshold\"\n",
    "\n",
    "    # 2) ë ˆë²¨ íŒì •\n",
    "    if direction == \"up\":\n",
    "        if last_val >= thr_red:\n",
    "            level = \"red\"\n",
    "        elif last_val >= thr_orange:\n",
    "            level = \"orange\"\n",
    "        elif last_val >= thr_yellow:\n",
    "            level = \"yellow\"\n",
    "        else:\n",
    "            level = \"normal\"\n",
    "    else:  # direction == \"down\": ê°’ì´ ì‘ì•„ì§ˆìˆ˜ë¡ ìœ„í—˜\n",
    "        if last_val <= thr_red:\n",
    "            level = \"red\"\n",
    "        elif last_val <= thr_orange:\n",
    "            level = \"orange\"\n",
    "        elif last_val <= thr_yellow:\n",
    "            level = \"yellow\"\n",
    "        else:\n",
    "            level = \"normal\"\n",
    "\n",
    "    # 3) íŒ€ì¥ë‹˜ ìš”ì²­: \"ì£¼ì˜ ì´ìƒì€ Y\" â†’ normalë§Œ G, ë‚˜ë¨¸ì§€ëŠ” ì „ë¶€ Y\n",
    "    if level == \"normal\":\n",
    "        flag = \"G\"\n",
    "    else:\n",
    "        flag = \"Y\"\n",
    "\n",
    "    info = {\n",
    "        \"last\": last_val,\n",
    "        \"mu\": mu,\n",
    "        \"sd\": sd,\n",
    "        \"zscore\": z,\n",
    "        \"thr_yellow\": thr_yellow,\n",
    "        \"thr_orange\": thr_orange,\n",
    "        \"thr_red\": thr_red,\n",
    "        \"level\": level,\n",
    "        \"reason\": reason,\n",
    "    }\n",
    "\n",
    "    # ì˜ˆì „ êµ¬ì¡° í˜¸í™˜ìš© í•„ë“œ(upper/lower)ëŠ” Noneìœ¼ë¡œ ë‘ \n",
    "    info[\"upper\"] = None\n",
    "    info[\"lower\"] = None\n",
    "\n",
    "    return flag, info\n",
    "\n",
    "\n",
    "# ---------------- ì—‘ì…€ ê¸°ë¡ ----------------\n",
    "def write_results_to_excel(\n",
    "    path: str,\n",
    "    flag: str,\n",
    "    mu: Optional[float],\n",
    "    sd: Optional[float],\n",
    "    sheet_name=0,\n",
    "):\n",
    "    \"\"\"\n",
    "    ì—‘ì…€ íŒŒì¼ì˜ C1/D1/E1 ì—…ë°ì´íŠ¸:\n",
    "      - C1: G ë˜ëŠ” Y (ì£¼ì˜ ì´ìƒì€ ëª¨ë‘ Y)\n",
    "      - D1: 60ì¼ ë¡¤ë§ í‰ê· (mu)\n",
    "      - E1: 60ì¼ ë¡¤ë§ í‘œì¤€í¸ì°¨(sd = Ïƒ)\n",
    "    \"\"\"\n",
    "    from openpyxl import load_workbook\n",
    "\n",
    "    wb = load_workbook(path)\n",
    "    ws = wb[wb.sheetnames[sheet_name]] if isinstance(sheet_name, int) else wb[sheet_name]\n",
    "\n",
    "    ws[\"C1\"] = flag\n",
    "\n",
    "    def _num_or_none(x):\n",
    "        try:\n",
    "            if x is None:\n",
    "                return None\n",
    "            if isinstance(x, (int, float)) and not (\n",
    "                isinstance(x, float) and np.isnan(x)\n",
    "            ):\n",
    "                return float(x)\n",
    "            return None\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    ws[\"D1\"] = _num_or_none(mu)  # 60ì¼ í‰ê· \n",
    "    ws[\"E1\"] = _num_or_none(sd)  # 60ì¼ í‘œì¤€í¸ì°¨(Ïƒ)\n",
    "\n",
    "    wb.save(path)\n",
    "\n",
    "\n",
    "# ---------------- ë©”ì¸ ë“œë¼ì´ë²„ ----------------\n",
    "def main():\n",
    "    results = []\n",
    "    for i in FILE_RANGE:\n",
    "        fname = f\"{FILE_PREFIX}{i:03d}.xlsx\"\n",
    "        fpath = os.path.join(BASE_DIR, fname)\n",
    "        if not os.path.exists(fpath):\n",
    "            results.append((fname, \"missing\", None))\n",
    "            print(f\"[SKIP] {fname} (file not found)\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            s, _df = _load_timeseries(fpath, sheet_name=SHEET_NAME)\n",
    "\n",
    "            # âœ… [ë³€ê²½] ì§€í‘œ IDë¥¼ ë„˜ê²¨ì„œ ì„ê³„ì¹˜ ê¸°ë°˜ í”Œë˜ê·¸ ê³„ì‚°\n",
    "            indicator_id = f\"{FILE_PREFIX}{i:03d}\"\n",
    "            flag, info = compute_threshold_flag(\n",
    "                s, indicator_id=indicator_id, window=WINDOW, k=K\n",
    "            )\n",
    "\n",
    "            mu = info.get(\"mu\") if isinstance(info, dict) else None\n",
    "            sd = info.get(\"sd\") if isinstance(info, dict) else None\n",
    "            write_results_to_excel(fpath, flag, mu, sd, sheet_name=SHEET_NAME)\n",
    "\n",
    "            ztxt = (\n",
    "                f\"{info.get('zscore'):.2f}\"\n",
    "                if isinstance(info, dict)\n",
    "                and \"zscore\" in info\n",
    "                and pd.notna(info.get(\"zscore\"))\n",
    "                else \"n/a\"\n",
    "            )\n",
    "            mutxt = (\n",
    "                f\"{mu:.6g}\"\n",
    "                if isinstance(mu, (int, float)) and not pd.isna(mu)\n",
    "                else \"n/a\"\n",
    "            )\n",
    "            sdtxt = (\n",
    "                f\"{sd:.6g}\"\n",
    "                if isinstance(sd, (int, float)) and not pd.isna(sd)\n",
    "                else \"n/a\"\n",
    "            )\n",
    "\n",
    "            level = info.get(\"level\") if isinstance(info, dict) else \"n/a\"\n",
    "\n",
    "            print(\n",
    "                f\"[OK] {fname} -> C1='{flag}', level={level}, \"\n",
    "                f\"D1(mu)={mutxt}, E1(sd)={sdtxt} (z={ztxt})\"\n",
    "            )\n",
    "            results.append((fname, flag, info))\n",
    "        except Exception as e:\n",
    "            err_msg = str(e)\n",
    "            print(f\"[ERR] {fname}: {err_msg}\")\n",
    "            # ê°„ë‹¨ í”„ë¡œë¸Œ: ì»¬ëŸ¼/íƒ€ì… íŒíŠ¸ ì¶œë ¥ (í—¤ë”/í˜•ì‹ ì¶”ì )\n",
    "            try:\n",
    "                df_probe = detect_header_and_read(fpath, sheet_name=SHEET_NAME)\n",
    "                print(f\"  -> columns: {list(df_probe.columns)}\")\n",
    "                sample_info = []\n",
    "                for c in df_probe.columns[:10]:\n",
    "                    sample_info.append(f\"{c}:{str(df_probe[c].dtype)}\")\n",
    "                print(\"  -> dtypes(head):\", \", \".join(sample_info))\n",
    "            except Exception as e2:\n",
    "                print(f\"  -> probe failed: {e2}\")\n",
    "            results.append((fname, \"error\", err_msg))\n",
    "\n",
    "    # ìš”ì•½ CSV ì €ì¥\n",
    "    summary_path = os.path.join(\n",
    "        BASE_DIR,\n",
    "        f\"vol_band_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\",\n",
    "    )\n",
    "    rows = []\n",
    "    for fname, flag, info in results:\n",
    "        row = {\"file\": fname, \"flag\": flag}\n",
    "        if isinstance(info, dict):\n",
    "            row.update(\n",
    "                {\n",
    "                    \"last\": info.get(\"last\"),\n",
    "                    \"mu\": info.get(\"mu\"),\n",
    "                    \"sd\": info.get(\"sd\"),\n",
    "                    \"upper\": info.get(\"upper\"),\n",
    "                    \"lower\": info.get(\"lower\"),\n",
    "                    \"zscore\": info.get(\"zscore\"),\n",
    "                    \"thr_yellow\": info.get(\"thr_yellow\"),\n",
    "                    \"thr_orange\": info.get(\"thr_orange\"),\n",
    "                    \"thr_red\": info.get(\"thr_red\"),\n",
    "                    \"level\": info.get(\"level\"),\n",
    "                    \"reason\": info.get(\"reason\"),\n",
    "                }\n",
    "            )\n",
    "        elif isinstance(info, str):\n",
    "            row[\"error\"] = info\n",
    "        rows.append(row)\n",
    "    pd.DataFrame(rows).to_csv(summary_path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"\\nìš”ì•½ ì €ì¥: {summary_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5901d068-d7ea-4276-b40e-5570322d9f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] IND008: file not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] IND011: ë°ì´í„° ê¸¸ì´ ë¶€ì¡±(len=12)\n",
      "[SKIP] IND012: ë°ì´í„° ê¸¸ì´ ë¶€ì¡±(len=11)\n",
      "[SKIP] IND013: ë°ì´í„° ê¸¸ì´ ë¶€ì¡±(len=10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] IND017: ë°ì´í„° ê¸¸ì´ ë¶€ì¡±(len=4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] IND021: ë°ì´í„° ê¸¸ì´ ë¶€ì¡±(len=12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] IND027: file not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] IND032: file not found\n",
      "[SKIP] IND033: file not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] IND036: ë°ì´í„° ê¸¸ì´ ë¶€ì¡±(len=12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] IND039: ë°ì´í„° ê¸¸ì´ ë¶€ì¡±(len=12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] IND055: ë°ì´í„° ê¸¸ì´ ë¶€ì¡±(len=12)\n",
      "[SKIP] IND056: ë°ì´í„° ê¸¸ì´ ë¶€ì¡±(len=12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] IND061: ë°ì´í„° ê¸¸ì´ ë¶€ì¡±(len=10)\n",
      "[SKIP] IND063: ë°ì´í„° ê¸¸ì´ ë¶€ì¡±(len=3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] IND067: file not found\n",
      "[SKIP] IND069: ë°ì´í„° ê¸¸ì´ ë¶€ì¡±(len=25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = np.nanvar(series.astype(float))\n",
      "C:\\Users\\amongpapa\\AppData\\Local\\Temp\\ipykernel_19792\\4045901939.py:206: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] IND082: file not found\n",
      "[SKIP] IND083: file not found\n",
      "[SKIP] IND084: file not found\n",
      "[SKIP] IND085: file not found\n",
      "[SKIP] IND086: file not found\n",
      "[SKIP] IND087: file not found\n",
      "[SKIP] IND088: file not found\n",
      "[SKIP] IND089: file not found\n",
      "[SKIP] IND090: file not found\n",
      "[SKIP] IND091: file not found\n",
      "[SKIP] IND092: file not found\n",
      "[SKIP] IND093: file not found\n",
      "[SKIP] IND094: file not found\n",
      "[SKIP] IND095: file not found\n",
      "[SKIP] IND096: file not found\n",
      "[SKIP] IND097: file not found\n",
      "[SKIP] IND098: file not found\n",
      "[SKIP] IND099: file not found\n",
      "[SKIP] IND100: file not found\n",
      "[SKIP] IND101: file not found\n",
      "[SKIP] IND102: file not found\n",
      "[SKIP] IND103: file not found\n",
      "[SKIP] IND104: file not found\n",
      "[SKIP] IND105: file not found\n",
      "[SKIP] IND106: file not found\n",
      "[SKIP] IND107: file not found\n",
      "[SKIP] IND108: file not found\n",
      "[SKIP] IND109: file not found\n",
      "[SKIP] IND110: file not found\n",
      "[SKIP] IND111: file not found\n",
      "[SKIP] IND112: file not found\n",
      "[SKIP] IND113: file not found\n",
      "[SKIP] IND114: file not found\n",
      "[SKIP] IND115: file not found\n",
      "[SKIP] IND116: file not found\n",
      "[SKIP] IND117: file not found\n",
      "[SKIP] IND118: file not found\n",
      "[SKIP] IND119: file not found\n",
      "[SKIP] IND120: file not found\n",
      "[SKIP] IND121: file not found\n",
      "[SKIP] IND122: file not found\n",
      "[SKIP] IND123: file not found\n",
      "[SKIP] IND124: file not found\n",
      "[SKIP] IND125: file not found\n",
      "[SKIP] IND126: file not found\n",
      "[SKIP] IND127: file not found\n",
      "[SKIP] IND128: file not found\n",
      "[SKIP] IND129: file not found\n",
      "[SKIP] IND130: file not found\n",
      "[SKIP] IND131: file not found\n",
      "[SKIP] IND132: file not found\n",
      "[SKIP] IND133: file not found\n",
      "[SKIP] IND134: file not found\n",
      "[SKIP] IND135: file not found\n",
      "[SKIP] IND136: file not found\n",
      "[SKIP] IND137: file not found\n",
      "[SKIP] IND138: file not found\n",
      "[SKIP] IND139: file not found\n",
      "[SKIP] IND140: file not found\n",
      "[SKIP] IND141: file not found\n",
      "[SKIP] IND142: file not found\n",
      "[SKIP] IND143: file not found\n",
      "[SKIP] IND144: file not found\n",
      "[SKIP] IND145: file not found\n",
      "[SKIP] IND146: file not found\n",
      "[SKIP] IND147: file not found\n",
      "[SKIP] IND148: file not found\n",
      "[SKIP] IND149: file not found\n",
      "[SKIP] IND150: file not found\n",
      "[SKIP] IND151: file not found\n",
      "[OK] ì €ì¥ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\market_data\\market_data.xlsx (rows=576)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "r\"\"\"\n",
    "IND001~IND151 ì—‘ì…€ë§Œ ì‚¬ìš©í•˜ì—¬ íŒŒìƒì§€í‘œë¥¼ ê³„ì‚°í•˜ê³ \n",
    "id, data(=JSON ë¬¸ìì—´) 2-ì»¬ëŸ¼ í˜•ì‹ìœ¼ë¡œ í•˜ë‚˜ì˜ ì—‘ì…€ íŒŒì¼ì— ì €ì¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì €ì¥ ìœ„ì¹˜:\n",
    "  C:\\Users\\amongpapa\\chartup\\go_scen\\data\\market_data\\market_data.xlsx\n",
    "\n",
    "ì„¤ì¹˜:\n",
    "  pip install pandas numpy openpyxl\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from typing import Optional, Tuple, Dict\n",
    "\n",
    "# ================= íŒ€ì¥ë‹˜ í™˜ê²½ ì„¤ì • =================\n",
    "BASE_DIR   = r\"C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\"                  # IND ì—‘ì…€ í´ë”\n",
    "OUT_PATH   = r\"C:\\Users\\amongpapa\\chartup\\go_scen\\data\\market_data\\market_data.xlsx\"\n",
    "FILE_PREFIX = \"IND\"\n",
    "FILE_RANGE  = range(1, 152)                                                  # 001~151\n",
    "SHEET_NAME  = 0\n",
    "\n",
    "WINDOWS_RET = [20, 60, 120]\n",
    "ANNUAL_DAYS = 252\n",
    "VOL_QUANTILES = (0.33, 0.66)\n",
    "\n",
    "# ìƒê´€/ë² íƒ€ìš© ë²¤ì¹˜ë§ˆí¬ ë§¤í•‘(í•„ìš” ì‹œ ì±„ìš°ì„¸ìš”: ì˜ˆ 'KOSPI': 'IND001')\n",
    "BENCHMARK_MAP: Dict[str, str] = {}\n",
    "\n",
    "DATE_COL_HINTS  = [\"date\", \"ë‚ ì§œ\", \"ì¼ì\", \"time\", \"ì¼ì‹œ\"]\n",
    "VALUE_COL_HINTS = [\"close\", \"price\", \"value\", \"index\", \"ì§€ìˆ˜\", \"ì¢…ê°€\", \"ê°€ê²©\", \"ê°’\", \"ìˆ˜ì¹˜\"]\n",
    "\n",
    "MIN_PERIODS = 30  # ì§§ì€ ë°ì´í„° ë³´í˜¸\n",
    "# ====================================================\n",
    "\n",
    "\n",
    "# ---------------- ìœ í‹¸: ì—‘ì…€ í—¤ë” ìë™ ê°ì§€ ----------------\n",
    "def detect_header_and_read(path, sheet_name=0, max_scan=10) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    í—¤ë”/ë°ì´í„° ì‹œì‘í–‰ ë¶ˆëª…í™• ì—‘ì…€ì„ ì•ˆì „í•˜ê²Œ ì½ê¸°:\n",
    "      1) ì¼ë°˜ ë¡œë“œ í›„ í’ˆì§ˆ ì ê²€, í†µê³¼ì‹œ ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
    "      2) ìœ„ì—ì„œë¶€í„° max_scanì¤„ì„ í—¤ë” í›„ë³´ë¡œ ìŠ¤ì½”ì–´ë§í•´ ìµœì  í—¤ë” ì±„íƒ\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df0 = pd.read_excel(path, sheet_name=sheet_name, engine=\"openpyxl\", header=0)\n",
    "    except Exception:\n",
    "        df0 = pd.read_excel(path, sheet_name=sheet_name, engine=\"openpyxl\", header=None)\n",
    "\n",
    "    if df0.shape[0] == 0:\n",
    "        df0 = pd.read_excel(path, sheet_name=sheet_name, engine=\"openpyxl\", header=None)\n",
    "\n",
    "    if _likely_good(df0):\n",
    "        return _clean_columns(df0)\n",
    "\n",
    "    raw = pd.read_excel(path, sheet_name=sheet_name, engine=\"openpyxl\", header=None)\n",
    "    nrows = min(max_scan, len(raw))\n",
    "    best_score, best_row = -1, 0\n",
    "    for hdr in range(nrows):\n",
    "        tmp = raw.copy()\n",
    "        tmp.columns = tmp.iloc[hdr].astype(str).str.strip()\n",
    "        tmp = tmp.iloc[hdr + 1 :].reset_index(drop=True)\n",
    "        score = _numeric_score(tmp, lookahead=5)\n",
    "        if score > best_score:\n",
    "            best_score, best_row = score, hdr\n",
    "\n",
    "    raw.columns = raw.iloc[best_row].astype(str).str.strip()\n",
    "    df = raw.iloc[best_row + 1 :].reset_index(drop=True)\n",
    "    return _clean_columns(df)\n",
    "\n",
    "def _likely_good(df: pd.DataFrame) -> bool:\n",
    "    return _numeric_score(df, lookahead=5) >= 2\n",
    "\n",
    "def _numeric_score(df: pd.DataFrame, lookahead: int = 5) -> int:\n",
    "    head = df.head(lookahead)\n",
    "    cnt = 0\n",
    "    for c in head.columns:\n",
    "        s = head[c]\n",
    "        s_num = _as_numeric_series(s, strict=False)\n",
    "        if s_num.notna().mean() >= 0.5:\n",
    "            cnt += 1\n",
    "    return cnt\n",
    "\n",
    "def _clean_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df.columns = [re.sub(r\"\\s+\", \" \", str(c)).strip() for c in df.columns]\n",
    "    return df\n",
    "\n",
    "\n",
    "# ---------------- ìˆ«ì ë¬¸ìì—´ â†’ float ì‹œë¦¬ì¦ˆ(ê°•ë ¥ ë°©ì–´) ----------------\n",
    "def _as_numeric_series(s: pd.Series, strict: bool = True) -> pd.Series:\n",
    "    \"\"\"\n",
    "    ë¬¸ì ì„ì¸ ìˆ«ìë¥¼ floatë¡œ ì •ì œ(%, ê´„í˜¸ìŒìˆ˜, ì½¤ë§ˆ ë“±)í•˜ì—¬ í•­ìƒ Series ë°˜í™˜.\n",
    "    strict=False ì´ë©´ ì˜ˆì™¸ëŠ” ì¡°ìš©íˆ NaNìœ¼ë¡œ ë³´ëƒ„.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # ì´ë¯¸ ìˆ«ìí˜•ì´ë©´ ì¡°ìš©íˆ ë³€í™˜\n",
    "        if pd.api.types.is_numeric_dtype(s):\n",
    "            return pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "        # ì–´ë–¤ íƒ€ì…ì´ë“  ë¬¸ìì—´ dtypeìœ¼ë¡œ ê°•ì œ(Series.str ì‚¬ìš© ë³´ì¥)\n",
    "        ss = s.astype(\"string\")  # pandas StringDtype\n",
    "        ss = ss.str.strip()\n",
    "\n",
    "        # ë¹ˆê°’/ëŒ€ì‹œë¥˜ â†’ NaN\n",
    "        ss = ss.replace({\"\": pd.NA, \"-\": pd.NA, \"â€”\": pd.NA, \"_\": pd.NA, \"nan\": pd.NA, \"NaN\": pd.NA, \"None\": pd.NA})\n",
    "\n",
    "        # ê´„í˜¸ ìŒìˆ˜\n",
    "        neg_mask = ss.str.match(r\"^\\(.*\\)$\", na=False)\n",
    "        ss2 = ss.str.replace(r\"^\\((.*)\\)$\", r\"\\1\", regex=True)\n",
    "\n",
    "        # ì½¤ë§ˆ ì œê±°, % ì œê±°\n",
    "        ss2 = ss2.str.replace(\",\", \"\", regex=False)\n",
    "        pct_mask = ss2.str.endswith(\"%\", na=False)\n",
    "        ss2 = ss2.str.replace(\"%\", \"\", regex=False)\n",
    "\n",
    "        num = pd.to_numeric(ss2, errors=\"coerce\")\n",
    "\n",
    "        # ê´„í˜¸ ìŒìˆ˜ ì ìš©\n",
    "        if neg_mask.any():\n",
    "            idx = neg_mask & num.notna()\n",
    "            num.loc[idx] = -num.loc[idx].abs()\n",
    "\n",
    "        # í¼ì„¼íŠ¸ â†’ /100\n",
    "        if pct_mask.any():\n",
    "            idx = pct_mask & num.notna()\n",
    "            num.loc[idx] = num.loc[idx] / 100.0\n",
    "\n",
    "        # í•­ìƒ Series\n",
    "        if not isinstance(num, pd.Series):\n",
    "            num = pd.Series(num, index=s.index, dtype=\"float64\")\n",
    "        return num.astype(float)\n",
    "\n",
    "    except Exception:\n",
    "        if strict:\n",
    "            raise\n",
    "        # ë¬¸ì œ ìˆìœ¼ë©´ ì „ë¶€ NaNìœ¼ë¡œ ë¦¬í„´(ìŠ¤ì½”ì–´ë§ìš©)\n",
    "        return pd.to_numeric(pd.Series([pd.NA]*len(s), index=s.index), errors=\"coerce\")\n",
    "\n",
    "\n",
    "# ---------------- ë‚ ì§œ/ê°’ ì»¬ëŸ¼ ìë™ ì„ íƒ ----------------\n",
    "def _pick_date_col(df: pd.DataFrame) -> Optional[str]:\n",
    "    for hint in DATE_COL_HINTS:\n",
    "        for c in df.columns:\n",
    "            if hint.lower() in str(c).lower():\n",
    "                return c\n",
    "    dt_cols = [c for c in df.columns if pd.api.types.is_datetime64_any_dtype(df[c])]\n",
    "    if dt_cols:\n",
    "        return dt_cols[0]\n",
    "    best_col, best_ratio = None, 0.0\n",
    "    for c in df.columns:\n",
    "        try:\n",
    "            converted = pd.to_datetime(df[c], errors=\"coerce\", infer_datetime_format=True)\n",
    "            ratio = converted.notna().mean()\n",
    "            if ratio > best_ratio and ratio >= 0.7:\n",
    "                best_col, best_ratio = c, ratio\n",
    "        except Exception:\n",
    "            pass\n",
    "    return best_col\n",
    "\n",
    "def _pick_value_col(df: pd.DataFrame, exclude_cols: list) -> Optional[str]:\n",
    "    # íŒíŠ¸ ìš°ì„ \n",
    "    for hint in VALUE_COL_HINTS:\n",
    "        for c in df.columns:\n",
    "            if c in exclude_cols: \n",
    "                continue\n",
    "            if hint.lower() in str(c).lower():\n",
    "                return c\n",
    "\n",
    "    # ìˆ«ìí˜• í›„ë³´ ìŠ¤ì½”ì–´ë§\n",
    "    candidates = []\n",
    "    for c in df.columns:\n",
    "        if c in exclude_cols:\n",
    "            continue\n",
    "        try:\n",
    "            series = _as_numeric_series(df[c], strict=False)\n",
    "            na_ratio = pd.isna(series).mean()\n",
    "            var = np.nanvar(series.astype(float))\n",
    "            if (~pd.isna(series)).sum() >= max(MIN_PERIODS, 10) and var > 0:\n",
    "                candidates.append((c, na_ratio, var))\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    if not candidates:\n",
    "        return None\n",
    "\n",
    "    candidates.sort(key=lambda x: (x[1], -x[2]))  # ê²°ì¸¡â†“, ë¶„ì‚°â†‘\n",
    "    return candidates[0][0]\n",
    "\n",
    "\n",
    "# ---------------- ì‹œê³„ì—´ ë¡œë”© ----------------\n",
    "def load_series_from_excel(path: str, sheet_name=0) -> pd.Series:\n",
    "    \"\"\"ì—‘ì…€ì—ì„œ (ë‚ ì§œ, ê°’) ì‹œê³„ì—´ Series ë°˜í™˜ (DatetimeIndex ì •ë ¬)\"\"\"\n",
    "    df = detect_header_and_read(path, sheet_name=sheet_name)\n",
    "\n",
    "    date_col = _pick_date_col(df)\n",
    "    value_col = _pick_value_col(df, exclude_cols=[date_col] if date_col else [])\n",
    "    if value_col is None:\n",
    "        raise ValueError(\"ìˆ«ìí˜• ì‹œê³„ì—´ ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    if date_col is not None:\n",
    "        dt = pd.to_datetime(df[date_col], errors=\"coerce\", infer_datetime_format=True)\n",
    "        df = df.loc[dt.notna()].copy()\n",
    "        df.index = pd.to_datetime(df[date_col], errors=\"coerce\")\n",
    "        df = df.sort_index()\n",
    "    else:\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "    s = _as_numeric_series(df[value_col]).astype(float).dropna()\n",
    "\n",
    "    # ê°™ì€ ë‚ ì§œ ì¤‘ë³µ â†’ í‰ê· \n",
    "    if isinstance(df.index, pd.DatetimeIndex) and s.index.has_duplicates:\n",
    "        s = s.groupby(level=0).mean()\n",
    "\n",
    "    s = s.sort_index()\n",
    "    if len(s) < MIN_PERIODS:\n",
    "        raise ValueError(f\"ë°ì´í„° ê¸¸ì´ ë¶€ì¡±(len={len(s)})\")\n",
    "\n",
    "    return s\n",
    "\n",
    "\n",
    "# ---------------- ë³´ì¡° ê³„ì‚° í•¨ìˆ˜ ----------------\n",
    "def pct_return(s: pd.Series, days: int) -> Optional[float]:\n",
    "    if len(s) <= days:\n",
    "        return None\n",
    "    return float(s.iloc[-1] / s.iloc[-days-1] - 1.0)\n",
    "\n",
    "def ann_return_from_period(r: Optional[float], days: int) -> Optional[float]:\n",
    "    if r is None:\n",
    "        return None\n",
    "    try:\n",
    "        return float((1.0 + r) ** (ANNUAL_DAYS / days) - 1.0)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def rolling_vol_annualized(s: pd.Series, days: int) -> Optional[float]:\n",
    "    if len(s) < max(days+1, MIN_PERIODS):\n",
    "        return None\n",
    "    rets = s.pct_change()\n",
    "    vol = rets.rolling(window=days, min_periods=int(days*0.6)).std(ddof=0)\n",
    "    last_vol = vol.iloc[-1]\n",
    "    if pd.isna(last_vol):\n",
    "        return None\n",
    "    return float(last_vol * np.sqrt(ANNUAL_DAYS))\n",
    "\n",
    "def drawdown_stats(s: pd.Series, lookback_days: int) -> Tuple[Optional[float], Optional[float]]:\n",
    "    if len(s) < max(lookback_days, MIN_PERIODS):\n",
    "        return (None, None)\n",
    "    sub = s.iloc[-lookback_days:]\n",
    "    peak = sub.cummax()\n",
    "    dd = sub / peak - 1.0\n",
    "    mdd = dd.min()\n",
    "    curr_dd = dd.iloc[-1]\n",
    "    return (float(mdd), float(curr_dd))\n",
    "\n",
    "def sma(s: pd.Series, days: int) -> Optional[float]:\n",
    "    if len(s) < days:\n",
    "        return None\n",
    "    return float(s.rolling(days).mean().iloc[-1])\n",
    "\n",
    "def ema(s: pd.Series, days: int) -> Optional[float]:\n",
    "    if len(s) < days:\n",
    "        return None\n",
    "    return float(s.ewm(span=days, adjust=False).mean().iloc[-1])\n",
    "\n",
    "def gap_pct(price: float, ref: Optional[float]) -> Optional[float]:\n",
    "    if ref is None or ref == 0 or price is None:\n",
    "        return None\n",
    "    return float(price / ref - 1.0)\n",
    "\n",
    "def golden_dead_cross_state(s: pd.Series, short=20, long=60) -> Optional[str]:\n",
    "    if len(s) < long + 1:\n",
    "        return None\n",
    "    sma_s = s.rolling(short).mean()\n",
    "    sma_l = s.rolling(long).mean()\n",
    "    prev = np.sign(sma_s.iloc[-2] - sma_l.iloc[-2])\n",
    "    curr = np.sign(sma_s.iloc[-1] - sma_l.iloc[-1])\n",
    "    if prev <= 0 and curr > 0:\n",
    "        return \"golden\"\n",
    "    elif prev >= 0 and curr < 0:\n",
    "        return \"dead\"\n",
    "    else:\n",
    "        return \"none\"\n",
    "\n",
    "def slope_tstat_lastN(s: pd.Series, N: int = 60) -> Tuple[Optional[float], Optional[float]]:\n",
    "    if len(s) < N:\n",
    "        return (None, None)\n",
    "    y = s.iloc[-N:].values.astype(float)\n",
    "    x = np.arange(N).astype(float)\n",
    "    x_mean = x.mean()\n",
    "    y_mean = y.mean()\n",
    "    cov_xy = np.sum((x - x_mean) * (y - y_mean))\n",
    "    var_x = np.sum((x - x_mean) ** 2)\n",
    "    if var_x == 0:\n",
    "        return (None, None)\n",
    "    beta1 = cov_xy / var_x\n",
    "    y_hat = (beta1 * (x - x_mean)) + y_mean\n",
    "    resid = y - y_hat\n",
    "    s2 = np.sum(resid**2) / (N - 2)\n",
    "    se_beta1 = math.sqrt(s2 / var_x)\n",
    "    tstat = beta1 / se_beta1 if se_beta1 != 0 else None\n",
    "    return (float(beta1), float(tstat) if tstat is not None else None)\n",
    "\n",
    "def pos_in_52w(s: pd.Series) -> Optional[float]:\n",
    "    if len(s) < 20:\n",
    "        return None\n",
    "    look = s.iloc[-min(len(s), 252):]\n",
    "    hi, lo = float(look.max()), float(look.min())\n",
    "    last = float(look.iloc[-1])\n",
    "    if hi == lo:\n",
    "        return None\n",
    "    return float((last - lo) / (hi - lo))\n",
    "\n",
    "def vol_regime_label(s: pd.Series, days: int = 60) -> Optional[str]:\n",
    "    if len(s) < max(days+20, MIN_PERIODS+20):\n",
    "        return None\n",
    "    rets = s.pct_change()\n",
    "    vol = rets.rolling(window=days, min_periods=int(days*0.6)).std(ddof=0) * np.sqrt(ANNUAL_DAYS)\n",
    "    curr = vol.iloc[-1]\n",
    "    hist = vol.dropna().values\n",
    "    if np.isnan(curr) or len(hist) < 30:\n",
    "        return None\n",
    "    q1, q2 = np.quantile(hist, VOL_QUANTILES)\n",
    "    if curr < q1:\n",
    "        return \"low\"\n",
    "    elif curr < q2:\n",
    "        return \"mid\"\n",
    "    else:\n",
    "        return \"high\"\n",
    "\n",
    "def trend_label_from_slope(s: pd.Series, N: int = 60) -> Optional[str]:\n",
    "    slope, t = slope_tstat_lastN(s, N)\n",
    "    if slope is None or t is None:\n",
    "        return None\n",
    "    if t > 2:\n",
    "        return \"up\"\n",
    "    elif t < -2:\n",
    "        return \"down\"\n",
    "    else:\n",
    "        return \"flat\"\n",
    "\n",
    "def compute_beta(x: pd.Series, mkt: pd.Series, days: int = 60) -> Optional[float]:\n",
    "    if len(x) < days+1 or len(mkt) < days+1:\n",
    "        return None\n",
    "    rx = x.pct_change().iloc[-days:]\n",
    "    rm = mkt.pct_change().iloc[-days:]\n",
    "    df = pd.concat([rx, rm], axis=1).dropna()\n",
    "    if len(df) < int(days*0.6):\n",
    "        return None\n",
    "    cov = np.cov(df.iloc[:,0], df.iloc[:,1])[0,1]\n",
    "    var = np.var(df.iloc[:,1])\n",
    "    if var == 0:\n",
    "        return None\n",
    "    return float(cov / var)\n",
    "\n",
    "def corr_rolling(x: pd.Series, y: pd.Series, days: int = 60) -> Optional[float]:\n",
    "    if len(x) < days+1 or len(y) < days+1:\n",
    "        return None\n",
    "    rx = x.pct_change()\n",
    "    ry = y.pct_change()\n",
    "    corr = rx.rolling(days).corr(ry)\n",
    "    val = corr.iloc[-1]\n",
    "    return float(val) if pd.notna(val) else None\n",
    "\n",
    "\n",
    "# ---------------- ë©”ì¸ íŒŒì´í”„ë¼ì¸ ----------------\n",
    "def main():\n",
    "    series_map: Dict[str, pd.Series] = {}\n",
    "    for i in FILE_RANGE:\n",
    "        fid = f\"{FILE_PREFIX}{i:03d}\"\n",
    "        fpath = os.path.join(BASE_DIR, f\"{fid}.xlsx\")\n",
    "        if not os.path.exists(fpath):\n",
    "            print(f\"[SKIP] {fid}: file not found\")\n",
    "            continue\n",
    "        try:\n",
    "            s = load_series_from_excel(fpath, sheet_name=SHEET_NAME)\n",
    "            series_map[fid] = s\n",
    "        except Exception as e:\n",
    "            # í•µì‹¬: ë¬¸ìì—´ ì²˜ë¦¬/ì»¬ëŸ¼ë§¤í•‘ ì‹¤íŒ¨ ì‹œì—ë„ ì›ì¸ ì¶œë ¥í•˜ê³  ê³„ì†\n",
    "            print(f\"[SKIP] {fid}: {e}\")\n",
    "\n",
    "    if not series_map:\n",
    "        raise RuntimeError(\"ìœ íš¨í•œ IND ì‹œê³„ì—´ì„ í•˜ë‚˜ë„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    # ë²¤ì¹˜ë§ˆí¬ í•´ì„(ì˜µì…˜)\n",
    "    bench_series: Dict[str, pd.Series] = {}\n",
    "    for name, ind in BENCHMARK_MAP.items():\n",
    "        if ind in series_map:\n",
    "            bench_series[name] = series_map[ind]\n",
    "\n",
    "    rows = []\n",
    "    now_str = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    for fid, s in series_map.items():\n",
    "        last = float(s.iloc[-1])\n",
    "        asof = str(s.index[-1]) if isinstance(s.index, pd.DatetimeIndex) else now_str\n",
    "\n",
    "        # ë³€ë™ì„±/ìˆ˜ìµë¥ \n",
    "        rets = {}; rets_ann = {}; vols = {}\n",
    "        for d in WINDOWS_RET:\n",
    "            r = pct_return(s, d)\n",
    "            rets[f\"{d}d\"] = r\n",
    "            rets_ann[f\"{d}d_ann\"] = ann_return_from_period(r, d)\n",
    "            vols[f\"{d}d_vol_ann\"] = rolling_vol_annualized(s, d)\n",
    "\n",
    "        # ì„±ê³¼(YTD/1M/3M/6M/1Y)\n",
    "        period_map = {\"1m\":21, \"3m\":63, \"6m\":126, \"1y\":252}\n",
    "        perf = {k: pct_return(s, d) for k, d in period_map.items()}\n",
    "        if isinstance(s.index, pd.DatetimeIndex):\n",
    "            year = s.index[-1].year\n",
    "            ytd_slice = s[s.index.year == year]\n",
    "            ytd_first = ytd_slice.iloc[0] if len(ytd_slice) > 0 else None\n",
    "            perf[\"ytd\"] = float(last / ytd_first - 1.0) if ytd_first and ytd_first != 0 else None\n",
    "        else:\n",
    "            perf[\"ytd\"] = None\n",
    "\n",
    "        # ë‚™í­\n",
    "        mdd6, dd6   = drawdown_stats(s, 126)\n",
    "        mdd1y, dd1y = drawdown_stats(s, 252)\n",
    "\n",
    "        # ì¶”ì„¸/ê´´ë¦¬\n",
    "        sma20, sma60, sma120 = sma(s,20), sma(s,60), sma(s,120)\n",
    "        ema20, ema60, ema120 = ema(s,20), ema(s,60), ema(s,120)\n",
    "        gaps = {\n",
    "            \"gap_to_sma20\":  gap_pct(last, sma20),\n",
    "            \"gap_to_sma60\":  gap_pct(last, sma60),\n",
    "            \"gap_to_sma120\": gap_pct(last, sma120),\n",
    "            \"gap_to_ema20\":  gap_pct(last, ema20),\n",
    "            \"gap_to_ema60\":  gap_pct(last, ema60),\n",
    "            \"gap_to_ema120\": gap_pct(last, ema120),\n",
    "        }\n",
    "        cross_20_60  = golden_dead_cross_state(s, 20, 60)\n",
    "        cross_60_120 = golden_dead_cross_state(s, 60, 120)\n",
    "\n",
    "        # ê¸°ìš¸ê¸°/t\n",
    "        slope60, t60 = slope_tstat_lastN(s, 60)\n",
    "\n",
    "        # 52ì£¼ ìœ„ì¹˜\n",
    "        pos52w = pos_in_52w(s)\n",
    "        pos52w_pct = float(pos52w*100.0) if pos52w is not None else None\n",
    "\n",
    "        # ë ˆì§\n",
    "        vol_reg   = vol_regime_label(s, 60)\n",
    "        trend_reg = trend_label_from_slope(s, 60)\n",
    "        regime    = f\"{trend_reg}-{vol_reg}\" if trend_reg and vol_reg else None\n",
    "\n",
    "        # ìƒê´€/ë² íƒ€(ì˜µì…˜)\n",
    "        corr_res = {}\n",
    "        beta_res = {}\n",
    "        for bname, bs in bench_series.items():\n",
    "            corr_res[bname] = corr_rolling(s, bs, 60)\n",
    "        mkt_key = next((k for k in [\"KOSPI\", \"S&P500\", \"KOSDAQ\"] if k in bench_series), None)\n",
    "        if mkt_key:\n",
    "            beta_res[mkt_key] = compute_beta(s, bench_series[mkt_key], 60)\n",
    "\n",
    "        # ìš”ì•½ ìµœê·¼ê°’\n",
    "        latest = {\"last\": last, \"asof\": asof, \"ytd\": perf.get(\"ytd\"),\n",
    "                  \"1m\": perf.get(\"1m\"), \"3m\": perf.get(\"3m\"),\n",
    "                  \"6m\": perf.get(\"6m\"), \"1y\": perf.get(\"1y\"), \"note\": None}\n",
    "\n",
    "        # === id, data(JSON) ì €ì¥ ===\n",
    "        def add_row(suffix: str, obj):\n",
    "            rows.append({\"id\": f\"{fid}:{suffix}\", \"data\": json.dumps(obj, ensure_ascii=False)})\n",
    "\n",
    "        add_row(\"returns\", {**rets, **rets_ann})\n",
    "        add_row(\"vol\", vols)\n",
    "        add_row(\"mdd\", {\"mdd_6m\": mdd6, \"dd_6m\": dd6, \"mdd_1y\": mdd1y, \"dd_1y\": dd1y})\n",
    "        add_row(\"trend\",\n",
    "                {\"sma20\":sma20,\"sma60\":sma60,\"sma120\":sma120,\n",
    "                 \"ema20\":ema20,\"ema60\":ema60,\"ema120\":ema120,\n",
    "                 **gaps,\n",
    "                 \"cross_20_60\": cross_20_60, \"cross_60_120\": cross_60_120})\n",
    "        add_row(\"slope60\", {\"slope\": slope60, \"tstat\": t60})\n",
    "        add_row(\"pos_52w\", {\"pos_0to1\": pos52w, \"pos_pct\": pos52w_pct})\n",
    "        add_row(\"regime\", {\"trend\": trend_reg, \"vol\": vol_reg, \"regime\": regime})\n",
    "        if corr_res:\n",
    "            add_row(\"corr60\", corr_res)\n",
    "        if beta_res:\n",
    "            add_row(\"beta60\", beta_res)\n",
    "        add_row(\"latest\", latest)\n",
    "\n",
    "        summary = {\n",
    "            \"latest\": latest,\n",
    "            \"returns\": {**rets, **rets_ann},\n",
    "            \"vol\": vols,\n",
    "            \"mdd\": {\"mdd_6m\": mdd6, \"dd_6m\": dd6, \"mdd_1y\": mdd1y, \"dd_1y\": dd1y},\n",
    "            \"trend\": {\"gaps\": gaps, \"cross_20_60\": cross_20_60, \"cross_60_120\": cross_60_120},\n",
    "            \"slope60\": {\"slope\": slope60, \"tstat\": t60},\n",
    "            \"pos_52w_pct\": pos52w_pct,\n",
    "            \"regime\": {\"trend\": trend_reg, \"vol\": vol_reg, \"regime\": regime},\n",
    "            \"corr60\": corr_res if corr_res else None,\n",
    "            \"beta60\": beta_res if beta_res else None\n",
    "        }\n",
    "        add_row(\"summary\", summary)\n",
    "\n",
    "    # ì €ì¥\n",
    "    os.makedirs(os.path.dirname(OUT_PATH), exist_ok=True)\n",
    "    df_out = pd.DataFrame(rows, columns=[\"id\", \"data\"])\n",
    "    df_out.to_excel(OUT_PATH, index=False, engine=\"openpyxl\")\n",
    "    print(f\"[OK] ì €ì¥ ì™„ë£Œ: {OUT_PATH} (rows={len(df_out)})\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6812ebee-34b0-4232-9b7c-55f3617a798a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–¶ ê¸°ì¤€ íŒŒì¼(íŒŒì¼ëª… ë‚ ì§œ ìµœì‹ ): risk_thresholds_20251122.xlsx\n",
      "[í–‰ 2 â†’ IND500] TRUEì¡´ì¬=False â†’ C1='G'\n",
      "  âœ… C1='G' ê¸°ë¡: IND500.xlsx\n",
      "[í–‰ 3 â†’ IND501] TRUEì¡´ì¬=False â†’ C1='G'\n",
      "  âœ… C1='G' ê¸°ë¡: IND501.xlsx\n",
      "[í–‰ 4 â†’ IND502] TRUEì¡´ì¬=False â†’ C1='G'\n",
      "  âœ… C1='G' ê¸°ë¡: IND502.xlsx\n",
      "[í–‰ 5 â†’ IND503] TRUEì¡´ì¬=False â†’ C1='G'\n",
      "  âœ… C1='G' ê¸°ë¡: IND503.xlsx\n",
      "[í–‰ 6 â†’ IND504] TRUEì¡´ì¬=False â†’ C1='G'\n",
      "  âœ… C1='G' ê¸°ë¡: IND504.xlsx\n",
      "[í–‰ 7 â†’ IND505] TRUEì¡´ì¬=True â†’ C1='Y'\n",
      "  âœ… C1='Y' ê¸°ë¡: IND505.xlsx\n",
      "[í–‰ 8 â†’ IND506] TRUEì¡´ì¬=True â†’ C1='Y'\n",
      "  âœ… C1='Y' ê¸°ë¡: IND506.xlsx\n",
      "[í–‰ 9 â†’ IND507] TRUEì¡´ì¬=False â†’ C1='G'\n",
      "  âœ… C1='G' ê¸°ë¡: IND507.xlsx\n",
      "[í–‰ 10 â†’ IND508] TRUEì¡´ì¬=False â†’ C1='G'\n",
      "  âœ… C1='G' ê¸°ë¡: IND508.xlsx\n",
      "[í–‰ 11 â†’ IND509] TRUEì¡´ì¬=False â†’ C1='G'\n",
      "  âœ… C1='G' ê¸°ë¡: IND509.xlsx\n",
      "[í–‰ 12 â†’ IND510] TRUEì¡´ì¬=False â†’ C1='G'\n",
      "  âœ… C1='G' ê¸°ë¡: IND510.xlsx\n",
      "[í–‰ 13 â†’ IND511] TRUEì¡´ì¬=False â†’ C1='G'\n",
      "  âœ… C1='G' ê¸°ë¡: IND511.xlsx\n",
      "[í–‰ 14 â†’ IND512] TRUEì¡´ì¬=False â†’ C1='G'\n",
      "  âœ… C1='G' ê¸°ë¡: IND512.xlsx\n",
      "[í–‰ 15 â†’ IND513] TRUEì¡´ì¬=False â†’ C1='G'\n",
      "  âœ… C1='G' ê¸°ë¡: IND513.xlsx\n",
      "[í–‰ 16 â†’ IND514] TRUEì¡´ì¬=False â†’ C1='G'\n",
      "  âœ… C1='G' ê¸°ë¡: IND514.xlsx\n",
      "[í–‰ 17 â†’ IND515] TRUEì¡´ì¬=False â†’ C1='G'\n",
      "  âœ… C1='G' ê¸°ë¡: IND515.xlsx\n",
      "[í–‰ 18 â†’ IND516] TRUEì¡´ì¬=False â†’ C1='G'\n",
      "  âœ… C1='G' ê¸°ë¡: IND516.xlsx\n",
      "[í–‰ 19 â†’ IND517] TRUEì¡´ì¬=False â†’ C1='G'\n",
      "  âœ… C1='G' ê¸°ë¡: IND517.xlsx\n",
      "[í–‰ 20 â†’ IND518] TRUEì¡´ì¬=False â†’ C1='G'\n",
      "  âœ… C1='G' ê¸°ë¡: IND518.xlsx\n",
      "[í–‰ 21 â†’ IND519] TRUEì¡´ì¬=False â†’ C1='G'\n",
      "  âœ… C1='G' ê¸°ë¡: IND519.xlsx\n",
      "[í–‰ 22 â†’ IND520] TRUEì¡´ì¬=False â†’ C1='G'\n",
      "  âœ… C1='G' ê¸°ë¡: IND520.xlsx\n",
      "[í–‰ 23 â†’ IND521] TRUEì¡´ì¬=False â†’ C1='G'\n",
      "  âœ… C1='G' ê¸°ë¡: IND521.xlsx\n",
      "[í–‰ 24 â†’ IND522] TRUEì¡´ì¬=False â†’ C1='G'\n",
      "  âœ… C1='G' ê¸°ë¡: IND522.xlsx\n",
      "[í–‰ 25 â†’ IND523] TRUEì¡´ì¬=False â†’ C1='G'\n",
      "  âœ… C1='G' ê¸°ë¡: IND523.xlsx\n",
      "[í–‰ 26 â†’ IND524] TRUEì¡´ì¬=False â†’ C1='G'\n",
      "  âœ… C1='G' ê¸°ë¡: IND524.xlsx\n",
      "[í–‰ 27 â†’ IND525] TRUEì¡´ì¬=False â†’ C1='G'\n",
      "  âœ… C1='G' ê¸°ë¡: IND525.xlsx\n",
      "[í–‰ 28 â†’ IND526] TRUEì¡´ì¬=False â†’ C1='G'\n",
      "  âœ… C1='G' ê¸°ë¡: IND526.xlsx\n",
      "[í–‰ 29 â†’ IND527] TRUEì¡´ì¬=False â†’ C1='G'\n",
      "  âœ… C1='G' ê¸°ë¡: IND527.xlsx\n",
      "[í–‰ 30 â†’ IND528] TRUEì¡´ì¬=False â†’ C1='G'\n",
      "  âœ… C1='G' ê¸°ë¡: IND528.xlsx\n",
      "[í–‰ 31 â†’ IND529] TRUEì¡´ì¬=False â†’ C1='G'\n",
      "  âœ… C1='G' ê¸°ë¡: IND529.xlsx\n",
      "[í–‰ 32 â†’ IND530] TRUEì¡´ì¬=False â†’ C1='G'\n",
      "  âœ… C1='G' ê¸°ë¡: IND530.xlsx\n",
      "[í–‰ 33 â†’ IND531] TRUEì¡´ì¬=False â†’ C1='G'\n",
      "  âœ… C1='G' ê¸°ë¡: IND531.xlsx\n",
      "[í–‰ 34 â†’ IND532] TRUEì¡´ì¬=False â†’ C1='G'\n",
      "  âœ… C1='G' ê¸°ë¡: IND532.xlsx\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€ ìš”ì•½ â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ì—…ë°ì´íŠ¸ ì„±ê³µ: 33ê°œ\n",
      "ìŠ¤í‚µ(íŒŒì¼ì—†ìŒ ë“±): 0ê°œ\n",
      "ì™„ë£Œ âœ…\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "ëª©ì :\n",
    "- C:/Users/amongpapa/chartup/raw_data í´ë”ì˜ risk_thresholds_YYYYMMDD.xlsx íŒŒì¼ë“¤ ì¤‘,\n",
    "  íŒŒì¼ëª… ë‚ ì§œ(YYYYMMDD)ê°€ 'ê°€ì¥ ìµœì‹ 'ì¸ íŒŒì¼ì„ ìë™ ì„ íƒ\n",
    "- í•´ë‹¹ íŒŒì¼ì˜ alerts ì‹œíŠ¸ë¥¼ ì½ì–´ì„œ,\n",
    "  ì—‘ì…€ 2í–‰ â†’ IND500, 3í–‰ â†’ IND501, ... ê·œì¹™ìœ¼ë¡œ ë§¤í•‘\n",
    "- ê° í–‰ì— 'TRUE'ê°€ í•œ ì¹¸ì´ë¼ë„ ìˆìœ¼ë©´ C1='Y', ì•„ë‹ˆë©´ 'G'ë¥¼\n",
    "  C:/Users/amongpapa/chartup/go_scen/data/set/IND###.xlsx ì— ê¸°ë¡\n",
    "- ëŒ€ìƒ ë²”ìœ„: IND500 ~ IND700 (ì¡´ì¬í•˜ëŠ” íŒŒì¼ë§Œ ì—…ë°ì´íŠ¸)\n",
    "\n",
    "ì„¤ì¹˜:\n",
    "    pip install pandas openpyxl\n",
    "\n",
    "íŒ€ì¥ë‹˜ í™˜ê²½ ìœ ì˜:\n",
    "- ìœˆë„ìš° ê²½ë¡œëŠ” pathlib.Path(r\"...\") í˜•ì‹ ì‚¬ìš©\n",
    "- ìŠ¬ë˜ì‹œ(/)ë¥¼ ì¨ë„ ë©ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” Pathë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ ì•ˆì „í•©ë‹ˆë‹¤.\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path  # âœ… ìœˆë„ìš°ì—ì„œë„ ì•ˆì „í•œ ê²½ë¡œ ì²˜ë¦¬\n",
    "from datetime import datetime\n",
    "import re\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 1) ê²½ë¡œ/íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# risk_thresholds ì—‘ì…€ë“¤ì´ ìˆëŠ” í´ë”\n",
    "RISK_DIR = Path(r\"C:\\Users\\amongpapa\\chartup\\raw_data\")\n",
    "\n",
    "# alerts ì‹œíŠ¸ëª…\n",
    "ALERTS_SHEET = \"alerts\"\n",
    "\n",
    "# IND ì—‘ì…€ë“¤ì´ ìˆëŠ” í´ë”(ì—…ë°ì´íŠ¸ ëŒ€ìƒ)\n",
    "TARGET_DIR = Path(r\"C:\\Users\\amongpapa\\chartup\\go_scen\\data\\set\")\n",
    "\n",
    "# ë§¤í•‘: ì—‘ì…€ '2í–‰' â†’ IND500 (ì¦‰, row 2 => 500, row 3 => 501, ...)\n",
    "START_EXCEL_ROW = 2\n",
    "START_IND = 500\n",
    "MAX_IND = 700  # ì´ ê°’ê¹Œì§€ ì¡´ì¬í•˜ëŠ” íŒŒì¼ë§Œ ì—…ë°ì´íŠ¸\n",
    "\n",
    "# ì—…ë°ì´íŠ¸í•  ì›Œí¬ì‹œíŠ¸: ì²« ì‹œíŠ¸ë¥¼ ì‚¬ìš©(ì •ìˆ˜ 0). íŠ¹ì • ì‹œíŠ¸ëª…ì´ë©´ ë¬¸ìì—´ë¡œ ì§€ì • ê°€ëŠ¥.\n",
    "TARGET_SHEET = 0\n",
    "\n",
    "# 'TRUE' íŒì • ì‹œ í¬í•¨í•  ê°’(ëŒ€ì†Œë¬¸ì, ê³µë°± ëŒ€ì‘)\n",
    "TRUE_TOKENS = {\"TRUE\"}  # ë¬¸ìì—´ 'TRUE' ë˜ëŠ” ë¶ˆë¦¬ì–¸ Trueë¥¼ í—ˆìš©\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "\n",
    "# ---------------- ìµœì‹  íŒŒì¼ ì„ íƒ: íŒŒì¼ëª… ë‚ ì§œ(YYYYMMDD) ê¸°ì¤€ ----------------\n",
    "def pick_risk_file_by_name_date() -> Path:\n",
    "    \"\"\"\n",
    "    risk_thresholds_YYYYMMDD.xlsx íŒŒì¼ë“¤ì—ì„œ 'íŒŒì¼ëª… ë‚ ì§œ'ê°€ ê°€ì¥ ìµœì‹ ì¸ íŒŒì¼ì„ ì„ íƒ.\n",
    "    ì˜ˆ: risk_thresholds_20251006.xlsx ê°€ ìˆìœ¼ë©´ ê·¸ê±¸ ì‚¬ìš©.\n",
    "    \"\"\"\n",
    "    patt = re.compile(r\"^risk_thresholds_(\\d{8})\\.xlsx$\", re.IGNORECASE)\n",
    "    best = None\n",
    "    best_dt = None\n",
    "    for p in RISK_DIR.glob(\"risk_thresholds_*.xlsx\"):\n",
    "        m = patt.match(p.name)\n",
    "        if not m:\n",
    "            continue\n",
    "        try:\n",
    "            dt = datetime.strptime(m.group(1), \"%Y%m%d\")\n",
    "        except ValueError:\n",
    "            continue\n",
    "        if (best_dt is None) or (dt > best_dt):\n",
    "            best_dt = dt\n",
    "            best = p\n",
    "    if best is None:\n",
    "        raise FileNotFoundError(f\"í´ë”ì— risk_thresholds_YYYYMMDD.xlsx íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {RISK_DIR}\")\n",
    "    return best\n",
    "\n",
    "\n",
    "# ---------------- ì—‘ì…€ í–‰ â†’ IND ë²ˆí˜¸ ë§¤í•‘ ----------------\n",
    "def excel_row_to_ind(excel_row: int) -> int:\n",
    "    \"\"\"\n",
    "    ì—‘ì…€ ì‹¤ì œ í–‰ ë²ˆí˜¸(1-based) â†’ IND ë²ˆí˜¸ ë§¤í•‘\n",
    "    ì˜ˆ) 2í–‰ â†’ 500, 3í–‰ â†’ 501 ...\n",
    "    \"\"\"\n",
    "    return START_IND + (excel_row - START_EXCEL_ROW)\n",
    "\n",
    "\n",
    "# ---------------- í•œ í–‰ì— TRUE ì¡´ì¬ ì—¬ë¶€ ê²€ì‚¬ ----------------\n",
    "def row_has_true(row_values) -> bool:\n",
    "    \"\"\"\n",
    "    í•œ í–‰ì— TRUEê°€ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ True ë°˜í™˜.\n",
    "    - ë¶ˆë¦¬ì–¸ True\n",
    "    - ë¬¸ìì—´ 'TRUE' (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ, ì•ë’¤ ê³µë°± ë¬´ì‹œ)\n",
    "    \"\"\"\n",
    "    for v in row_values:\n",
    "        # ë¶ˆë¦¬ì–¸ True\n",
    "        if v is True:\n",
    "            return True\n",
    "        # ë¬¸ìì—´ 'TRUE'\n",
    "        if isinstance(v, str) and v.strip().upper() in TRUE_TOKENS:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# ---------------- IND ì—‘ì…€ì˜ C1 ì—…ë°ì´íŠ¸ ----------------\n",
    "def update_c1_flag(ind_num: int, flag: str) -> bool:\n",
    "    \"\"\"\n",
    "    IND íŒŒì¼ì˜ C1ì„ flag('Y'/'G')ë¡œ ì—…ë°ì´íŠ¸.\n",
    "    - íŒŒì¼ì´ ì—†ìœ¼ë©´ False ë°˜í™˜(ìŠ¤í‚µ)\n",
    "    - ì„±ê³µí•˜ë©´ True\n",
    "    \"\"\"\n",
    "    fpath = TARGET_DIR / f\"IND{ind_num:03d}.xlsx\"\n",
    "    if not fpath.exists():\n",
    "        print(f\"  â­ï¸ ìŠ¤í‚µ (íŒŒì¼ì—†ìŒ): {fpath.name}\")\n",
    "        return False\n",
    "\n",
    "    wb = load_workbook(fpath)\n",
    "    ws = wb.worksheets[TARGET_SHEET] if isinstance(TARGET_SHEET, int) else wb[TARGET_SHEET]\n",
    "    ws[\"C1\"] = flag  # C1ë§Œ ê¸°ë¡ (D1/E1ì€ ë³€ê²½í•˜ì§€ ì•ŠìŒ)\n",
    "    wb.save(fpath)\n",
    "    print(f\"  âœ… C1='{flag}' ê¸°ë¡: {fpath.name}\")\n",
    "    return True\n",
    "\n",
    "\n",
    "# ---------------- ë©”ì¸ ë£¨í‹´ ----------------\n",
    "def main():\n",
    "    # 1) ìµœì‹  risk_thresholds íŒŒì¼ ì„ íƒ(íŒŒì¼ëª… ë‚ ì§œ ê¸°ì¤€)\n",
    "    risk_file = pick_risk_file_by_name_date()\n",
    "    print(f\"â–¶ ê¸°ì¤€ íŒŒì¼(íŒŒì¼ëª… ë‚ ì§œ ìµœì‹ ): {risk_file.name}\")\n",
    "\n",
    "    # 2) alerts ì‹œíŠ¸ë¥¼ í—¤ë” ì—†ì´(raw) ë¡œë“œ â†’ ì—‘ì…€ ì‹¤ì œ í–‰ ë²ˆí˜¸ì™€ 1:1 ë§¤í•‘ ê°€ëŠ¥\n",
    "    df = pd.read_excel(risk_file, sheet_name=ALERTS_SHEET, header=None, engine=\"openpyxl\")\n",
    "    nrows = df.shape[0]\n",
    "\n",
    "    total_updated = 0\n",
    "    total_skipped = 0\n",
    "\n",
    "    # 3) ì—‘ì…€ '2í–‰'ë¶€í„° ëê¹Œì§€ ìˆœíšŒí•˜ë©° IND ë²ˆí˜¸ë¡œ ë§¤í•‘\n",
    "    #    ë‹¨, IND ë²ˆí˜¸ê°€ MAX_INDë¥¼ ë„˜ìœ¼ë©´ ì¤‘ë‹¨\n",
    "    for excel_row in range(START_EXCEL_ROW, nrows + 1):\n",
    "        ind_num = excel_row_to_ind(excel_row)\n",
    "\n",
    "        if ind_num < START_IND:\n",
    "            continue\n",
    "        if ind_num > MAX_IND:\n",
    "            break  # ë²”ìœ„ë¥¼ ë„˜ìœ¼ë©´ ì¢…ë£Œ\n",
    "\n",
    "        row_vals = df.iloc[excel_row - 1].tolist()  # pandasëŠ” 0-based â†’ excel_row-1\n",
    "        has_true = row_has_true(row_vals)\n",
    "        flag = \"Y\" if has_true else \"G\"\n",
    "\n",
    "        print(f\"[í–‰ {excel_row} â†’ IND{ind_num:03d}] TRUEì¡´ì¬={has_true} â†’ C1='{flag}'\")\n",
    "        ok = update_c1_flag(ind_num, flag)\n",
    "        if ok:\n",
    "            total_updated += 1\n",
    "        else:\n",
    "            total_skipped += 1\n",
    "\n",
    "    print(\"\\nâ”€â”€â”€â”€â”€â”€â”€â”€ ìš”ì•½ â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "    print(f\"ì—…ë°ì´íŠ¸ ì„±ê³µ: {total_updated}ê°œ\")\n",
    "    print(f\"ìŠ¤í‚µ(íŒŒì¼ì—†ìŒ ë“±): {total_skipped}ê°œ\")\n",
    "    print(\"ì™„ë£Œ âœ…\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc4a08c0-2d9c-4555-b128-7fc7a5cba2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] market_data.xlsx íŒŒì¼ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\market_data\\market_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ğŸ“‚ íŒŒì¼ ê²½ë¡œ\n",
    "market_data_path = Path(r\"C:\\Users\\amongpapa\\chartup\\go_scen\\data\\market_data\\market_data.xlsx\")\n",
    "indicator_path   = Path(r\"C:\\Users\\amongpapa\\lm\\agent\\go_scen\\data\\indicator.xlsx\")\n",
    "\n",
    "# 1ï¸âƒ£ ì—‘ì…€ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "market_df = pd.read_excel(market_data_path)\n",
    "indicator_df = pd.read_excel(indicator_path)\n",
    "\n",
    "# 2ï¸âƒ£ id ì¹¼ëŸ¼ì—ì„œ \"IND001:returns\" â†’ \"IND001\" ë¶€ë¶„ ì¶”ì¶œ\n",
    "market_df[\"Indicator_ID\"] = market_df[\"id\"].str.split(\":\").str[0]\n",
    "\n",
    "# 3ï¸âƒ£ indicator.xlsx ë§¤í•‘\n",
    "merged_df = market_df.merge(\n",
    "    indicator_df[[\"Indicator_ID\", \"Indicator_Name\", \"Bloomberg_Ticker\"]],\n",
    "    on=\"Indicator_ID\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# 4ï¸âƒ£ C, Dì—´ ìœ„ì¹˜ì— Indicator_Name, Bloomberg_Ticker ì‚½ì…\n",
    "cols = list(market_df.columns)\n",
    "insert_position = 2  # Cì—´ ìœ„ì¹˜\n",
    "for new_col in [\"Indicator_Name\", \"Bloomberg_Ticker\"]:\n",
    "    cols.insert(insert_position, new_col)\n",
    "    insert_position += 1\n",
    "\n",
    "final_df = merged_df[cols]\n",
    "\n",
    "# 5ï¸âƒ£ ê¸°ì¡´ íŒŒì¼ ë®ì–´ì“°ê¸° (ì—…ë°ì´íŠ¸ ì €ì¥)\n",
    "final_df.to_excel(market_data_path, index=False)\n",
    "\n",
    "print(f\"[OK] market_data.xlsx íŒŒì¼ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤: {market_data_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a40aa19-14ba-4812-a721-97e86ffb6a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] ì œì™¸ íŒŒì¼ ë³´ì¡´: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\news\\bigkinds\\daily_news\\keyword_news.xlsx\n",
      "[DEL ] íŒŒì¼ ì‚­ì œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\news\\bigkinds\\daily_news\\keyword_news_bf.xlsx\n",
      "[DEL ] íŒŒì¼ ì‚­ì œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\news\\bigkinds\\20251122_bigkinds_risk.xlsx\n",
      "[DEL ] íŒŒì¼ ì‚­ì œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\news\\bigkinds\\daily_news\\keyword_news.xlsx\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "í´ë” ë¹„ìš°ê¸° ìœ í‹¸ (ë³´ì¡´ ì˜ˆì™¸ ì§€ì›, **í´ë”ëŠ” ì ˆëŒ€ ì‚­ì œí•˜ì§€ ì•ŠìŒ**)\n",
    "- target í´ë” ë‚´ë¶€ì˜ íŒŒì¼/í•˜ìœ„í´ë” 'ë‚´ìš©'ë§Œ ì‚­ì œí•˜ë˜, ì§€ì •í•œ ì˜ˆì™¸ íŒŒì¼/í´ë”ëŠ” ë³´ì¡´\n",
    "- dry_run=True ì‹œ ì‹¤ì œ ì‚­ì œ ì—†ì´ ë¡œê·¸ë§Œ ì¶œë ¥\n",
    "- Windowsì—ì„œë„ ì•ˆì „í•˜ê²Œ: pathlib.Path ì‚¬ìš© + / ìŠ¬ë˜ì‹œ ê²½ë¡œ\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import shutil  # (ë‚¨ê²¨ë‘ : ì¶”í›„ í™•ì¥ ëŒ€ë¹„, í˜„ì¬ í´ë” ì‚­ì œì—ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)\n",
    "from typing import Iterable, Set\n",
    "\n",
    "# [ì„¤ì •] ëŒ€ìƒ í´ë”ë“¤\n",
    "TARGET_BIGKINDS = Path(r\"C:/Users/amongpapa/chartup/go_scen/data/news/bigkinds\")\n",
    "TARGET_DAILY_NEWS = Path(r\"C:/Users/amongpapa/chartup/go_scen/data/news/bigkinds/daily_news\")\n",
    "\n",
    "def _is_dangerous_path(p: Path) -> bool:\n",
    "    \"\"\"\n",
    "    ë£¨íŠ¸ ê°™ì€ ìœ„í—˜ ê²½ë¡œë¥¼ ë³´í˜¸í•˜ê¸° ìœ„í•œ ê°„ë‹¨ ê°€ë“œ.\n",
    "    - ë“œë¼ì´ë¸Œ ë£¨íŠ¸(ex: C:/) ë˜ëŠ” ê²½ë¡œ ë¬¸ìì—´ì´ ë„ˆë¬´ ì§§ì€ ê²½ìš° ìœ„í—˜ìœ¼ë¡œ ê°„ì£¼\n",
    "    \"\"\"\n",
    "    try:\n",
    "        p = p.resolve()\n",
    "    except Exception:\n",
    "        return True\n",
    "    return (p == Path(p.anchor)) or (len(str(p)) < 10)\n",
    "\n",
    "def purge_dir(target: Path, dry_run: bool = False, exclude: Iterable[Path] = ()) -> None:\n",
    "    \"\"\"\n",
    "    target í´ë” ì•ˆì˜ ëª¨ë“  'ë‚´ìš©ë¬¼'ì„ ì •ë¦¬(íŒŒì¼/ë§í¬ ì‚­ì œ)í•˜ë˜, **í´ë” ìì²´ëŠ” ì‚­ì œí•˜ì§€ ì•ŠìŒ**.\n",
    "    excludeëŠ” ì ˆëŒ€/ìƒëŒ€ ê²½ë¡œ ëª¨ë‘ í—ˆìš©:\n",
    "      - ì ˆëŒ€ê²½ë¡œ: ê·¸ëŒ€ë¡œ ë³´ì¡´\n",
    "      - ìƒëŒ€ê²½ë¡œ: target ê¸°ì¤€ ìƒëŒ€ ê²½ë¡œë¡œ í•´ì„í•˜ì—¬ ë³´ì¡´\n",
    "    \"\"\"\n",
    "    target = Path(target).resolve()\n",
    "    if not target.is_dir():\n",
    "        raise FileNotFoundError(f\"ëŒ€ìƒ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {target}\")\n",
    "\n",
    "    if _is_dangerous_path(target):\n",
    "        raise ValueError(f\"ìœ„í—˜í•œ ê²½ë¡œë¡œ íŒë‹¨ë˜ì–´ ì¤‘ë‹¨í•©ë‹ˆë‹¤: {target}\")\n",
    "\n",
    "    # ë³´ì¡´(ì œì™¸) ì§‘í•©: ì ˆëŒ€ ê²½ë¡œë¡œ ì •ê·œí™”\n",
    "    exclude_abs: Set[Path] = set()\n",
    "    for ex in exclude:\n",
    "        ex = Path(ex)\n",
    "        if not ex.is_absolute():\n",
    "            ex = (target / ex).resolve()\n",
    "        else:\n",
    "            ex = ex.resolve()\n",
    "        exclude_abs.add(ex)\n",
    "\n",
    "    def _purge(curr: Path) -> None:\n",
    "        for child in curr.iterdir():\n",
    "            try:\n",
    "                cres = child.resolve()\n",
    "\n",
    "                # ----------------------------\n",
    "                # 1) í´ë” ìì²´ê°€ excludeë©´: í†µì§¸ë¡œ ê±´ë“œë¦¬ì§€ ì•ŠìŒ\n",
    "                # ----------------------------\n",
    "                if cres in exclude_abs and child.is_dir():\n",
    "                    print(f\"[SKIP] ì œì™¸ í´ë” ë³´ì¡´: {child}\")\n",
    "                    continue\n",
    "\n",
    "                # ----------------------------\n",
    "                # 2) íŒŒì¼/ë§í¬ ì²˜ë¦¬\n",
    "                # ----------------------------\n",
    "                if child.is_file() or child.is_symlink():\n",
    "                    if cres in exclude_abs:\n",
    "                        print(f\"[SKIP] ì œì™¸ íŒŒì¼ ë³´ì¡´: {child}\")\n",
    "                        continue\n",
    "                    if dry_run:\n",
    "                        print(f\"[DRY ] íŒŒì¼ ì‚­ì œ ì˜ˆì •: {child}\")\n",
    "                    else:\n",
    "                        child.unlink()\n",
    "                        print(f\"[DEL ] íŒŒì¼ ì‚­ì œ: {child}\")\n",
    "                    continue\n",
    "\n",
    "                # ----------------------------\n",
    "                # 3) í´ë” ì²˜ë¦¬ (ì¤‘ìš”)\n",
    "                #    - **í´ë”ëŠ” ì ˆëŒ€ ì‚­ì œí•˜ì§€ ì•ŠìŒ**\n",
    "                #    - ë‚´ë¶€ë¡œ ì¬ê·€ ì§„ì…í•˜ì—¬ íŒŒì¼ë§Œ ì •ë¦¬\n",
    "                # ----------------------------\n",
    "                if child.is_dir():\n",
    "                    _purge(child)\n",
    "                    # í´ë” ì‚­ì œ ë¡œì§ì€ ì „ë¶€ ì œê±° (í´ë” êµ¬ì¡°ëŠ” í•­ìƒ ìœ ì§€)\n",
    "            except Exception as e:\n",
    "                print(f\"[ERR ] ì‚­ì œ ì‹¤íŒ¨: {child} -> {e}\")\n",
    "\n",
    "    _purge(target)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # 1) daily_news í´ë”: keyword_news.xlsxëŠ” ë³´ì¡´(ì‚­ì œ ì œì™¸)\n",
    "    #    â†’ ìƒëŒ€ê²½ë¡œ 'keyword_news.xlsx'ëŠ” TARGET_DAILY_NEWS ê¸°ì¤€ìœ¼ë¡œ í•´ì„ë¨\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    EXCLUDE_IN_DAILY = [Path(\"keyword_news.xlsx\")]\n",
    "\n",
    "    # [ë³€ê²½] 2) bigkinds ì „ì²´ ì •ë¦¬ ì‹œì—ë„ keyword_news.xlsx ë³´ì¡´\n",
    "    # - ì—¬ê¸°ì„œëŠ” ì ˆëŒ€ê²½ë¡œë¡œ ì˜ˆì™¸ë¥¼ ë„£ì–´ì¤Œ\n",
    "    # - TARGET_BIGKINDS ì•„ë˜ ì–´ë””ë¥¼ ëŒë”ë¼ë„ ì´ íŒŒì¼ì€ ì‚­ì œë˜ì§€ ì•Šê²Œ ë³´í˜¸\n",
    "    EXCLUDE_IN_BIGKINDS = [\n",
    "        TARGET_DAILY_NEWS / \"keyword_news.xlsx\"   # [ë³€ê²½] ì ˆëŒ€ê²½ë¡œ ì˜ˆì™¸ ì§€ì •\n",
    "    ]\n",
    "\n",
    "    # (ìƒ˜í”Œ) ì˜ˆí–‰ì—°ìŠµ: ë¬´ì—‡ì´ ì§€ì›Œì§ˆì§€ ë¡œê·¸ë§Œ í™•ì¸í•  ë•Œ ì‚¬ìš©\n",
    "    # purge_dir(TARGET_DAILY_NEWS, dry_run=True,  exclude=EXCLUDE_IN_DAILY)\n",
    "    # purge_dir(TARGET_BIGKINDS,   dry_run=True,  exclude=EXCLUDE_IN_BIGKINDS)\n",
    "\n",
    "    # ì‹¤ì œ ì‹¤í–‰: **í´ë”ëŠ” ë‚¨ê¸°ê³  íŒŒì¼/ë§í¬ë§Œ ì‚­ì œ**\n",
    "    purge_dir(TARGET_DAILY_NEWS, dry_run=False, exclude=EXCLUDE_IN_DAILY)\n",
    "    purge_dir(TARGET_BIGKINDS,   dry_run=False, exclude=EXCLUDE_IN_BIGKINDS)  # [ë³€ê²½]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f26b4095-9a96-4656-b174-b9392f72ca73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "íŒì—… ê°ì§€ë¨! í™•ì¸ ë²„íŠ¼ í´ë¦­ ì¤‘...\n",
      "í™•ì¸ ë²„íŠ¼ í´ë¦­ ì™„ë£Œ!\n",
      "íŒŒì¼ëª…ì´ 'C:\\Users\\amongpapa\\chartup\\go_scen\\data\\news\\bigkinds\\20251122_bigkinds.xlsx'(ìœ¼)ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤!\n",
      "íŒŒì¼ì´ C:\\Users\\amongpapa\\chartup\\go_scen\\data\\news\\bigkinds í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import shutil\n",
    "\n",
    "# ğŸ“Œ ë‹¤ìš´ë¡œë“œ í´ë” ì„¤ì •\n",
    "download_folder = r\"C:\\Users\\amongpapa\\chartup\\go_scen\\data\\news\\bigkinds\"\n",
    "\n",
    "# í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±\n",
    "if not os.path.exists(download_folder):\n",
    "    os.makedirs(download_folder)\n",
    "\n",
    "# ğŸ”¹ ì˜¤ëŠ˜ ë‚ ì§œ ê°€ì ¸ì˜¤ê¸° (YYYYMMDD í˜•ì‹)\n",
    "today_date = datetime.datetime.today().strftime(\"%Y%m%d\")\n",
    "\n",
    "# ğŸ”¹ í¬ë¡¬ ì˜µì…˜ ì„¤ì • (ìë™ ë‹¤ìš´ë¡œë“œ í™œì„±í™”)\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "prefs = {\n",
    "    \"download.default_directory\": download_folder,\n",
    "    \"download.prompt_for_download\": False,\n",
    "    \"download.directory_upgrade\": True,\n",
    "    \"safebrowsing.enabled\": True\n",
    "}\n",
    "chrome_options.add_experimental_option(\"prefs\", prefs)\n",
    "\n",
    "# ğŸ”¹ í¬ë¡¬ ë“œë¼ì´ë²„ ì‹¤í–‰\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "# ğŸ”¹ ì‚¬ì´íŠ¸ ì ‘ì†\n",
    "driver.get(\"https://www.bigkinds.or.kr/v2/mypage/myKeyword.do\")\n",
    "\n",
    "# ğŸ”¹ ë¡œê·¸ì¸ ë²„íŠ¼ì— ë§ˆìš°ìŠ¤ ì˜¤ë²„í•˜ì—¬ ì‘ì€ íŒì—… í‘œì‹œ\n",
    "time.sleep(2)  # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°\n",
    "login_menu = driver.find_element(By.CSS_SELECTOR, \"#header > div.header-anim > div > div > div.topRightArea > ul > li.topMembership > a\")\n",
    "ActionChains(driver).move_to_element(login_menu).perform()\n",
    "\n",
    "# ğŸ”¹ ì‘ì€ íŒì—…ì—ì„œ ë¡œê·¸ì¸ ë§í¬ í´ë¦­\n",
    "time.sleep(1)  # íŒì—… í‘œì‹œ ëŒ€ê¸°\n",
    "login_link = driver.find_element(By.XPATH, '//*[@id=\"header\"]/div[2]/div/div/div[2]/ul/li[1]/div/ul/li/a')\n",
    "login_link.click()\n",
    "\n",
    "# ğŸ”¹ ë¡œê·¸ì¸ íŒì—…ì—ì„œ ì•„ì´ë””ì™€ ë¹„ë°€ë²ˆí˜¸ ì…ë ¥\n",
    "time.sleep(2)  # ë¡œê·¸ì¸ íŒì—… ë¡œë”© ëŒ€ê¸°\n",
    "username = \"amongddomong@gmail.com\"\n",
    "password = \"^^joahane1\"\n",
    "\n",
    "# ì•„ì´ë”” ì…ë ¥\n",
    "id_input = driver.find_element(By.XPATH, '//*[@id=\"login-user-id\"]')\n",
    "id_input.clear()  # ğŸ‘‰ ê¸°ì¡´ ì…ë ¥ê°’ ì œê±°\n",
    "id_input.send_keys(username)\n",
    "\n",
    "# ë¹„ë°€ë²ˆí˜¸ ì…ë ¥\n",
    "pw_input = driver.find_element(By.XPATH, '//*[@id=\"login-user-password\"]')\n",
    "pw_input.clear()  # ğŸ‘‰ ê¸°ì¡´ ì…ë ¥ê°’ ì œê±°\n",
    "pw_input.send_keys(password)\n",
    "\n",
    "# ë¡œê·¸ì¸ ë²„íŠ¼ í´ë¦­\n",
    "login_button = driver.find_element(By.XPATH, '//*[@id=\"login-btn\"]')\n",
    "login_button.click()\n",
    "\n",
    "# ğŸ”¹ ë¡œê·¸ì¸ í›„ í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°\n",
    "time.sleep(5)\n",
    "\n",
    "# ğŸ”¹ ë‹¤ìš´ë¡œë“œ í˜ì´ì§€ë¡œ ì§ì ‘ ì´ë™\n",
    "driver.get(\"https://www.bigkinds.or.kr/v2/mypage/myKeyword.do\")\n",
    "\n",
    "# ğŸ”¹ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ í´ë¦­ (JS ê°•ì œ í´ë¦­ ë°©ì‹)\n",
    "time.sleep(3)  # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°\n",
    "download_button = driver.find_element(By.XPATH, '//*[@id=\"btn-keyword-download\"]')\n",
    "driver.execute_script(\"arguments[0].click();\", download_button)\n",
    "\n",
    "# ğŸ”¹ íŒì—…ì´ ë‚˜íƒ€ë‚˜ë©´ \"í™•ì¸\" ë²„íŠ¼ í´ë¦­\n",
    "time.sleep(3)\n",
    "try:\n",
    "    alert = driver.switch_to.alert\n",
    "    print(\"íŒì—… ê°ì§€ë¨! í™•ì¸ ë²„íŠ¼ í´ë¦­ ì¤‘...\")\n",
    "    alert.accept()\n",
    "    print(\"í™•ì¸ ë²„íŠ¼ í´ë¦­ ì™„ë£Œ!\")\n",
    "except:\n",
    "    print(\"íŒì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ.\")\n",
    "\n",
    "# ğŸ”¹ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ ëŒ€ê¸°\n",
    "time.sleep(50)\n",
    "\n",
    "# ğŸ”¹ ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ ì´ë¦„ ë³€ê²½ (ê°€ì¥ ìµœê·¼ íŒŒì¼ ì°¾ê¸°)\n",
    "downloaded_files = os.listdir(download_folder)\n",
    "if downloaded_files:\n",
    "    downloaded_files = sorted(\n",
    "        downloaded_files,\n",
    "        key=lambda x: os.path.getctime(os.path.join(download_folder, x)),\n",
    "        reverse=True\n",
    "    )\n",
    "    latest_file = os.path.join(download_folder, downloaded_files[0])\n",
    "    new_filename = os.path.join(download_folder, f\"{today_date}_bigkinds.xlsx\")\n",
    "\n",
    "    shutil.move(latest_file, new_filename)\n",
    "    print(f\"íŒŒì¼ëª…ì´ '{new_filename}'(ìœ¼)ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "print(f\"íŒŒì¼ì´ {download_folder} í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "# ğŸ”¹ ë“œë¼ì´ë²„ ì¢…ë£Œ\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e7d42be-c3fa-4a90-82bc-04c1aafb9e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amongpapa\\anaconda3\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì˜¤ëŠ˜ê³¼ í•˜ë£¨ ì „ ë‚ ì§œ ê¸°ì¤€ í•„í„°ë§ëœ íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\news\\bigkinds\\20251122_bigkinds_risk.xlsx\n",
      "ğŸ—‘ï¸ ì›ë³¸ íŒŒì¼ ì‚­ì œ ì™„ë£Œ: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\news\\bigkinds\\20251122_bigkinds.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ğŸ”¹ ì˜¤ëŠ˜ ë‚ ì§œ ë¬¸ìì—´ ìƒì„± (YYYYMMDD)\n",
    "today = datetime.now()\n",
    "today_str = today.strftime(\"%Y%m%d\")\n",
    "\n",
    "# ğŸ”¹ í•˜ë£¨ ì „ ë‚ ì§œ ë¬¸ìì—´ ìƒì„±\n",
    "yesterday = today - timedelta(days=1)\n",
    "yesterday_str = yesterday.strftime(\"%Y%m%d\")\n",
    "\n",
    "# ğŸ”¹ ì›ë³¸ íŒŒì¼ ê²½ë¡œ (ì˜¤ëŠ˜ ê¸°ì¤€)\n",
    "input_path = rf\"C:\\Users\\amongpapa\\chartup\\go_scen\\data\\news\\bigkinds\\{today_str}_bigkinds.xlsx\"\n",
    "\n",
    "# ğŸ”¹ ê²°ê³¼ ì €ì¥ íŒŒì¼ ê²½ë¡œ\n",
    "output_path = rf\"C:\\Users\\amongpapa\\chartup\\go_scen\\data\\news\\bigkinds\\{today_str}_bigkinds_risk.xlsx\"\n",
    "\n",
    "# ğŸ”¹ ì—‘ì…€ íŒŒì¼ ë¡œë“œ\n",
    "df = pd.read_excel(input_path)\n",
    "\n",
    "# ğŸ”¹ 'ì¼ì' ì»¬ëŸ¼ì´ datetimeì´ ì•„ë‹ˆë¼ë©´ ë¬¸ìì—´ë¡œ ì²˜ë¦¬\n",
    "df[\"ì¼ì\"] = df[\"ì¼ì\"].astype(str)\n",
    "\n",
    "# ğŸ”¹ ì˜¤ëŠ˜ê³¼ í•˜ë£¨ ì „ ë‚ ì§œ í¬í•¨í•˜ëŠ” ë°ì´í„°ë§Œ í•„í„°ë§\n",
    "df = df[df[\"ì¼ì\"].isin([today_str, yesterday_str])]\n",
    "\n",
    "# ğŸ”¹ í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ\n",
    "df = df[['ì¼ì', 'ì œëª©', 'ì–¸ë¡ ì‚¬', 'í†µí•© ë¶„ë¥˜1', 'URL']]\n",
    "\n",
    "# ğŸ”¹ ì œì™¸í•  í†µí•© ë¶„ë¥˜1 ì•ê¸€ì ë¦¬ìŠ¤íŠ¸\n",
    "excluded_prefixes = ['IT_ê³¼í•™', 'ë¬¸í™”', 'ë¯¸ë¶„ë¥˜', 'ìŠ¤í¬ì¸ ']\n",
    "\n",
    "# ğŸ”¹ ì œì™¸ ì¡°ê±´ ì ìš©\n",
    "df = df[~df[\"í†µí•© ë¶„ë¥˜1\"].str.startswith(tuple(excluded_prefixes), na=False)]\n",
    "\n",
    "# ğŸ”¹ URL ê°’ì´ NULLì¸ í–‰ ì œê±°\n",
    "df = df[df[\"URL\"].notna()]\n",
    "\n",
    "# ğŸ”¹ ê²°ê³¼ ì €ì¥\n",
    "df.to_excel(output_path, index=False)\n",
    "print(f\"âœ… ì˜¤ëŠ˜ê³¼ í•˜ë£¨ ì „ ë‚ ì§œ ê¸°ì¤€ í•„í„°ë§ëœ íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}\")\n",
    "\n",
    "# ğŸ”¹ ì›ë³¸ íŒŒì¼ ì‚­ì œ\n",
    "if os.path.exists(input_path):\n",
    "    os.remove(input_path)\n",
    "    print(f\"ğŸ—‘ï¸ ì›ë³¸ íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {input_path}\")\n",
    "else:\n",
    "    print(f\"âš ï¸ ì›ë³¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {input_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71a30ebb-f315-473f-b6db-639e0e1c3bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ì™„ë£Œ] ë°ì¼ë¦¬ ê¸°ì‚¬ íŒŒì¼: C:\\Users\\amongpapa\\chartup\\go_scen\\data\\news\\bigkinds\\daily_news\\keyword_news_bf.xlsx\n",
      " - ë§¤ì¹­ ì„±ê³µ 4ê±´ / ì‹¤íŒ¨ 257ê±´\n",
      " - ë§¤ì¹­ ì‹¤íŒ¨ ë¦¬ìŠ¤íŠ¸(Scenario_ID, News_kor):\n",
      "   Â· SC001 | ì¶”ê°€ê¸´ì¶•\n",
      "   Â· SC001 | ì‹ ìš©ê²½ìƒ‰\n",
      "   Â· SC001 | ë§¤íŒŒì—°ì¤€\n",
      "   Â· SC001 | ê¸ˆë¦¬ì¸ìƒ\n",
      "   Â· SC001 | ì„œë¹„ìŠ¤ë¬¼ê°€\n",
      "   Â· SC001 | ê³ ì°©ì¸í”Œë ˆ\n",
      "   Â· SC001 | ì„ê¸ˆì••ë°•\n",
      "   Â· SC002 | ë°˜ë„ì²´ì¤‘ë‹¨,ëŒ€ë§Œ\n",
      "   Â· SC002 | ëŒ€ë§Œë´‰ì‡„\n",
      "   Â· SC002 | SWIFTë°°ì œ\n",
      "   Â· SC002 | í¬í† ë¥˜í†µì œ\n",
      "   Â· SC002 | G7ì„±ëª…,ëŒ€ë§Œ\n",
      "   Â· SC002 | ADIZì¹¨ë²”\n",
      "   Â· SC002 | êµ°ì‚¬í›ˆë ¨,ëŒ€ë§Œ\n",
      "   Â· SC002 | í•­ëª¨ì§„ì…,ëŒ€ë§Œ\n",
      "   Â· SC003 | ì „ì—¼ìœ„í—˜\n",
      "   Â· SC003 | ëª¨ë¼í† ë¦¬ì—„\n",
      "   Â· SC003 | êµ­ê°€ë¶€ë„\n",
      "   Â· SC003 | IMFêµ¬ì œ\n",
      "   Â· SC003 | ìë³¸ìœ ì¶œ\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "from typing import List, Optional\n",
    "\n",
    "\n",
    "def _pick_col(df: pd.DataFrame, candidates: List[str], required: bool = True) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    ë‹¤ì–‘í•œ í‘œê¸°(ëŒ€ì†Œë¬¸ì/í•œì˜í˜¼ìš©/ìŠ¤í˜ì´ìŠ¤ ìœ ë¬´)ë¥¼ ê³ ë ¤í•´ ê°€ì¥ ë¨¼ì € ë§¤ì¹­ë˜ëŠ” ì»¬ëŸ¼ëª…ì„ ì°¾ì•„ ë°˜í™˜.\n",
    "    required=Falseì´ë©´ ëª» ì°¾ì„ ê²½ìš° None ë°˜í™˜.\n",
    "    \"\"\"\n",
    "    norm = {re.sub(r\"\\s+\", \"\", str(c)).lower(): c for c in df.columns}\n",
    "    for cand in candidates:\n",
    "        key = re.sub(r\"\\s+\", \"\", cand).lower()\n",
    "        if key in norm:\n",
    "            return norm[key]\n",
    "    if required:\n",
    "        raise KeyError(f\"í•„ìˆ˜ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í›„ë³´: {candidates}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def _load_keywords(keyword_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    keyword.xlsx ë¡œë“œ ë° í‘œì¤€ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ì •ë¦¬\n",
    "    ê¸°ëŒ€ ì»¬ëŸ¼(ëŒ€ì²´ í—ˆìš©): \n",
    "      - Scenario_ID: ['Scenario_ID','ì‹œë‚˜ë¦¬ì˜¤ID','ì‹œë‚˜ë¦¬ì˜¤','ScenarioId','SCENARIO_ID']\n",
    "      - News_kor   : ['News_kor','news_kor','News_KOR','í‚¤ì›Œë“œ','Keyword']\n",
    "      - Phase      : ['Phase','phase','ë‹¨ê³„']\n",
    "    \"\"\"\n",
    "    df = pd.read_excel(keyword_path)\n",
    "    sc_col = _pick_col(df, [\"Scenario_ID\", \"ì‹œë‚˜ë¦¬ì˜¤ID\", \"ì‹œë‚˜ë¦¬ì˜¤\", \"ScenarioId\", \"SCENARIO_ID\"])\n",
    "    kw_col = _pick_col(df, [\"News_kor\", \"news_kor\", \"News_KOR\", \"í‚¤ì›Œë“œ\", \"Keyword\"])\n",
    "    ph_col = _pick_col(df, [\"Phase\", \"phase\", \"ë‹¨ê³„\"], required=False)\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"Scenario_ID\": df[sc_col].astype(str).str.strip(),\n",
    "        \"News_kor\": df[kw_col].astype(str).str.strip(),\n",
    "        \"Phase\": df[ph_col].astype(str).str.strip() if ph_col else \"\"\n",
    "    })\n",
    "    # ë¹ˆ í‚¤ì›Œë“œ ì œê±°\n",
    "    out = out[out[\"News_kor\"].str.len() > 0].reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "\n",
    "def _load_latest_bigkinds(risk_dir: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    risk_dir ë‚´ '*bigkinds_risk*.xlsx' íŒŒì¼ ì¤‘ **ê°€ì¥ ìµœì‹  ìˆ˜ì •ì‹œê°** íŒŒì¼ì„ ì½ì–´ í‘œì¤€ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ë°˜í™˜\n",
    "    ê¸°ëŒ€ ì»¬ëŸ¼(ëŒ€ì²´ í—ˆìš©):\n",
    "      - ì œëª©   : ['ì œëª©','ê¸°ì‚¬ì œëª©','title','Title']\n",
    "      - ì–¸ë¡ ì‚¬ : ['ì–¸ë¡ ì‚¬','ì–¸ë¡ ì‚¬ëª…','ë§¤ì²´','publisher','Publisher','ì‹ ë¬¸ì‚¬']\n",
    "      - URL   : ['URL','url','ë§í¬','Link']\n",
    "    \"\"\"\n",
    "    paths = glob.glob(os.path.join(risk_dir, \"*bigkinds_risk*.xlsx\"))\n",
    "    if not paths:\n",
    "        raise FileNotFoundError(f\"bigkinds_risk íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {risk_dir}\")\n",
    "\n",
    "    latest = max(paths, key=os.path.getmtime)  # [ë³€ê²½ì ] ê°€ì¥ ìµœê·¼ íŒŒì¼ ìë™ ì„ íƒ\n",
    "    df = pd.read_excel(latest)\n",
    "\n",
    "    title_col = _pick_col(df, [\"ì œëª©\", \"ê¸°ì‚¬ì œëª©\", \"title\", \"Title\"])\n",
    "    media_col = _pick_col(df, [\"ì–¸ë¡ ì‚¬\", \"ì–¸ë¡ ì‚¬ëª…\", \"ë§¤ì²´\", \"publisher\", \"Publisher\", \"ì‹ ë¬¸ì‚¬\"])\n",
    "    url_col   = _pick_col(df, [\"URL\", \"url\", \"ë§í¬\", \"Link\"])\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"ì œëª©\": df[title_col].astype(str).str.strip(),\n",
    "        \"ì–¸ë¡ ì‚¬\": df[media_col].astype(str).str.strip(),\n",
    "        \"URL\": df[url_col].astype(str).str.strip()\n",
    "    }).dropna(subset=[\"ì œëª©\"]).reset_index(drop=True)\n",
    "\n",
    "    # ì¤‘ë³µ ì œëª© ì œê±°(ì„ í–‰ ë°ì´í„° ìš°ì„ )\n",
    "    out = out.drop_duplicates(subset=[\"ì œëª©\"], keep=\"first\").reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "\n",
    "def _match_first(corpus: pd.DataFrame, query: str, used_titles: set) -> Optional[pd.Series]:\n",
    "    \"\"\"\n",
    "    News_kor ë¬¸ìì—´ì„ ',' ê¸°ì¤€ **AND ì¡°ê±´**ìœ¼ë¡œ ë¶„í•´í•˜ì—¬ ê¸°ì‚¬ ì œëª©ì—ì„œ ëª¨ë‘ ë§¤ì¹­ë˜ëŠ” ì²« ê±´ ë°˜í™˜.\n",
    "    ì´ë¯¸ ì„ íƒëœ ì œëª©(used_titles)ì€ ì œì™¸.\n",
    "    \"\"\"\n",
    "    # 'í‚¤ì›Œë“œ1,í‚¤ì›Œë“œ2' -> ['í‚¤ì›Œë“œ1','í‚¤ì›Œë“œ2']\n",
    "    terms = [t.strip() for t in str(query).split(\",\") if t.strip()]\n",
    "    mask = pd.Series(True, index=corpus.index)\n",
    "    for t in terms:\n",
    "        # ëŒ€ì†Œë¬¸ì ë¬´ì‹œ, ì •ê·œì‹ ë©”íƒ€ë¬¸ì ì´ìŠ¤ì¼€ì´í”„\n",
    "        mask &= corpus[\"ì œëª©\"].str.contains(re.escape(t), case=False, na=False)\n",
    "\n",
    "    candidates = corpus[mask & ~corpus[\"ì œëª©\"].isin(used_titles)]\n",
    "    if candidates.empty:\n",
    "        return None\n",
    "    # ì²« ê±´ ì„ íƒ(ê°€ì¥ ë‹¨ìˆœí•˜ê³  ì˜ˆì¸¡ê°€ëŠ¥)  [ë³€ê²½ì ] ìš°ì„ ìˆœìœ„ì–¸ë¡ ì‚¬ ê·œì¹™ ì œê±°\n",
    "    return candidates.iloc[0]\n",
    "\n",
    "\n",
    "def extract_daily_news_from_keyword_file(\n",
    "    keyword_path: str,\n",
    "    output_dir: str,\n",
    "    risk_dir: str = r\"C:\\Users\\amongpapa\\uto\\risk_report\\bigkinds\"\n",
    "):\n",
    "    \"\"\"\n",
    "    [ë³€ê²½ì ] ìš”êµ¬ì‚¬í•­ì— ë§ì¶˜ ìƒˆë¡œìš´ ë©”ì¸ í•¨ìˆ˜\n",
    "      - ì…ë ¥: keyword.xlsx (Scenario_ID, News_kor, Phase)\n",
    "      - ë¹…ì¹´ì¸ì¦ˆ: risk_dirì˜ ìµœì‹  '*bigkinds_risk*.xlsx'\n",
    "      - ë§¤ì¹­ ë¡œì§: News_korë¥¼ ','ë¡œ ë¶„í•´í•œ **AND ì¡°ê±´**ìœ¼ë¡œ ì œëª© ê²€ìƒ‰, í‚¤ì›Œë“œë‹¹ 1ê±´ ì„ ì •(ì¤‘ë³µ ì œëª©ì€ ìŠ¤í‚µ)\n",
    "      - ì¶œë ¥ ì»¬ëŸ¼: Scenario_ID, News_kor, Phase, ì œëª©, ì–¸ë¡ ì‚¬, URL\n",
    "      - íŒŒì¼ëª…: YYYYMMDD_news.xlsx\n",
    "    \"\"\"\n",
    "    # 1) í‚¤ì›Œë“œ ë¡œë“œ\n",
    "    df_kw = _load_keywords(keyword_path)\n",
    "\n",
    "    # 2) ìµœì‹  bigkinds ë°ì´í„° ë¡œë“œ\n",
    "    df_risk = _load_latest_bigkinds(risk_dir)\n",
    "\n",
    "    # 3) ë§¤ì¹­ ìˆ˜í–‰\n",
    "    used_titles = set()\n",
    "    rows = []\n",
    "    not_found = []\n",
    "\n",
    "    for _, r in df_kw.iterrows():\n",
    "        scenario_id = r[\"Scenario_ID\"]\n",
    "        news_kor = r[\"News_kor\"]\n",
    "        phase = r[\"Phase\"]\n",
    "\n",
    "        hit = _match_first(df_risk, news_kor, used_titles)\n",
    "        if hit is None:\n",
    "            not_found.append((scenario_id, news_kor))\n",
    "            continue\n",
    "\n",
    "        used_titles.add(hit[\"ì œëª©\"])\n",
    "        rows.append({\n",
    "            \"Scenario_ID\": scenario_id,\n",
    "            \"News_kor\": news_kor,\n",
    "            \"Phase\": phase,\n",
    "            \"ì œëª©\": hit[\"ì œëª©\"],\n",
    "            \"ì–¸ë¡ ì‚¬\": hit[\"ì–¸ë¡ ì‚¬\"],\n",
    "            \"URL\": hit[\"URL\"],\n",
    "        })\n",
    "\n",
    "    # 4) ì €ì¥\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    date_str = dt.datetime.now().strftime(\"%Y%m%d\")\n",
    "    out_file = os.path.join(output_dir, f\"keyword_news_bf.xlsx\")\n",
    "    pd.DataFrame(rows).to_excel(out_file, index=False)\n",
    "\n",
    "    print(f\"[ì™„ë£Œ] ë°ì¼ë¦¬ ê¸°ì‚¬ íŒŒì¼: {out_file}\")\n",
    "    print(f\" - ë§¤ì¹­ ì„±ê³µ {len(rows)}ê±´ / ì‹¤íŒ¨ {len(not_found)}ê±´\")\n",
    "    if not_found:\n",
    "        print(\" - ë§¤ì¹­ ì‹¤íŒ¨ ë¦¬ìŠ¤íŠ¸(Scenario_ID, News_kor):\")\n",
    "        for sc, kw in not_found[:20]:  # ë„ˆë¬´ ê¸¸ë©´ ì• 20ê°œë§Œ\n",
    "            print(f\"   Â· {sc} | {kw}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # âš ï¸ ê²½ë¡œëŠ” r\"...\" raw stringìœ¼ë¡œ ì…ë ¥í•˜ì„¸ìš” (ìœˆë„ìš° ë°±ìŠ¬ë˜ì‹œ ì´ìŠ¤ì¼€ì´í”„ ë°©ì§€)\n",
    "    keyword_path = r\"C:\\Users\\amongpapa\\chartup\\go_scen\\data\\news\\keyword.xlsx\"   # [ë³€ê²½ì ]\n",
    "    output_dir   = r\"C:\\Users\\amongpapa\\chartup\\go_scen\\data\\news\\bigkinds\\daily_news\"                          # í•„ìš”ì— ë§ê²Œ ì¡°ì •\n",
    "    risk_dir     = r\"C:\\Users\\amongpapa\\chartup\\go_scen\\data\\news\\bigkinds\"                 # í•„ìš” ì‹œ ì¡°ì •\n",
    "    extract_daily_news_from_keyword_file(keyword_path, output_dir, risk_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63c68e93-2e40-4aac-8e92-c2607ef55b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] ì†ŒìŠ¤ íŒŒì¼: keyword_news_bf.xlsx\n",
      "[INFO] íƒ€ê¹ƒ íŒŒì¼: keyword_news.xlsx (ìµœëŒ€ 30í–‰, FIFO)\n",
      "\n",
      "[DEBUG] row=0, fill?=True, news=<NA>\n",
      "[DEBUG] URL=https://www.ajunews.com/view/20251121095621074\n",
      "[INFO] í˜ì´ì§€ ì—´ê¸°: https://www.ajunews.com/view/20251121095621074\n",
      "[DEBUG] ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ê¸¸ì´: 2597\n",
      "[DEBUG] ì •ì œ í›„ í…ìŠ¤íŠ¸ ê¸¸ì´: 2452\n",
      "[OK] row=0 ìš”ì•½ ì™„ë£Œ\n",
      "\n",
      "[DEBUG] row=1, fill?=True, news=<NA>\n",
      "[DEBUG] URL=https://www.mt.co.kr/world/2025/11/22/2025112206033930726\n",
      "[INFO] í˜ì´ì§€ ì—´ê¸°: https://www.mt.co.kr/world/2025/11/22/2025112206033930726\n",
      "[DEBUG] ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ê¸¸ì´: 3261\n",
      "[DEBUG] ì •ì œ í›„ í…ìŠ¤íŠ¸ ê¸¸ì´: 3066\n",
      "[OK] row=1 ìš”ì•½ ì™„ë£Œ\n",
      "\n",
      "[DEBUG] row=2, fill?=True, news=<NA>\n",
      "[DEBUG] URL=https://www.etoday.co.kr/news/view/2528102\n",
      "[INFO] í˜ì´ì§€ ì—´ê¸°: https://www.etoday.co.kr/news/view/2528102\n",
      "[DEBUG] ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ê¸¸ì´: 5438\n",
      "[DEBUG] ì •ì œ í›„ í…ìŠ¤íŠ¸ ê¸¸ì´: 5118\n",
      "[OK] row=2 ìš”ì•½ ì™„ë£Œ\n",
      "\n",
      "[DEBUG] row=3, fill?=True, news=<NA>\n",
      "[DEBUG] URL=https://www.etoday.co.kr/news/view/2528075\n",
      "[INFO] í˜ì´ì§€ ì—´ê¸°: https://www.etoday.co.kr/news/view/2528075\n",
      "[DEBUG] ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ê¸¸ì´: 5336\n",
      "[DEBUG] ì •ì œ í›„ í…ìŠ¤íŠ¸ ê¸¸ì´: 5006\n",
      "[OK] row=3 ìš”ì•½ ì™„ë£Œ\n",
      "\n",
      "[OK] ì €ì¥ ì™„ë£Œ(source): keyword_news_bf.xlsx (updated=4)\n",
      "[INFO] íƒ€ê¹ƒ íŒŒì¼ ìµœì´ˆ ìƒì„± ìƒíƒœ\n",
      "[OK] ì €ì¥ ì™„ë£Œ(target): keyword_news.xlsx (ì´ 4í–‰, max=30)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "r\"\"\"\n",
    "ëª©ì (ì—…ë°ì´íŠ¸ ë²„ì „ - ìš´ì˜ìš©)\n",
    "- (ì†ŒìŠ¤) daily_news í´ë”ì˜ 'keyword_news_bf.xlsx' ë§Œ ì²˜ë¦¬\n",
    "- ê° í–‰ì˜ URL í˜ì´ì§€ë¥¼ Seleniumìœ¼ë¡œ ì—´ì–´ body.innerText ì¶”ì¶œ â†’ GPT ìš”ì•½ ìƒì„±\n",
    "- (íƒ€ê¹ƒ) 'keyword_news.xlsx'ëŠ” ì €ì¥ìš©: ê¸°ì¡´ ë‚´ìš©ì€ ìœ ì§€í•˜ë©´ì„œ\n",
    "  - ì²˜ë¦¬ëœ í–‰ë“¤ì„ 'ê·¸ëŒ€ë¡œ' ì•„ë˜ë¡œ ì´ì–´ì„œ ì¶”ê°€(append)\n",
    "  - ì „ì²´ í–‰ ìˆ˜ê°€ max_rows(ê¸°ë³¸ 30)ë¥¼ ë„˜ìœ¼ë©´, 'ë¨¼ì € ë“¤ì–´ì˜¨ í–‰'ë¶€í„° ì œê±°(FIFO)í•˜ì—¬ ìµœê·¼ max_rowsí–‰ ìœ ì§€\n",
    "\n",
    "íŠ¹ì§•\n",
    "- news ì»¬ëŸ¼ ë¹„ì–´ ìˆëŠ” í–‰ë§Œ ì²˜ë¦¬(FILL_ONLY_EMPTY=True)\n",
    "- íŠ¹ì • ì–¸ë¡ ì‚¬ì—ì„œ timeout ë‚˜ë”ë¼ë„ ê·¸ í–‰ë§Œ ìŠ¤í‚µí•˜ê³  ë‹¤ìŒ í–‰ ì²˜ë¦¬\n",
    "- Windows ê²½ë¡œëŠ” pathlib.Path(r\"...\") ì‚¬ìš©\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import time\n",
    "from typing import List, Optional\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# âœ… Selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import WebDriverException, TimeoutException, NoSuchElementException\n",
    "\n",
    "# =========================\n",
    "# ê²½ë¡œ ë° ì˜µì…˜\n",
    "# =========================\n",
    "DIR_PATH = Path(r\"C:\\Users\\amongpapa\\chartup\\go_scen\\data\\news\\bigkinds\\daily_news\")  # ì‘ì—… í´ë”\n",
    "KEY_PATH = Path(r\"C:\\Users\\amongpapa\\lm\\keys\\open.txt\")  # OpenAI í‚¤ íŒŒì¼\n",
    "SOURCE_BF = DIR_PATH / \"keyword_news_bf.xlsx\"  # ì†ŒìŠ¤(ë§¤ì¼ ê°±ì‹ )\n",
    "TARGET_NEWS = DIR_PATH / \"keyword_news.xlsx\"   # íƒ€ê¹ƒ(ì €ì¥/ë¡¤ë§)\n",
    "\n",
    "# ğŸ” ìˆ˜ì •: ìµœëŒ€ í–‰ ìˆ˜ 20 â†’ 30 (ìµœê·¼ 30ê°œë§Œ ìœ ì§€)\n",
    "MAX_TARGET_ROWS = 30  # íƒ€ê¹ƒ ìµœëŒ€ í–‰ ìˆ˜(ë„˜ì¹˜ë©´ FIFO, ìµœê·¼ 30ê°œ ìœ ì§€)\n",
    "\n",
    "# âœ… daily_news í´ë”ê°€ ì—†ìœ¼ë©´ ìë™ ìƒì„±\n",
    "DIR_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# íŒ€ì¥ë‹˜ í™˜ê²½\n",
    "CHROME_PATH = Path(r\"C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe\")\n",
    "CHROME_PROFILE = \"Profile 1\"\n",
    "\n",
    "MODEL_ID = \"gpt-4o-mini\"\n",
    "FILL_ONLY_EMPTY = True\n",
    "TARGET_NEWS_COL_INDEX = 6  # Gì—´(0-based=6)\n",
    "PAGE_LOAD_WAIT = 8.0       # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°(ì´ˆ)\n",
    "REQUEST_INTERVAL_SEC = 0.4 # GPT í˜¸ì¶œ ê°„ê²©\n",
    "\n",
    "# =========================\n",
    "# OpenAI ì‹ /êµ¬ SDK ìë™ í˜¸í™˜\n",
    "# =========================\n",
    "def load_api_key(path: Path) -> str:\n",
    "    \"\"\"open.txtì—ì„œ OpenAI API í‚¤ë¥¼ í•œ ì¤„ ì½ì–´ì˜¤ëŠ” í•¨ìˆ˜.\"\"\"\n",
    "    key = path.read_text(encoding=\"utf-8\").strip()\n",
    "    if not key:\n",
    "        raise ValueError(\"API í‚¤ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.\")\n",
    "    return key\n",
    "\n",
    "\n",
    "class ChatClient:\n",
    "    \"\"\"ì‹ /êµ¬ OpenAI SDK ìë™ ê°ì§€ ë˜í¼(.chat -> str).\"\"\"\n",
    "    def __init__(self, api_key: str):\n",
    "        self.mode = None\n",
    "        try:\n",
    "            from openai import OpenAI  # ì‹ ë²„ì „\n",
    "            self._client = OpenAI(api_key=api_key)\n",
    "            self.mode = \"new\"\n",
    "        except Exception:\n",
    "            import openai  # êµ¬ë²„ì „\n",
    "            openai.api_key = api_key\n",
    "            self._client = openai\n",
    "            self.mode = \"old\"\n",
    "\n",
    "    def chat(self, messages: List[dict], model: str, temperature: float = 0.2) -> str:\n",
    "        \"\"\"messages ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ GPTë¡œë¶€í„° ë¬¸ìì—´ ë‹µë³€ë§Œ ë°˜í™˜í•˜ëŠ” ê³µí†µ ì¸í„°í˜ì´ìŠ¤.\"\"\"\n",
    "        if self.mode == \"new\":\n",
    "            res = self._client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                temperature=temperature,\n",
    "            )\n",
    "            return res.choices[0].message.content.strip()\n",
    "        else:\n",
    "            res = self._client.ChatCompletion.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                temperature=temperature,\n",
    "            )\n",
    "            return res[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "\n",
    "\n",
    "# =========================\n",
    "# í…ìŠ¤íŠ¸ ì •ë¦¬ & í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
    "# =========================\n",
    "PROMPT_TEMPLATE = (\n",
    "    \"ê¸°ì‚¬ ìš”ì•½ â€“ ì„œìˆ í˜• ë³´ê³ ì„œ\\n\"\n",
    "    \"[ì—­í• ] ë‹¹ì‹ ì€ ì€í–‰ ë¦¬ìŠ¤í¬ê´€ë¦¬ ë³´ê³ ì„œ ì—ë””í„°ë‹¤.\\n\"\n",
    "    \"[ëª©í‘œ] ì—¬ëŸ¬ ê¸°ì‚¬ ì›ë¬¸ì—ì„œ ê´‘ê³ /í™ë³´/ë¬´ê´€/ì¤‘ë³µ ë‚´ìš©ì„ ì œê±°í•˜ê³  í•µì‹¬ ì‚¬ì‹¤ë§Œì„ ë°”íƒ•ìœ¼ë¡œ í•œêµ­ì–´ ì„œìˆ í˜• ë³´ê³ ì„œë¥¼ ì‘ì„±í•œë‹¤. \"\n",
    "    \"ì´ ê¸¸ì´ {2000}ì ì´ë‚´.\\n\"\n",
    "    \"[ì…ë ¥] {ê¸°ì‚¬ ì›ë¬¸ë“¤}\\n\"\n",
    "    \"[ì¶œë ¥ ì§€ì¹¨ â€“ ì„œìˆ í˜• ë³´ê³ ì„œ]\\n\"\n",
    "    \"- ì œëª©: í•œ ì¤„\\n\"\n",
    "    \"- ìš”ì•½: 3ë¬¸ì¥\\n\"\n",
    "    \"- ë³¸ë¬¸: ì—°ëŒ€ê¸° ìˆœ(ì‚¬ì‹¤â†’ì›ì¸â†’ì˜í–¥â†’ì „ë§)ìœ¼ë¡œ 3â€“6ë‹¨ë½. ìˆ«ìÂ·ê¸°ê´€ëª…Â·ì§€ëª… ì •í™•íˆ ê¸°ìˆ .\\n\"\n",
    "    \"- í•µì‹¬ ìˆ˜ì¹˜: ë³¸ë¬¸ì— ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ ì“°ë˜ ìµœì´ˆ ë“±ì¥ ë¬¸ì¥ ëì— ê·¼ê±° [s#] í‘œê¸°(ìµœëŒ€ 5ê°œ).\\n\"\n",
    "    \"- ìì‚°/ì„¹í„°/í‹°ì»¤: í•„ìš”í•œ ê²½ìš° ê´„í˜¸ë¡œ ê°„ë‹¨ í‘œê¸°(ì˜ˆ: ì›/ë‹¬ëŸ¬ í™˜ìœ¨(USDKRW), ì‚¼ì„±ì „ì(005930.KS)).\\n\"\n",
    "    \"- ì‹œë‚˜ë¦¬ì˜¤ ì—°ê²°: ë¬¸ë‹¨ ë§ë¯¸ì— 1â€“2ë¬¸ì¥ìœ¼ë¡œ â€˜ì£¼ìš” ë™ì¸Â·ì§€í‘œÂ·íŠ¸ë¦¬ê±°Â·ë°©í–¥ì„±Â·ì˜ˆìƒ ì‹œê³„â€™ë¥¼ í†µí•© ì„œìˆ .\\n\"\n",
    "    \"- ì‹ ë¢°ë„: ë§ˆì§€ë§‰ ë¬¸ì¥ì— (ì‹ ë¢°ë„ 0.0â€“1.0; ê·¼ê±° ìš”ì•½) í˜•ì‹ìœ¼ë¡œ í‘œê¸°.\\n\"\n",
    "    \"- ì¤‘ë³µ/ì œê±°: ì‚­ì œÂ·í†µí•©í•œ ê¸°ì‚¬ ì œëª©(ë˜ëŠ” ìš”ì§€)ë§Œ ë§ˆì§€ë§‰ ì¤„ì— â€˜ì œê±°: â€¦â€™ë¡œ ë‚˜ì—´.\\n\"\n",
    "    \"[ê¸ˆì§€] ê´‘ê³ ë¬¸êµ¬, ê³¼ì¥/ì¶”ì¸¡, ë¶ˆí•„ìš” í…ìŠ¤íŠ¸, í‘œ/ë¶ˆë¦¿/JSON ì¶œë ¥.\\n\"\n",
    "    \"[ì‹¤í–‰] ìœ„ ì§€ì¹¨ì„ ì ìš©í•´ ê²°ê³¼ë§Œ ì¶œë ¥í•œë‹¤.\\n\"\n",
    ")\n",
    "\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    ë³¸ë¬¸ í…ìŠ¤íŠ¸ ì •ì œ:\n",
    "    - ê°œí–‰/ê³µë°± ì •ë¦¬\n",
    "    - ì¿ í‚¤/ì €ì‘ê¶Œ/êµ¬ë…/ê´‘ê³  ê´€ë ¨ ë¬¸êµ¬ ì œê±°\n",
    "    \"\"\"\n",
    "    text = re.sub(r\"\\r\", \"\\n\", text)\n",
    "    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n",
    "    text = re.sub(r\"[ \\t]+\", \" \", text)\n",
    "\n",
    "    drop_patterns = [\n",
    "        r\"ì¿ í‚¤(ë¥¼|ì—) ì‚¬ìš©\",\n",
    "        r\"ì´ìš©ì•½ê´€\",\n",
    "        r\"ê°œì¸ì •ë³´\",\n",
    "        r\"êµ¬ë…\",\n",
    "        r\"ê´‘ê³ ë¬¸ì˜\",\n",
    "        r\"ë¬´ë‹¨ì „ì¬\",\n",
    "        r\"ì €ì‘ê¶Œ\",\n",
    "    ]\n",
    "\n",
    "    cleaned_lines = []\n",
    "    for ln in text.splitlines():\n",
    "        if any(re.search(pat, ln, re.IGNORECASE) for pat in drop_patterns):\n",
    "            continue\n",
    "        cleaned_lines.append(ln.strip())\n",
    "    return \"\\n\".join(cleaned_lines).strip()\n",
    "\n",
    "\n",
    "def build_prompt(article_text: str, max_chars: int = 2000) -> str:\n",
    "    \"\"\"\n",
    "    ê¸°ì‚¬ í…ìŠ¤íŠ¸ë¥¼ PROMPT_TEMPLATEì— ì±„ì›Œ ë„£ì–´ GPTìš© í”„ë¡¬í”„íŠ¸ ìƒì„±.\n",
    "    - ë„ˆë¬´ ê¸´ í…ìŠ¤íŠ¸ëŠ” 8,000ìê¹Œì§€ë§Œ ì‚¬ìš©\n",
    "    \"\"\"\n",
    "    article_text = article_text[:8000]\n",
    "    return (\n",
    "        PROMPT_TEMPLATE\n",
    "        .replace(\"{2000}\", str(max_chars))\n",
    "        .replace(\"{ê¸°ì‚¬ ì›ë¬¸ë“¤}\", article_text)\n",
    "    )\n",
    "\n",
    "\n",
    "def summarize_article(client: ChatClient, article_text: str, model: str = MODEL_ID) -> str:\n",
    "    \"\"\"\n",
    "    ì •ì œëœ ê¸°ì‚¬ í…ìŠ¤íŠ¸ â†’ GPT ìš”ì•½.\n",
    "    - ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¡œ 'ë¦¬ìŠ¤í¬ê´€ë¦¬ ë³´ì¡°ì›' ì—­í•  ì§€ì •\n",
    "    - ì¶œë ¥ì€ ë°˜ë“œì‹œ í•œêµ­ì–´ ì„œìˆ í˜•\n",
    "    \"\"\"\n",
    "    sys_msg = (\n",
    "        \"ë„ˆëŠ” ì€í–‰ ë¦¬ìŠ¤í¬ê´€ë¦¬ ë³´ì¡°ì›ì´ë©°, ì¶œë ¥ì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•œë‹¤. \"\n",
    "        \"ê´‘ê³ /êµ¬ë…/ì €ì‘ê¶Œ/ì¶”ì²œê¸°ì‚¬/ëŒ“ê¸€ ë“± ë¶ˆí•„ìš” í…ìŠ¤íŠ¸ëŠ” ì œê±°í•˜ê³ , \"\n",
    "        \"ìš”êµ¬ëœ í•„ë“œë§Œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•œë‹¤.\"\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": sys_msg},\n",
    "        {\"role\": \"user\", \"content\": build_prompt(article_text, max_chars=2000)},\n",
    "    ]\n",
    "    return client.chat(messages, model=model, temperature=0.2)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Selenium ë“œë¼ì´ë²„ êµ¬ì„±/í•´ì œ\n",
    "# =========================\n",
    "def build_driver(download_dir: Optional[Path] = None) -> webdriver.Chrome:\n",
    "    \"\"\"\n",
    "    Selenium Chrome ë“œë¼ì´ë²„ ìƒì„±.\n",
    "    - í¬ë¡¬ í”„ë¡œí•„ ì¬ì‚¬ìš©(íšŒì‚¬ í”„ë¡ì‹œ/ë³´ì•ˆ ì„¤ì • ê·¸ëŒ€ë¡œ í™œìš©)\n",
    "    - page_load_timeout ê¸°ë³¸ 45ì´ˆ\n",
    "    \"\"\"\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "\n",
    "    # íŒ€ì¥ë‹˜ PCì— ì„¤ì¹˜ëœ Chrome ê²½ë¡œ ì§€ì •\n",
    "    if CHROME_PATH.exists():\n",
    "        chrome_options.binary_location = str(CHROME_PATH)\n",
    "\n",
    "    # ì§€ì •í•œ ì‚¬ìš©ì í”„ë¡œí•„ ì‚¬ìš©\n",
    "    chrome_options.add_argument(f'--profile-directory={CHROME_PROFILE}')\n",
    "    chrome_options.add_argument('--disable-gpu')\n",
    "    chrome_options.add_argument('--disable-notifications')\n",
    "    chrome_options.add_argument('--start-maximized')\n",
    "\n",
    "    # (ì„ íƒ) ë‹¤ìš´ë¡œë“œ ê²½ë¡œ ì§€ì •\n",
    "    if download_dir:\n",
    "        prefs = {\n",
    "            \"download.default_directory\": str(download_dir),\n",
    "            \"download.prompt_for_download\": False,\n",
    "            \"directory_upgrade\": True,\n",
    "            \"safebrowsing.enabled\": True\n",
    "        }\n",
    "        chrome_options.add_experimental_option(\"prefs\", prefs)\n",
    "\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.set_page_load_timeout(45)  # ğŸ” 30ì´ˆ â†’ 45ì´ˆë¡œ ì—¬ìœ \n",
    "    return driver\n",
    "\n",
    "\n",
    "def safe_quit(driver: webdriver.Chrome):\n",
    "    \"\"\"ë“œë¼ì´ë²„ ì¢…ë£Œ ì‹œ ì˜ˆì™¸ ë¬´ì‹œí•˜ê³  ì•ˆì „í•˜ê²Œ ì¢…ë£Œ.\"\"\"\n",
    "    try:\n",
    "        driver.quit()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "\n",
    "# =========================\n",
    "# ì—‘ì…€ ìœ í‹¸\n",
    "# =========================\n",
    "def ensure_news_column_at_G(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    'news' ì¹¼ëŸ¼ì„ Gì—´(index=6)ì— ê³ ì •:\n",
    "    - ì—†ìœ¼ë©´ ìƒì„±í•˜ì—¬ Gì—´ì— ì‚½ì…\n",
    "    - ìˆìœ¼ë©´ í•´ë‹¹ ì¹¼ëŸ¼ì„ Gì—´ ìœ„ì¹˜ë¡œ ì´ë™\n",
    "    \"\"\"\n",
    "    cols = list(df.columns)\n",
    "\n",
    "    if \"news\" not in cols:\n",
    "        insert_at = min(TARGET_NEWS_COL_INDEX, len(cols))\n",
    "        df.insert(insert_at, \"news\", pd.NA)\n",
    "    else:\n",
    "        current_idx = cols.index(\"news\")\n",
    "        if current_idx != TARGET_NEWS_COL_INDEX:\n",
    "            cols.pop(current_idx)\n",
    "            insert_at = min(TARGET_NEWS_COL_INDEX, len(cols))\n",
    "            cols.insert(insert_at, \"news\")\n",
    "            df = df.reindex(columns=cols)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def should_fill(val) -> bool:\n",
    "    \"\"\"\n",
    "    newsë¥¼ ì±„ìš¸ì§€ ì—¬ë¶€(FILL_ONLY_EMPTY ì •ì±…).\n",
    "    - FILL_ONLY_EMPTY=True: ë¹„ì–´ ìˆì„ ë•Œë§Œ True\n",
    "    - pandasì˜ <NA>, NaN ë“±ë„ ë¹„ì–´ìˆëŠ” ê²ƒìœ¼ë¡œ ì²˜ë¦¬\n",
    "    \"\"\"\n",
    "    if not FILL_ONLY_EMPTY:\n",
    "        # í•­ìƒ ë®ì–´ì“°ëŠ” ëª¨ë“œì¼ ë•ŒëŠ” ê·¸ëƒ¥ True\n",
    "        return True\n",
    "\n",
    "    # ì–´ë–¤ íƒ€ì…ì´ë“  NaN/<NA>/Noneì´ë©´ True\n",
    "    if pd.isna(val):\n",
    "        return True\n",
    "\n",
    "    # ë¬¸ìì—´ì¸ë° ê³µë°±ë¿ì¸ ê²½ìš°ë„ ë¹„ì–´ìˆëŠ” ê²ƒìœ¼ë¡œ ê°„ì£¼\n",
    "    if isinstance(val, str) and not val.strip():\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "# =========================\n",
    "# í˜ì´ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ (Selenium)\n",
    "# =========================\n",
    "def get_visible_text(driver: webdriver.Chrome, url: str) -> str:\n",
    "    \"\"\"\n",
    "    ì£¼ì–´ì§„ URLì„ ì—´ê³ , document.body.innerTextë¥¼ ê°€ì ¸ì˜´.\n",
    "    - PAGE_LOAD_WAIT ë™ì•ˆ ì¶”ê°€ ëŒ€ê¸°\n",
    "    - timeout/ê¸°íƒ€ ì˜ˆì™¸ ì‹œ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"[INFO] í˜ì´ì§€ ì—´ê¸°: {url}\")\n",
    "        driver.get(url)\n",
    "        time.sleep(PAGE_LOAD_WAIT)\n",
    "\n",
    "        try:\n",
    "            text = driver.execute_script(\n",
    "                \"return document.body ? document.body.innerText : '';\"\n",
    "            )\n",
    "        except Exception:\n",
    "            try:\n",
    "                text = driver.find_element(By.TAG_NAME, \"body\").text\n",
    "            except NoSuchElementException:\n",
    "                text = \"\"\n",
    "\n",
    "        text = text or \"\"\n",
    "        print(f\"[DEBUG] ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)}\")\n",
    "        return text\n",
    "\n",
    "    except (WebDriverException, TimeoutException) as e:\n",
    "        print(f\"[ERR] í˜ì´ì§€ ë¡œë”© ì‹¤íŒ¨: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "# =========================\n",
    "# íƒ€ê¹ƒ íŒŒì¼(keyword_news.xlsx) Append + FIFO(ìµœê·¼ 30í–‰ ìœ ì§€)\n",
    "# =========================\n",
    "def append_rows_to_keyword_news(\n",
    "    rows_df: pd.DataFrame,\n",
    "    target_path: Path,\n",
    "    max_rows: int = MAX_TARGET_ROWS\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    - ê¸°ì¡´ targetì„ ì½ì–´ì˜¤ê³ (rows_old), rows_dfë¥¼ ì•„ë˜ë¡œ ì´ì–´ë¶™ì„\n",
    "    - ì „ì²´ í–‰ì´ max_rowsë¥¼ ì´ˆê³¼í•˜ë©´ 'ë¨¼ì € ë“¤ì–´ì˜¨ í–‰'ë¶€í„° ì œê±°í•˜ì—¬ ìµœê·¼ max_rowsí–‰ ìœ ì§€\n",
    "    \"\"\"\n",
    "    if target_path.exists():\n",
    "        try:\n",
    "            rows_old = pd.read_excel(target_path, engine=\"openpyxl\")\n",
    "            print(f\"[INFO] ê¸°ì¡´ íƒ€ê¹ƒ í–‰ ìˆ˜: {len(rows_old)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] íƒ€ê¹ƒ íŒŒì¼ ë¡œë”© ì‹¤íŒ¨, ì´ë²ˆ ì‹¤í–‰ë¶€í„° ìƒˆë¡œ ì‹œì‘: {e}\")\n",
    "            rows_old = pd.DataFrame()\n",
    "    else:\n",
    "        print(\"[INFO] íƒ€ê¹ƒ íŒŒì¼ ìµœì´ˆ ìƒì„± ìƒíƒœ\")\n",
    "        rows_old = pd.DataFrame()\n",
    "\n",
    "    rows_old = ensure_news_column_at_G(rows_old)\n",
    "    rows_df = ensure_news_column_at_G(rows_df.copy())\n",
    "\n",
    "    # ê¸°ì¡´ + ì‹ ê·œë¥¼ ê·¸ëŒ€ë¡œ ì´ì–´ ë¶™ì„ (keyword_news.xlsx ë§ˆì§€ë§‰ë¶€í„° ì´ì–´ì„œ)\n",
    "    out_df = pd.concat([rows_old, rows_df], ignore_index=True)\n",
    "\n",
    "    # FIFO: ìµœëŒ€ í–‰ ìˆ˜ ìœ ì§€ (ì•ì—ì„œ ì˜ë¼ë‚´ê³  ìµœì‹  max_rowsë§Œ ë‚¨ê¹€)\n",
    "    if len(out_df) > max_rows:\n",
    "        out_df = out_df.iloc[-max_rows:].reset_index(drop=True)\n",
    "\n",
    "    out_df = ensure_news_column_at_G(out_df)\n",
    "    out_df.to_excel(target_path, index=False, engine=\"openpyxl\")\n",
    "    print(f\"[OK] ì €ì¥ ì™„ë£Œ(target): {target_path.name} (ì´ {len(out_df)}í–‰, max={max_rows})\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# ì†ŒìŠ¤ íŒŒì¼ ì²˜ë¦¬ + 'ì´ë²ˆì— ì²˜ë¦¬ëœ í–‰' ë°˜í™˜\n",
    "# =========================\n",
    "def process_source_file_and_collect(\n",
    "    xlsx_path: Path,\n",
    "    client: ChatClient,\n",
    "    driver: webdriver.Chrome\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    - (ì†ŒìŠ¤) keyword_news_bf.xlsx í•œ ê°œë¥¼ ì²˜ë¦¬\n",
    "    - ì´ë²ˆ ì‹¤í–‰ì—ì„œ newsê°€ ìƒˆë¡œ ì±„ì›Œì§„ í–‰ë§Œ ëª¨ì•„ DataFrameìœ¼ë¡œ ë°˜í™˜(íƒ€ê¹ƒ Append ìš©)\n",
    "    - ì†ŒìŠ¤ íŒŒì¼ì—ë„ news ë°˜ì˜í•˜ì—¬ ì €ì¥\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_excel(xlsx_path, engine=\"openpyxl\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERR] ì—‘ì…€ ë¡œë”© ì‹¤íŒ¨: {xlsx_path.name} -> {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    if \"URL\" not in df.columns:\n",
    "        print(f\"[SKIP] 'URL' ì¹¼ëŸ¼ ì—†ìŒ: {xlsx_path.name}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = ensure_news_column_at_G(df)\n",
    "\n",
    "    updated_indices: List[int] = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        url = str(row.get(\"URL\", \"\")).strip()\n",
    "        news_val = row.get(\"news\", None)\n",
    "        fill_flag = should_fill(news_val)\n",
    "\n",
    "        print(f\"\\n[DEBUG] row={idx}, fill?={fill_flag}, news={repr(news_val)}\")\n",
    "        print(f\"[DEBUG] URL={url}\")\n",
    "\n",
    "        if not url.startswith(\"http\"):\n",
    "            print(\"[SKIP] http/https ì•„ë‹˜\")\n",
    "            continue\n",
    "\n",
    "        if not fill_flag:\n",
    "            print(\"[SKIP] newsê°€ ì´ë¯¸ ì±„ì›Œì ¸ ìˆìŒ(ë®ì–´ì“°ê¸° ëª¨ë“œ ì•„ë‹˜)\")\n",
    "            continue\n",
    "\n",
    "        # 1) í˜ì´ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "        raw = get_visible_text(driver, url)\n",
    "        if not raw or len(raw) < 30:\n",
    "            print(f\"[WARN] í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìŒ(len={len(raw)})\")\n",
    "            continue\n",
    "\n",
    "        # 2) í…ìŠ¤íŠ¸ ì •ì œ\n",
    "        article_text = clean_text(raw)\n",
    "        print(f\"[DEBUG] ì •ì œ í›„ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(article_text)}\")\n",
    "\n",
    "        # 3) GPT ìš”ì•½\n",
    "        try:\n",
    "            summary = summarize_article(client, article_text, model=MODEL_ID)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERR] GPT ìš”ì•½ ì‹¤íŒ¨ row={idx} -> {e}\")\n",
    "            continue\n",
    "\n",
    "        # 4) ì†ŒìŠ¤ dfì— news ë°˜ì˜\n",
    "        df.at[idx, \"news\"] = summary\n",
    "        updated_indices.append(idx)\n",
    "        print(f\"[OK] row={idx} ìš”ì•½ ì™„ë£Œ\")\n",
    "\n",
    "        # 5) API í˜¸ì¶œ ê°„ ê°„ê²©\n",
    "        time.sleep(REQUEST_INTERVAL_SEC)\n",
    "\n",
    "    # ì†ŒìŠ¤ íŒŒì¼ ì €ì¥\n",
    "    try:\n",
    "        df.to_excel(xlsx_path, index=False, engine=\"openpyxl\")\n",
    "        print(f\"\\n[OK] ì €ì¥ ì™„ë£Œ(source): {xlsx_path.name} (updated={len(updated_indices)})\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERR] ì†ŒìŠ¤ ì €ì¥ ì‹¤íŒ¨: {xlsx_path.name} -> {e}\")\n",
    "\n",
    "    if updated_indices:\n",
    "        # ì´ë²ˆì— ì‹¤ì œë¡œ ìƒˆë¡œ ìš”ì•½ëœ í–‰ë§Œ ë°˜í™˜ (íƒ€ê¹ƒ append ìš©)\n",
    "        return df.loc[updated_indices].copy()\n",
    "\n",
    "    return pd.DataFrame()\n",
    "\n",
    "\n",
    "# =========================\n",
    "# ì‹¤í–‰ë¶€\n",
    "# =========================\n",
    "def main():\n",
    "    # 1) API í‚¤ ë¡œë”©\n",
    "    api_key = load_api_key(KEY_PATH)\n",
    "    client = ChatClient(api_key=api_key)\n",
    "\n",
    "    # 2) Selenium ë“œë¼ì´ë²„ ìƒì„±\n",
    "    driver = build_driver(download_dir=None)\n",
    "\n",
    "    try:\n",
    "        bf_path = SOURCE_BF\n",
    "\n",
    "        if not bf_path.exists():\n",
    "            print(f\"[ERR] ì†ŒìŠ¤ íŒŒì¼ ì—†ìŒ: {bf_path}\")\n",
    "            return\n",
    "\n",
    "        print(f\"[INFO] ì†ŒìŠ¤ íŒŒì¼: {bf_path.name}\")\n",
    "        print(f\"[INFO] íƒ€ê¹ƒ íŒŒì¼: {TARGET_NEWS.name} (ìµœëŒ€ {MAX_TARGET_ROWS}í–‰, FIFO)\")\n",
    "\n",
    "        # 3) ì†ŒìŠ¤ íŒŒì¼ ì²˜ë¦¬ (keyword_news_bf.xlsxì˜ news ë¹ˆ ì¹¸ ì±„ìš°ê¸°)\n",
    "        processed_rows = process_source_file_and_collect(bf_path, client, driver)\n",
    "\n",
    "        # 4) íƒ€ê¹ƒ íŒŒì¼ Append + FIFO ìœ ì§€\n",
    "        #    - keyword_news.xlsx ê¸°ì¡´ í–‰ ë’¤ì— processed_rows(ì´ë²ˆì— ìƒˆë¡œ ìš”ì•½ëœ í–‰) ì´ì–´ ë¶™ì´ê³ \n",
    "        #    - ìƒìœ„ë¶€í„° ì‚­ì œí•´ì„œ ìµœê·¼ ê¸°ì¤€ 30ê°œë§Œ ë‚¨ê¹€\n",
    "        if not processed_rows.empty:\n",
    "            append_rows_to_keyword_news(\n",
    "                processed_rows,\n",
    "                TARGET_NEWS,\n",
    "                max_rows=MAX_TARGET_ROWS\n",
    "            )\n",
    "        else:\n",
    "            print(\"[INFO] ì´ë²ˆ ì‹¤í–‰ì—ì„œ ìƒˆë¡œ ì²˜ë¦¬ëœ í–‰ì´ ì—†ìŠµë‹ˆë‹¤(ìš”ì•½ ëŒ€ìƒ ì—†ìŒ).\")\n",
    "\n",
    "    finally:\n",
    "        safe_quit(driver)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9387cdd3-3a32-4655-b8fa-f4adc9dc49ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
